{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b9e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from source.Data_load import Data_load\n",
    "from source.Attention_LSTM import RNNModel\n",
    "from source.train import train_epoch_lstm,evaluate_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98024906",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b6d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbrnlist1=[(5,194),(2,155),(12,100),(17,29),(42,1),(44,1),(50,92),(2,83),(4,10118),(8,298)]\n",
    "mbrnlist2=[(5,194),(12,100),(2,155),(17,29),(42,1),(44,1),(2,83),(4,10118),(4,9997),(50,91)]\n",
    "\n",
    "mbrnlist=mbrnlist1+mbrnlist2\n",
    "mbrnlist=set(mbrnlist)\n",
    "mbrnlist=list(mbrnlist)\n",
    "\n",
    "# load array\n",
    "MBR_NO,BRN_NO=mbrnlist[2]\n",
    "featnorm=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59917b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 39\n",
    "TGT_VOCAB_SIZE = 3\n",
    "EMB_SIZE =128\n",
    "NHEAD = 16\n",
    "FFN_HID_DIM = 128\n",
    "BATCH_SIZE = 32\n",
    "NUM_LAYERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff76f3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "42337\n",
      "Acc: 0.5802768640350877\n",
      "Prec 0.37837993139960807\n",
      "Recall 0.33710688954444695\n",
      "F1 0.3565529874382879\n",
      "468\n",
      "468\n",
      "71744\n",
      "42801\n",
      "Acc: 0.5965795049063336\n",
      "Prec 0.19885983496877788\n",
      "Recall 0.3333333333333333\n",
      "F1 0.2491073377275307\n",
      "Epoch: 1, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "43211\n",
      "Acc: 0.5922560307017544\n",
      "Prec 0.19949676823638043\n",
      "Recall 0.3333333333333333\n",
      "F1 0.24960647887405302\n",
      "468\n",
      "468\n",
      "71744\n",
      "42801\n",
      "Acc: 0.5965795049063336\n",
      "Prec 0.19885983496877788\n",
      "Recall 0.3333333333333333\n",
      "F1 0.2491073377275307\n",
      "Epoch: 2, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.801s\n",
      "468\n",
      "468\n",
      "72960\n",
      "43211\n",
      "Acc: 0.5922560307017544\n",
      "Prec 0.19949953138778467\n",
      "Recall 0.3333333333333333\n",
      "F1 0.24960864165439153\n",
      "468\n",
      "468\n",
      "71744\n",
      "43210\n",
      "Acc: 0.6022803300624442\n",
      "Prec 0.358277522490726\n",
      "Recall 0.34337048038733337\n",
      "F1 0.35066564575116277\n",
      "Epoch: 3, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.797s\n",
      "468\n",
      "468\n",
      "72960\n",
      "44157\n",
      "Acc: 0.6052220394736842\n",
      "Prec 0.4837339456995157\n",
      "Recall 0.36427992855926566\n",
      "F1 0.4155935947041766\n",
      "468\n",
      "468\n",
      "71744\n",
      "45326\n",
      "Acc: 0.6317740856378233\n",
      "Prec 0.4905583697477236\n",
      "Recall 0.4249278340110078\n",
      "F1 0.45539059934934206\n",
      "Epoch: 4, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45276\n",
      "Acc: 0.6205592105263158\n",
      "Prec 0.4832914498912782\n",
      "Recall 0.41548818652388625\n",
      "F1 0.4468323044761828\n",
      "468\n",
      "468\n",
      "71744\n",
      "45257\n",
      "Acc: 0.6308123327386262\n",
      "Prec 0.4899946597103282\n",
      "Recall 0.427133548562368\n",
      "F1 0.45640981466018077\n",
      "Epoch: 5, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.817s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45359\n",
      "Acc: 0.6216968201754386\n",
      "Prec 0.48960927068165566\n",
      "Recall 0.41776982727415213\n",
      "F1 0.450845695928651\n",
      "468\n",
      "468\n",
      "71744\n",
      "45377\n",
      "Acc: 0.6324849464763604\n",
      "Prec 0.5023360978632765\n",
      "Recall 0.43487293240956576\n",
      "F1 0.4661764128956063\n",
      "Epoch: 6, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.771s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45585\n",
      "Acc: 0.6247944078947368\n",
      "Prec 0.49788078970974753\n",
      "Recall 0.41836182154427254\n",
      "F1 0.45467065499123166\n",
      "468\n",
      "468\n",
      "71744\n",
      "45518\n",
      "Acc: 0.634450267618198\n",
      "Prec 0.4984098698065331\n",
      "Recall 0.4418991042943275\n",
      "F1 0.46845639275018763\n",
      "Epoch: 7, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.813s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45604\n",
      "Acc: 0.6250548245614035\n",
      "Prec 0.4970666934064949\n",
      "Recall 0.4239011726558861\n",
      "F1 0.45757764627354525\n",
      "468\n",
      "468\n",
      "71744\n",
      "45723\n",
      "Acc: 0.6373076494201606\n",
      "Prec 0.5134830262471484\n",
      "Recall 0.44221911055094615\n",
      "F1 0.4751940974219968\n",
      "Epoch: 8, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.813s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45610\n",
      "Acc: 0.6251370614035088\n",
      "Prec 0.49742624844224365\n",
      "Recall 0.4241900725110957\n",
      "F1 0.4578983066996283\n",
      "468\n",
      "468\n",
      "71744\n",
      "46043\n",
      "Acc: 0.641767952720785\n",
      "Prec 0.51870461914792\n",
      "Recall 0.4432294770262306\n",
      "F1 0.4780060879230965\n",
      "Epoch: 9, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.814s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45863\n",
      "Acc: 0.6286047149122806\n",
      "Prec 0.5041699278921588\n",
      "Recall 0.42571935053294946\n",
      "F1 0.46163537797533627\n",
      "468\n",
      "468\n",
      "71744\n",
      "45588\n",
      "Acc: 0.6354259589652096\n",
      "Prec 0.5042008670491921\n",
      "Recall 0.45279985836113984\n",
      "F1 0.47711997519656907\n",
      "Epoch: 10, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45393\n",
      "Acc: 0.6221628289473684\n",
      "Prec 0.4925396775438092\n",
      "Recall 0.4252222101100716\n",
      "F1 0.4564120891694013\n",
      "468\n",
      "468\n",
      "71744\n",
      "45870\n",
      "Acc: 0.6393566012488849\n",
      "Prec 0.5138639663484669\n",
      "Recall 0.4368142365584249\n",
      "F1 0.4722167721297242\n",
      "Epoch: 11, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45402\n",
      "Acc: 0.6222861842105263\n",
      "Prec 0.49286965854903814\n",
      "Recall 0.41436615579336317\n",
      "F1 0.4502214363487953\n",
      "468\n",
      "468\n",
      "71744\n",
      "45894\n",
      "Acc: 0.6396911239964318\n",
      "Prec 0.5125057998800239\n",
      "Recall 0.45765754575529954\n",
      "F1 0.4835312478330112\n",
      "Epoch: 12, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45816\n",
      "Acc: 0.6279605263157895\n",
      "Prec 0.4978680024342614\n",
      "Recall 0.4287465784199107\n",
      "F1 0.46072921138727235\n",
      "468\n",
      "468\n",
      "71744\n",
      "45797\n",
      "Acc: 0.63833909455843\n",
      "Prec 0.5231659881971619\n",
      "Recall 0.45098192090503036\n",
      "F1 0.48439954570509386\n",
      "Epoch: 13, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45922\n",
      "Acc: 0.6294133771929824\n",
      "Prec 0.5052161185957192\n",
      "Recall 0.42907846204707806\n",
      "F1 0.4640449803728969\n",
      "468\n",
      "468\n",
      "71744\n",
      "45255\n",
      "Acc: 0.6307844558429974\n",
      "Prec 0.5074417399958563\n",
      "Recall 0.45561011376129706\n",
      "F1 0.48013113309481614\n",
      "Epoch: 14, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46162\n",
      "Acc: 0.632702850877193\n",
      "Prec 0.5027692860795451\n",
      "Recall 0.4355428531522372\n",
      "F1 0.4667478127602194\n",
      "468\n",
      "468\n",
      "71744\n",
      "46210\n",
      "Acc: 0.6440956735057984\n",
      "Prec 0.5291083417885335\n",
      "Recall 0.45748799833280235\n",
      "F1 0.4906985893668626\n",
      "Epoch: 15, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46101\n",
      "Acc: 0.6318667763157895\n",
      "Prec 0.5014767996550241\n",
      "Recall 0.4367012375324355\n",
      "F1 0.4668528367167398\n",
      "468\n",
      "468\n",
      "71744\n",
      "46243\n",
      "Acc: 0.6445556422836753\n",
      "Prec 0.37305929557761947\n",
      "Recall 0.456126416102624\n",
      "F1 0.41043205903964786\n",
      "Epoch: 16, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46338\n",
      "Acc: 0.6351151315789474\n",
      "Prec 0.509893176830305\n",
      "Recall 0.43866536454243876\n",
      "F1 0.47160500177094294\n",
      "468\n",
      "468\n",
      "71744\n",
      "46258\n",
      "Acc: 0.644764719000892\n",
      "Prec 0.3755400143838504\n",
      "Recall 0.4695215694066754\n",
      "F1 0.41730482206423\n",
      "Epoch: 17, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46586\n",
      "Acc: 0.6385142543859649\n",
      "Prec 0.5129996977971506\n",
      "Recall 0.44121410390071564\n",
      "F1 0.47440668236440964\n",
      "468\n",
      "468\n",
      "71744\n",
      "45351\n",
      "Acc: 0.6321225468331847\n",
      "Prec 0.4808503260421744\n",
      "Recall 0.4716937662757561\n",
      "F1 0.47622803633966554\n",
      "Epoch: 18, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46456\n",
      "Acc: 0.6367324561403509\n",
      "Prec 0.5085323532737295\n",
      "Recall 0.4391620626181245\n",
      "F1 0.4713082897329742\n",
      "468\n",
      "468\n",
      "71744\n",
      "47008\n",
      "Acc: 0.6552185548617306\n",
      "Prec 0.5239704544236524\n",
      "Recall 0.4798068285930624\n",
      "F1 0.5009170983784698\n",
      "Epoch: 19, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46991\n",
      "Acc: 0.6440652412280702\n",
      "Prec 0.516958733855845\n",
      "Recall 0.4549117328960315\n",
      "F1 0.4839546040329283\n",
      "468\n",
      "468\n",
      "71744\n",
      "45984\n",
      "Acc: 0.6409455842997324\n",
      "Prec 0.49827528242054503\n",
      "Recall 0.4806938352689814\n",
      "F1 0.48932668497603854\n",
      "Epoch: 20, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46865\n",
      "Acc: 0.6423382675438597\n",
      "Prec 0.5160771323576067\n",
      "Recall 0.4543036539664826\n",
      "F1 0.4832241739796792\n",
      "468\n",
      "468\n",
      "71744\n",
      "46730\n",
      "Acc: 0.6513436663693131\n",
      "Prec 0.5203449318066711\n",
      "Recall 0.48435664505057513\n",
      "F1 0.5017062404287631\n",
      "Epoch: 21, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46964\n",
      "Acc: 0.6436951754385964\n",
      "Prec 0.5195140018173182\n",
      "Recall 0.4548190942710925\n",
      "F1 0.48501870400646424\n",
      "468\n",
      "468\n",
      "71744\n",
      "46533\n",
      "Acc: 0.6485977921498662\n",
      "Prec 0.5145526506386503\n",
      "Recall 0.48411233272982135\n",
      "F1 0.49886856585834716\n",
      "Epoch: 22, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46690\n",
      "Acc: 0.6399396929824561\n",
      "Prec 0.5126761166428054\n",
      "Recall 0.44868683240036394\n",
      "F1 0.4785518789812451\n",
      "468\n",
      "468\n",
      "71744\n",
      "47352\n",
      "Acc: 0.6600133809099019\n",
      "Prec 0.5368793675959552\n",
      "Recall 0.4624253107989558\n",
      "F1 0.4968787073445382\n",
      "Epoch: 23, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.903s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47023\n",
      "Acc: 0.6445038377192982\n",
      "Prec 0.515928604068573\n",
      "Recall 0.4575766117532831\n",
      "F1 0.48500379601355725\n",
      "468\n",
      "468\n",
      "71744\n",
      "46593\n",
      "Acc: 0.6494340990187333\n",
      "Prec 0.5172712033214144\n",
      "Recall 0.49319777787494606\n",
      "F1 0.5049477278060951\n",
      "Epoch: 24, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47077\n",
      "Acc: 0.6452439692982456\n",
      "Prec 0.5184619564686354\n",
      "Recall 0.4621022573843749\n",
      "F1 0.4886624191814328\n",
      "468\n",
      "468\n",
      "71744\n",
      "47177\n",
      "Acc: 0.6575741525423728\n",
      "Prec 0.5281833911756934\n",
      "Recall 0.4721808885106129\n",
      "F1 0.4986145707243637\n",
      "Epoch: 25, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46752\n",
      "Acc: 0.6407894736842106\n",
      "Prec 0.5124146069537839\n",
      "Recall 0.44947624923492935\n",
      "F1 0.47888633955699283\n",
      "468\n",
      "468\n",
      "71744\n",
      "46977\n",
      "Acc: 0.6547864629794826\n",
      "Prec 0.5240423238122687\n",
      "Recall 0.4969836107446198\n",
      "F1 0.5101544191122828\n",
      "Epoch: 26, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47385\n",
      "Acc: 0.6494654605263158\n",
      "Prec 0.522124573310258\n",
      "Recall 0.46996377973622655\n",
      "F1 0.4946729536992277\n",
      "468\n",
      "468\n",
      "71744\n",
      "47585\n",
      "Acc: 0.663261039250669\n",
      "Prec 0.5329490428783509\n",
      "Recall 0.49415442836800755\n",
      "F1 0.5128190820215026\n",
      "Epoch: 27, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46980\n",
      "Acc: 0.6439144736842105\n",
      "Prec 0.5180198740018104\n",
      "Recall 0.4564464332336313\n",
      "F1 0.4852878382282189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "71744\n",
      "47059\n",
      "Acc: 0.6559294157002676\n",
      "Prec 0.5260673682435689\n",
      "Recall 0.49834256925712134\n",
      "F1 0.5118297944911446\n",
      "Epoch: 28, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.823s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47283\n",
      "Acc: 0.6480674342105263\n",
      "Prec 0.5216929655910113\n",
      "Recall 0.4663247123027386\n",
      "F1 0.4924574277015166\n",
      "468\n",
      "468\n",
      "71744\n",
      "47256\n",
      "Acc: 0.6586752899197146\n",
      "Prec 0.5280130126249124\n",
      "Recall 0.49845897605572304\n",
      "F1 0.5128105365162539\n",
      "Epoch: 29, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.892s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47222\n",
      "Acc: 0.6472313596491228\n",
      "Prec 0.522520600894362\n",
      "Recall 0.46330220197363464\n",
      "F1 0.49113277612703027\n",
      "468\n",
      "468\n",
      "71744\n",
      "47136\n",
      "Acc: 0.6570026761819804\n",
      "Prec 0.5251066451803172\n",
      "Recall 0.4948374036285808\n",
      "F1 0.5095228688918563\n",
      "Epoch: 30, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46966\n",
      "Acc: 0.6437225877192982\n",
      "Prec 0.5129346614334693\n",
      "Recall 0.46371062321201423\n",
      "F1 0.4870821684388655\n",
      "468\n",
      "468\n",
      "71744\n",
      "46898\n",
      "Acc: 0.653685325602141\n",
      "Prec 0.5265622833327447\n",
      "Recall 0.5016001683881295\n",
      "F1 0.5137782060499658\n",
      "Epoch: 31, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46795\n",
      "Acc: 0.6413788377192983\n",
      "Prec 0.5116124507035988\n",
      "Recall 0.4587813002705044\n",
      "F1 0.48375873223165533\n",
      "468\n",
      "468\n",
      "71744\n",
      "46940\n",
      "Acc: 0.6542707404103479\n",
      "Prec 0.5263505696183265\n",
      "Recall 0.5038300711958564\n",
      "F1 0.5148441631657772\n",
      "Epoch: 32, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47209\n",
      "Acc: 0.6470531798245615\n",
      "Prec 0.5216783305473275\n",
      "Recall 0.4696905801138665\n",
      "F1 0.4943213269501996\n",
      "468\n",
      "468\n",
      "71744\n",
      "47756\n",
      "Acc: 0.6656445138269402\n",
      "Prec 0.5351518750498597\n",
      "Recall 0.4896687695677054\n",
      "F1 0.5114010174635075\n",
      "Epoch: 33, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47182\n",
      "Acc: 0.6466831140350877\n",
      "Prec 0.5206330517799973\n",
      "Recall 0.4643149957979565\n",
      "F1 0.4908639269735176\n",
      "468\n",
      "468\n",
      "71744\n",
      "48189\n",
      "Acc: 0.6716798617305977\n",
      "Prec 0.5431973017833985\n",
      "Recall 0.5054757879180047\n",
      "F1 0.5236581100637929\n",
      "Epoch: 34, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47442\n",
      "Acc: 0.6502467105263158\n",
      "Prec 0.5238184685269802\n",
      "Recall 0.46921995788553333\n",
      "F1 0.49501826556668077\n",
      "468\n",
      "468\n",
      "71744\n",
      "47804\n",
      "Acc: 0.6663135593220338\n",
      "Prec 0.5296621295452383\n",
      "Recall 0.5123706472317834\n",
      "F1 0.5208729210392776\n",
      "Epoch: 35, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45839\n",
      "Acc: 0.6282757675438596\n",
      "Prec 0.49200946131642426\n",
      "Recall 0.4677946224664436\n",
      "F1 0.47959658454319076\n",
      "468\n",
      "468\n",
      "71744\n",
      "46591\n",
      "Acc: 0.6494062221231044\n",
      "Prec 0.5431389676369428\n",
      "Recall 0.43231007023264006\n",
      "F1 0.48142842143354214\n",
      "Epoch: 36, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.813s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45930\n",
      "Acc: 0.6295230263157895\n",
      "Prec 0.5032170385500424\n",
      "Recall 0.4291952995462393\n",
      "F1 0.46326797442046463\n",
      "468\n",
      "468\n",
      "71744\n",
      "47460\n",
      "Acc: 0.6615187332738626\n",
      "Prec 0.5314825483581412\n",
      "Recall 0.4854100310079256\n",
      "F1 0.5074025821675803\n",
      "Epoch: 37, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.891s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46504\n",
      "Acc: 0.637390350877193\n",
      "Prec 0.5063828079132019\n",
      "Recall 0.45226131346367\n",
      "F1 0.47779431118466614\n",
      "468\n",
      "468\n",
      "71744\n",
      "47609\n",
      "Acc: 0.6635955619982159\n",
      "Prec 0.5308961457166211\n",
      "Recall 0.4931091733615673\n",
      "F1 0.5113054681997724\n",
      "Epoch: 38, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46232\n",
      "Acc: 0.6336622807017543\n",
      "Prec 0.5043551819472322\n",
      "Recall 0.4457063727100359\n",
      "F1 0.4732205352405927\n",
      "468\n",
      "468\n",
      "71744\n",
      "47407\n",
      "Acc: 0.6607799955396967\n",
      "Prec 0.5268177189379255\n",
      "Recall 0.48933593792887925\n",
      "F1 0.5073855531040679\n",
      "Epoch: 39, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47016\n",
      "Acc: 0.6444078947368421\n",
      "Prec 0.520383360261517\n",
      "Recall 0.45412994855008465\n",
      "F1 0.4850044970859806\n",
      "468\n",
      "468\n",
      "71744\n",
      "47215\n",
      "Acc: 0.658103813559322\n",
      "Prec 0.5262928028760362\n",
      "Recall 0.49284234092751317\n",
      "F1 0.5090186096707237\n",
      "Epoch: 40, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47128\n",
      "Acc: 0.6459429824561403\n",
      "Prec 0.5230282159977309\n",
      "Recall 0.46247161774457113\n",
      "F1 0.4908893880986248\n",
      "468\n",
      "468\n",
      "71744\n",
      "47435\n",
      "Acc: 0.6611702720785013\n",
      "Prec 0.5300784528738048\n",
      "Recall 0.49985158091176096\n",
      "F1 0.5145214606517577\n",
      "Epoch: 41, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47347\n",
      "Acc: 0.6489446271929824\n",
      "Prec 0.5257047639120236\n",
      "Recall 0.46660538451522293\n",
      "F1 0.4943951725081823\n",
      "468\n",
      "468\n",
      "71744\n",
      "47458\n",
      "Acc: 0.6614908563782337\n",
      "Prec 0.52863888251829\n",
      "Recall 0.5035208853445968\n",
      "F1 0.5157742559648913\n",
      "Epoch: 42, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47533\n",
      "Acc: 0.6514939692982457\n",
      "Prec 0.5255133110597475\n",
      "Recall 0.4756917959222717\n",
      "F1 0.4993629556537214\n",
      "468\n",
      "468\n",
      "71744\n",
      "48318\n",
      "Acc: 0.6734779214986619\n",
      "Prec 0.5406320871543947\n",
      "Recall 0.5101064829057006\n",
      "F1 0.5249258766783896\n",
      "Epoch: 43, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47610\n",
      "Acc: 0.6525493421052632\n",
      "Prec 0.5254907441023767\n",
      "Recall 0.47682053129442054\n",
      "F1 0.49997397404115096\n",
      "468\n",
      "468\n",
      "71744\n",
      "48259\n",
      "Acc: 0.6726555530776093\n",
      "Prec 0.5448286255282832\n",
      "Recall 0.4974638132868256\n",
      "F1 0.520070021713355\n",
      "Epoch: 44, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47555\n",
      "Acc: 0.6517955043859649\n",
      "Prec 0.5267279519027976\n",
      "Recall 0.4720711467947473\n",
      "F1 0.4979040702536697\n",
      "468\n",
      "468\n",
      "71744\n",
      "47684\n",
      "Acc: 0.6646409455842998\n",
      "Prec 0.5354066663168137\n",
      "Recall 0.5172117049058681\n",
      "F1 0.526151931743369\n",
      "Epoch: 45, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47962\n",
      "Acc: 0.6573739035087719\n",
      "Prec 0.5339466498118287\n",
      "Recall 0.4848255749370054\n",
      "F1 0.5082019026275069\n",
      "468\n",
      "468\n",
      "71744\n",
      "47668\n",
      "Acc: 0.6644179304192686\n",
      "Prec 0.5337444266504979\n",
      "Recall 0.520100983170647\n",
      "F1 0.5268343885653793\n",
      "Epoch: 46, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47789\n",
      "Acc: 0.6550027412280702\n",
      "Prec 0.5302345136100366\n",
      "Recall 0.4847908598603654\n",
      "F1 0.5064954088818113\n",
      "468\n",
      "468\n",
      "71744\n",
      "48052\n",
      "Acc: 0.6697702943800179\n",
      "Prec 0.5388203945532862\n",
      "Recall 0.5151870424597086\n",
      "F1 0.5267387605415128\n",
      "Epoch: 47, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47639\n",
      "Acc: 0.6529468201754386\n",
      "Prec 0.5269281746932248\n",
      "Recall 0.4773224272220244\n",
      "F1 0.5009001435230741\n",
      "468\n",
      "468\n",
      "71744\n",
      "48344\n",
      "Acc: 0.6738403211418377\n",
      "Prec 0.5442506530529418\n",
      "Recall 0.5042334228253916\n",
      "F1 0.5234783741163551\n",
      "Epoch: 48, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47994\n",
      "Acc: 0.6578125\n",
      "Prec 0.5341614504034725\n",
      "Recall 0.47881781182519173\n",
      "F1 0.5049777944730052\n",
      "468\n",
      "468\n",
      "71744\n",
      "47754\n",
      "Acc: 0.6656166369313113\n",
      "Prec 0.5312954571493945\n",
      "Recall 0.5108912200474363\n",
      "F1 0.5208935985226583\n",
      "Epoch: 49, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47310\n",
      "Acc: 0.6484375\n",
      "Prec 0.5161041828641896\n",
      "Recall 0.47423137253945846\n",
      "F1 0.4942825564074233\n",
      "468\n",
      "468\n",
      "71744\n",
      "47812\n",
      "Acc: 0.6664250669045495\n",
      "Prec 0.5363629540004998\n",
      "Recall 0.5144061503207712\n",
      "F1 0.5251551481812801\n",
      "Epoch: 50, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47893\n",
      "Acc: 0.6564281798245614\n",
      "Prec 0.5303272653596315\n",
      "Recall 0.48335891924244273\n",
      "F1 0.5057549717512587\n",
      "468\n",
      "468\n",
      "71744\n",
      "47474\n",
      "Acc: 0.6617138715432649\n",
      "Prec 0.532542481696325\n",
      "Recall 0.5078671894756914\n",
      "F1 0.5199122248659023\n",
      "Epoch: 51, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47176\n",
      "Acc: 0.6466008771929824\n",
      "Prec 0.5166700455567167\n",
      "Recall 0.47924827849965096\n",
      "F1 0.4972560980239142\n",
      "468\n",
      "468\n",
      "71744\n",
      "48045\n",
      "Acc: 0.6696727252453167\n",
      "Prec 0.5388116817088391\n",
      "Recall 0.49345709057754444\n",
      "F1 0.5151380182437102\n",
      "Epoch: 52, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46415\n",
      "Acc: 0.6361705043859649\n",
      "Prec 0.5059185716327411\n",
      "Recall 0.4590915195615515\n",
      "F1 0.48136890576519686\n",
      "468\n",
      "468\n",
      "71744\n",
      "47436\n",
      "Acc: 0.6611842105263158\n",
      "Prec 0.5303974810037698\n",
      "Recall 0.4976513228702686\n",
      "F1 0.5135028747155178\n",
      "Epoch: 53, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46781\n",
      "Acc: 0.641186951754386\n",
      "Prec 0.5149355085803088\n",
      "Recall 0.45502585371953125\n",
      "F1 0.48313052150179375\n",
      "468\n",
      "468\n",
      "71744\n",
      "47530\n",
      "Acc: 0.6624944246208743\n",
      "Prec 0.5325972697873879\n",
      "Recall 0.5170397436201474\n",
      "F1 0.524703211312431\n",
      "Epoch: 54, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47708\n",
      "Acc: 0.6538925438596491\n",
      "Prec 0.5270090961590453\n",
      "Recall 0.48024599879573876\n",
      "F1 0.502542029376782\n",
      "468\n",
      "468\n",
      "71744\n",
      "47567\n",
      "Acc: 0.663010147190009\n",
      "Prec 0.531611388053238\n",
      "Recall 0.513842451860695\n",
      "F1 0.5225759161147305\n",
      "Epoch: 55, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "47212\n",
      "Acc: 0.647094298245614\n",
      "Prec 0.515682010227991\n",
      "Recall 0.4750801076100985\n",
      "F1 0.49454911628291026\n",
      "468\n",
      "468\n",
      "71744\n",
      "47424\n",
      "Acc: 0.6610169491525424\n",
      "Prec 0.5316571709090202\n",
      "Recall 0.5107452661914028\n",
      "F1 0.5209914589874196\n",
      "Epoch: 56, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46887\n",
      "Acc: 0.6426398026315789\n",
      "Prec 0.5206934426616395\n",
      "Recall 0.4551214654074139\n",
      "F1 0.48570432915629697\n",
      "468\n",
      "468\n",
      "71744\n",
      "46495\n",
      "Acc: 0.6480681311329171\n",
      "Prec 0.5185673680363485\n",
      "Recall 0.4997223200414476\n",
      "F1 0.5089704654518967\n",
      "Epoch: 57, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46325\n",
      "Acc: 0.6349369517543859\n",
      "Prec 0.5041153363631077\n",
      "Recall 0.4595136695986172\n",
      "F1 0.4807823066346216\n",
      "468\n",
      "468\n",
      "71744\n",
      "46864\n",
      "Acc: 0.6532114183764496\n",
      "Prec 0.5270300916452334\n",
      "Recall 0.47303703326591817\n",
      "F1 0.4985760351153929\n",
      "Epoch: 58, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.819s\n",
      "468\n",
      "468\n",
      "72960\n",
      "45637\n",
      "Acc: 0.6255071271929824\n",
      "Prec 0.4939612015224715\n",
      "Recall 0.4345215944706477\n",
      "F1 0.46233879576110504\n",
      "468\n",
      "468\n",
      "71744\n",
      "47021\n",
      "Acc: 0.6553997546833185\n",
      "Prec 0.5236983184528743\n",
      "Recall 0.492882996081907\n",
      "F1 0.5078236094871247\n",
      "Epoch: 59, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.818s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46049\n",
      "Acc: 0.6311540570175439\n",
      "Prec 0.5006335421793022\n",
      "Recall 0.44173808049648117\n",
      "F1 0.46934541455419837\n",
      "468\n",
      "468\n",
      "71744\n",
      "45770\n",
      "Acc: 0.6379627564674398\n",
      "Prec 0.5112543842412692\n",
      "Recall 0.4953102194440813\n",
      "F1 0.5031560226201847\n",
      "Epoch: 60, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46440\n",
      "Acc: 0.6365131578947368\n",
      "Prec 0.5073744446630163\n",
      "Recall 0.4500171292838477\n",
      "F1 0.4769776490051068\n",
      "468\n",
      "468\n",
      "71744\n",
      "47593\n",
      "Acc: 0.6633725468331847\n",
      "Prec 0.5379169645287981\n",
      "Recall 0.4753374735325993\n",
      "F1 0.5046947366520199\n",
      "Epoch: 61, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47349\n",
      "Acc: 0.6489720394736842\n",
      "Prec 0.5243759194306697\n",
      "Recall 0.4694087277100229\n",
      "F1 0.49537217925419724\n",
      "468\n",
      "468\n",
      "71744\n",
      "47677\n",
      "Acc: 0.6645433764495986\n",
      "Prec 0.5340826982596752\n",
      "Recall 0.5131028322964051\n",
      "F1 0.5233826044407324\n",
      "Epoch: 62, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47555\n",
      "Acc: 0.6517955043859649\n",
      "Prec 0.5264608099500104\n",
      "Recall 0.4775782835421895\n",
      "F1 0.5008296023487657\n",
      "468\n",
      "468\n",
      "71744\n",
      "48170\n",
      "Acc: 0.6714150312221231\n",
      "Prec 0.5415618130900203\n",
      "Recall 0.5193826060192115\n",
      "F1 0.530240379678597\n",
      "Epoch: 63, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.864s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47714\n",
      "Acc: 0.6539747807017544\n",
      "Prec 0.5324048793759075\n",
      "Recall 0.47381808747524295\n",
      "F1 0.5014058911769939\n",
      "468\n",
      "468\n",
      "71744\n",
      "47583\n",
      "Acc: 0.6632331623550402\n",
      "Prec 0.5334456172407317\n",
      "Recall 0.5189285194181692\n",
      "F1 0.5260869394295428\n",
      "Epoch: 64, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47944\n",
      "Acc: 0.6571271929824561\n",
      "Prec 0.5344260646602724\n",
      "Recall 0.484248444174414\n",
      "F1 0.5081014359219422\n",
      "468\n",
      "468\n",
      "71744\n",
      "47672\n",
      "Acc: 0.6644736842105263\n",
      "Prec 0.5305348124507331\n",
      "Recall 0.5169380889836602\n",
      "F1 0.5236482045731738\n",
      "Epoch: 65, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47743\n",
      "Acc: 0.6543722587719298\n",
      "Prec 0.530227794995389\n",
      "Recall 0.4808714132521394\n",
      "F1 0.5043449486364913\n",
      "468\n",
      "468\n",
      "71744\n",
      "48114\n",
      "Acc: 0.6706344781445138\n",
      "Prec 0.5238342708727034\n",
      "Recall 0.5030975058879533\n",
      "F1 0.5132565203230903\n",
      "Epoch: 66, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47590\n",
      "Acc: 0.6522752192982456\n",
      "Prec 0.526507612066724\n",
      "Recall 0.47528544440030035\n",
      "F1 0.4995870210236598\n",
      "468\n",
      "468\n",
      "71744\n",
      "48756\n",
      "Acc: 0.6795829616413916\n",
      "Prec 0.5405739037883004\n",
      "Recall 0.5161751685494619\n",
      "F1 0.5280928712510505\n",
      "Epoch: 67, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.823s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47589\n",
      "Acc: 0.6522615131578947\n",
      "Prec 0.5273580223879374\n",
      "Recall 0.47472594232902093\n",
      "F1 0.4996597948627883\n",
      "468\n",
      "468\n",
      "71744\n",
      "48145\n",
      "Acc: 0.6710665700267618\n",
      "Prec 0.5141001183045041\n",
      "Recall 0.5108789347191299\n",
      "F1 0.5124844649334072\n",
      "Epoch: 68, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47421\n",
      "Acc: 0.6499588815789473\n",
      "Prec 0.5260806739270154\n",
      "Recall 0.47285117877151867\n",
      "F1 0.49804772192077934\n",
      "468\n",
      "468\n",
      "71744\n",
      "48657\n",
      "Acc: 0.6782030553077609\n",
      "Prec 0.539689142653145\n",
      "Recall 0.5062699847488473\n",
      "F1 0.5224456804517499\n",
      "Epoch: 69, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47430\n",
      "Acc: 0.6500822368421053\n",
      "Prec 0.5247252269892563\n",
      "Recall 0.4708919574803468\n",
      "F1 0.4963532030795999\n",
      "468\n",
      "468\n",
      "71744\n",
      "48509\n",
      "Acc: 0.6761401650312221\n",
      "Prec 0.5383442797753136\n",
      "Recall 0.5111581693394625\n",
      "F1 0.5243991126584336\n",
      "Epoch: 70, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47444\n",
      "Acc: 0.6502741228070176\n",
      "Prec 0.524615661095336\n",
      "Recall 0.47257424656902797\n",
      "F1 0.49723698339692024\n",
      "468\n",
      "468\n",
      "71744\n",
      "48253\n",
      "Acc: 0.6725719223907226\n",
      "Prec 0.535295118617335\n",
      "Recall 0.498725152525076\n",
      "F1 0.5163634546224309\n",
      "Epoch: 71, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47415\n",
      "Acc: 0.6498766447368421\n",
      "Prec 0.526378604258121\n",
      "Recall 0.46903122011807813\n",
      "F1 0.4960529682414108\n",
      "468\n",
      "468\n",
      "71744\n",
      "47945\n",
      "Acc: 0.6682788804638715\n",
      "Prec 0.5344855857838628\n",
      "Recall 0.5105916336995224\n",
      "F1 0.5222654620088911\n",
      "Epoch: 72, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47388\n",
      "Acc: 0.6495065789473684\n",
      "Prec 0.5251808334772663\n",
      "Recall 0.4719366952986957\n",
      "F1 0.49713719763754044\n",
      "468\n",
      "468\n",
      "71744\n",
      "48430\n",
      "Acc: 0.6750390276538805\n",
      "Prec 0.5407012520840091\n",
      "Recall 0.4992242670268718\n",
      "F1 0.5191356136407499\n",
      "Epoch: 73, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46623\n",
      "Acc: 0.6390213815789474\n",
      "Prec 0.5135930728260253\n",
      "Recall 0.4524874002930661\n",
      "F1 0.48110773542760066\n",
      "468\n",
      "468\n",
      "71744\n",
      "47918\n",
      "Acc: 0.6679025423728814\n",
      "Prec 0.5277460313688741\n",
      "Recall 0.5071900432085943\n",
      "F1 0.517263894897902\n",
      "Epoch: 74, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47046\n",
      "Acc: 0.6448190789473685\n",
      "Prec 0.5166739581620106\n",
      "Recall 0.4632732039934199\n",
      "F1 0.4885185839840444\n",
      "468\n",
      "468\n",
      "71744\n",
      "47864\n",
      "Acc: 0.667149866190901\n",
      "Prec 0.5305045010885675\n",
      "Recall 0.5031130537185602\n",
      "F1 0.5164458330120263\n",
      "Epoch: 75, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46890\n",
      "Acc: 0.6426809210526315\n",
      "Prec 0.5141197291692655\n",
      "Recall 0.46886993660764303\n",
      "F1 0.4904533449673928\n",
      "468\n",
      "468\n",
      "71744\n",
      "48477\n",
      "Acc: 0.6756941347011597\n",
      "Prec 0.5451323565272456\n",
      "Recall 0.49268380428476233\n",
      "F1 0.5175827731231706\n",
      "Epoch: 76, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47499\n",
      "Acc: 0.6510279605263158\n",
      "Prec 0.5277034756852863\n",
      "Recall 0.47032647938568156\n",
      "F1 0.4973656684703413\n",
      "468\n",
      "468\n",
      "71744\n",
      "47714\n",
      "Acc: 0.6650590990187333\n",
      "Prec 0.5255967030864966\n",
      "Recall 0.5083165702677659\n",
      "F1 0.5168122324036161\n",
      "Epoch: 77, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47673\n",
      "Acc: 0.6534128289473684\n",
      "Prec 0.5283260384407015\n",
      "Recall 0.4813103256021302\n",
      "F1 0.5037234922239586\n",
      "468\n",
      "468\n",
      "71744\n",
      "47945\n",
      "Acc: 0.6682788804638715\n",
      "Prec 0.5306993050056775\n",
      "Recall 0.5048013252147032\n",
      "F1 0.5174264595094888\n",
      "Epoch: 78, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47319\n",
      "Acc: 0.6485608552631579\n",
      "Prec 0.5204954599467416\n",
      "Recall 0.47202764155628874\n",
      "F1 0.49507813778310544\n",
      "468\n",
      "468\n",
      "71744\n",
      "48172\n",
      "Acc: 0.671442908117752\n",
      "Prec 0.5324321641402204\n",
      "Recall 0.5125418658033083\n",
      "F1 0.5222977165028097\n",
      "Epoch: 79, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47579\n",
      "Acc: 0.6521244517543859\n",
      "Prec 0.5262753168109177\n",
      "Recall 0.4755996829334632\n",
      "F1 0.49965589295040025\n",
      "468\n",
      "468\n",
      "71744\n",
      "47694\n",
      "Acc: 0.6647803300624442\n",
      "Prec 0.5224457427995497\n",
      "Recall 0.512284822934164\n",
      "F1 0.5173153934096735\n",
      "Epoch: 80, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47725\n",
      "Acc: 0.6541255482456141\n",
      "Prec 0.5289452097746276\n",
      "Recall 0.4845550765821964\n",
      "F1 0.5057780250885765\n",
      "468\n",
      "468\n",
      "71744\n",
      "48728\n",
      "Acc: 0.679192685102587\n",
      "Prec 0.5445618054259923\n",
      "Recall 0.5099642546119146\n",
      "F1 0.5266954809712373\n",
      "Epoch: 81, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47367\n",
      "Acc: 0.64921875\n",
      "Prec 0.5239648643365368\n",
      "Recall 0.4770831294774578\n",
      "F1 0.4994261988608602\n",
      "468\n",
      "468\n",
      "71744\n",
      "48584\n",
      "Acc: 0.677185548617306\n",
      "Prec 0.5396256296084488\n",
      "Recall 0.5013961557241186\n",
      "F1 0.5198089416148916\n",
      "Epoch: 82, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46952\n",
      "Acc: 0.643530701754386\n",
      "Prec 0.5180239709765387\n",
      "Recall 0.46497764947102116\n",
      "F1 0.490069524574431\n",
      "468\n",
      "468\n",
      "71744\n",
      "47512\n",
      "Acc: 0.6622435325602141\n",
      "Prec 0.5179227066989552\n",
      "Recall 0.5026175080942837\n",
      "F1 0.5101553401875801\n",
      "Epoch: 83, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "46918\n",
      "Acc: 0.6430646929824562\n",
      "Prec 0.5169002335977378\n",
      "Recall 0.46333114604655723\n",
      "F1 0.48865192973414295\n",
      "468\n",
      "468\n",
      "71744\n",
      "48156\n",
      "Acc: 0.6712198929527208\n",
      "Prec 0.5343471632208001\n",
      "Recall 0.49887435841062916\n",
      "F1 0.5160018304678868\n",
      "Epoch: 84, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47338\n",
      "Acc: 0.6488212719298245\n",
      "Prec 0.5229133586471439\n",
      "Recall 0.47077638894371027\n",
      "F1 0.4954771110624176\n",
      "468\n",
      "468\n",
      "71744\n",
      "48559\n",
      "Acc: 0.6768370874219447\n",
      "Prec 0.5337312468375814\n",
      "Recall 0.514612897407158\n",
      "F1 0.5239977442134716\n",
      "Epoch: 85, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.812s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47518\n",
      "Acc: 0.6512883771929825\n",
      "Prec 0.5226415228176774\n",
      "Recall 0.47940599676304946\n",
      "F1 0.500091014248514\n",
      "468\n",
      "468\n",
      "71744\n",
      "48496\n",
      "Acc: 0.6759589652096343\n",
      "Prec 0.5374773391143927\n",
      "Recall 0.5031049526137307\n",
      "F1 0.5197234536386881\n",
      "Epoch: 86, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46411\n",
      "Acc: 0.6361156798245614\n",
      "Prec 0.5035141579838422\n",
      "Recall 0.4644019284567061\n",
      "F1 0.48316780607058024\n",
      "468\n",
      "468\n",
      "71744\n",
      "47810\n",
      "Acc: 0.6663971900089206\n",
      "Prec 0.5462841199332037\n",
      "Recall 0.4700758915945206\n",
      "F1 0.5053229009975152\n",
      "Epoch: 87, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.890s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46506\n",
      "Acc: 0.6374177631578948\n",
      "Prec 0.5128205167700842\n",
      "Recall 0.4492810123613686\n",
      "F1 0.47895261353994545\n",
      "468\n",
      "468\n",
      "71744\n",
      "47949\n",
      "Acc: 0.6683346342551294\n",
      "Prec 0.5303019695130073\n",
      "Recall 0.49654739056246955\n",
      "F1 0.5128698899952904\n",
      "Epoch: 88, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46728\n",
      "Acc: 0.6404605263157894\n",
      "Prec 0.5123917312408618\n",
      "Recall 0.46012774542782625\n",
      "F1 0.4848553838311202\n",
      "468\n",
      "468\n",
      "71744\n",
      "47750\n",
      "Acc: 0.6655608831400536\n",
      "Prec 0.5267453106488987\n",
      "Recall 0.4966739525334974\n",
      "F1 0.5112678348557659\n",
      "Epoch: 89, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47014\n",
      "Acc: 0.6443804824561403\n",
      "Prec 0.5192804825140708\n",
      "Recall 0.46521744841338797\n",
      "F1 0.49076454809506204\n",
      "468\n",
      "468\n",
      "71744\n",
      "47910\n",
      "Acc: 0.6677910347903657\n",
      "Prec 0.5228117843877421\n",
      "Recall 0.5101148165229298\n",
      "F1 0.5163852634521171\n",
      "Epoch: 90, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47459\n",
      "Acc: 0.6504797149122807\n",
      "Prec 0.5230680521298474\n",
      "Recall 0.47342507322006666\n",
      "F1 0.4970100135747455\n",
      "468\n",
      "468\n",
      "71744\n",
      "47925\n",
      "Acc: 0.6680001115075825\n",
      "Prec 0.5193775694041756\n",
      "Recall 0.5045809977103056\n",
      "F1 0.5118723756505522\n",
      "Epoch: 91, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47047\n",
      "Acc: 0.6448327850877194\n",
      "Prec 0.517600245954193\n",
      "Recall 0.47072912232619046\n",
      "F1 0.49305326202694727\n",
      "468\n",
      "468\n",
      "71744\n",
      "48309\n",
      "Acc: 0.6733524754683319\n",
      "Prec 0.5453453112880463\n",
      "Recall 0.4860507042711483\n",
      "F1 0.5139935943592187\n",
      "Epoch: 92, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "46718\n",
      "Acc: 0.6403234649122806\n",
      "Prec 0.5126384988199373\n",
      "Recall 0.4565819178057944\n",
      "F1 0.4829891424432802\n",
      "468\n",
      "468\n",
      "71744\n",
      "48213\n",
      "Acc: 0.6720143844781445\n",
      "Prec 0.5432886012475924\n",
      "Recall 0.49246431882705544\n",
      "F1 0.516629489049602\n",
      "Epoch: 93, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47157\n",
      "Acc: 0.6463404605263158\n",
      "Prec 0.520992366996945\n",
      "Recall 0.46948056690358553\n",
      "F1 0.49389697272582\n",
      "468\n",
      "468\n",
      "71744\n",
      "48015\n",
      "Acc: 0.6692545718108831\n",
      "Prec 0.5281862575700907\n",
      "Recall 0.5063386873578307\n",
      "F1 0.5170317789816431\n",
      "Epoch: 94, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47338\n",
      "Acc: 0.6488212719298245\n",
      "Prec 0.5232963280281272\n",
      "Recall 0.4703829563857977\n",
      "F1 0.49543082502496266\n",
      "468\n",
      "468\n",
      "71744\n",
      "47733\n",
      "Acc: 0.6653239295272079\n",
      "Prec 0.5208416208414456\n",
      "Recall 0.5080677629546194\n",
      "F1 0.5143753984986902\n",
      "Epoch: 95, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.882s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47642\n",
      "Acc: 0.6529879385964912\n",
      "Prec 0.5274874857603272\n",
      "Recall 0.4785925895391972\n",
      "F1 0.5018519061405663\n",
      "468\n",
      "468\n",
      "71744\n",
      "47995\n",
      "Acc: 0.6689758028545941\n",
      "Prec 0.5294274708293955\n",
      "Recall 0.5116415584226445\n",
      "F1 0.5203825848926151\n",
      "Epoch: 96, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.878s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47928\n",
      "Acc: 0.6569078947368421\n",
      "Prec 0.5331815551683587\n",
      "Recall 0.48563534221070387\n",
      "F1 0.5082990038165467\n",
      "468\n",
      "468\n",
      "71744\n",
      "48397\n",
      "Acc: 0.6745790588760036\n",
      "Prec 0.5308536879847321\n",
      "Recall 0.5165535776268263\n",
      "F1 0.5236060140652176\n",
      "Epoch: 97, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.817s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47993\n",
      "Acc: 0.6577987938596491\n",
      "Prec 0.5324495551248232\n",
      "Recall 0.4862186280422493\n",
      "F1 0.5082850264148032\n",
      "468\n",
      "468\n",
      "71744\n",
      "48938\n",
      "Acc: 0.6821197591436218\n",
      "Prec 0.5485754238454946\n",
      "Recall 0.5166932314545581\n",
      "F1 0.5321572300715913\n",
      "Epoch: 98, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48234\n",
      "Acc: 0.6611019736842105\n",
      "Prec 0.5372998390988796\n",
      "Recall 0.49059517556540855\n",
      "F1 0.5128864429410073\n",
      "468\n",
      "468\n",
      "71744\n",
      "48519\n",
      "Acc: 0.6762795495093666\n",
      "Prec 0.534771684271452\n",
      "Recall 0.520215032615844\n",
      "F1 0.5273929324837611\n",
      "Epoch: 99, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48036\n",
      "Acc: 0.6583881578947368\n",
      "Prec 0.5333788070774981\n",
      "Recall 0.4936892223500778\n",
      "F1 0.5127671409085967\n",
      "468\n",
      "468\n",
      "71744\n",
      "49039\n",
      "Acc: 0.6835275423728814\n",
      "Prec 0.5521155281485853\n",
      "Recall 0.5087136370230874\n",
      "F1 0.5295267279646049\n",
      "Epoch: 100, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.872s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47622\n",
      "Acc: 0.6527138157894737\n",
      "Prec 0.5279465965392923\n",
      "Recall 0.47563712220555027\n",
      "F1 0.5004286043424898\n",
      "468\n",
      "468\n",
      "71744\n",
      "48420\n",
      "Acc: 0.6748996431757359\n",
      "Prec 0.5361589670603217\n",
      "Recall 0.515511271678483\n",
      "F1 0.5256324287783419\n",
      "Epoch: 101, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47707\n",
      "Acc: 0.6538788377192982\n",
      "Prec 0.5288386145447077\n",
      "Recall 0.48138815377956307\n",
      "F1 0.5039990075204636\n",
      "468\n",
      "468\n",
      "71744\n",
      "48845\n",
      "Acc: 0.6808234834968778\n",
      "Prec 0.5466249360213397\n",
      "Recall 0.5124393680564858\n",
      "F1 0.5289804135596817\n",
      "Epoch: 102, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47846\n",
      "Acc: 0.6557839912280702\n",
      "Prec 0.5319759763467421\n",
      "Recall 0.48273115446965376\n",
      "F1 0.5061586134816479\n",
      "468\n",
      "468\n",
      "71744\n",
      "48638\n",
      "Acc: 0.6779382247992863\n",
      "Prec 0.5464504338406655\n",
      "Recall 0.5050557739405949\n",
      "F1 0.5249383118068733\n",
      "Epoch: 103, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47393\n",
      "Acc: 0.6495751096491228\n",
      "Prec 0.5224922746144044\n",
      "Recall 0.47652080003323416\n",
      "F1 0.49844880518357043\n",
      "468\n",
      "468\n",
      "71744\n",
      "48761\n",
      "Acc: 0.6796526538804639\n",
      "Prec 0.5528511470994629\n",
      "Recall 0.5001935922295583\n",
      "F1 0.5252057978317488\n",
      "Epoch: 104, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47943\n",
      "Acc: 0.6571134868421052\n",
      "Prec 0.5319465463410823\n",
      "Recall 0.48431403245247023\n",
      "F1 0.5070140125152887\n",
      "468\n",
      "468\n",
      "71744\n",
      "48988\n",
      "Acc: 0.6828166815343444\n",
      "Prec 0.5493647940982813\n",
      "Recall 0.5158703149675037\n",
      "F1 0.5320909664948649\n",
      "Epoch: 105, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48149\n",
      "Acc: 0.6599369517543859\n",
      "Prec 0.5363488879160743\n",
      "Recall 0.4865121011490368\n",
      "F1 0.5102163973376214\n",
      "468\n",
      "468\n",
      "71744\n",
      "48715\n",
      "Acc: 0.6790114852809991\n",
      "Prec 0.5431793213340601\n",
      "Recall 0.5183982512621071\n",
      "F1 0.5304995462793778\n",
      "Epoch: 106, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47958\n",
      "Acc: 0.6573190789473684\n",
      "Prec 0.5317601967234865\n",
      "Recall 0.48688299675026164\n",
      "F1 0.5083330449601873\n",
      "468\n",
      "468\n",
      "71744\n",
      "48787\n",
      "Acc: 0.6800150535236396\n",
      "Prec 0.5469358366536683\n",
      "Recall 0.5073541272769273\n",
      "F1 0.5264019644981942\n",
      "Epoch: 107, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.880s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47361\n",
      "Acc: 0.6491365131578948\n",
      "Prec 0.5218337684092346\n",
      "Recall 0.47366170771507377\n",
      "F1 0.4965822142164023\n",
      "468\n",
      "468\n",
      "71744\n",
      "48229\n",
      "Acc: 0.6722373996431757\n",
      "Prec 0.5387050397601691\n",
      "Recall 0.4985666078087129\n",
      "F1 0.5178592221472046\n",
      "Epoch: 108, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47364\n",
      "Acc: 0.6491776315789474\n",
      "Prec 0.5203862512445393\n",
      "Recall 0.4723756400165395\n",
      "F1 0.4952200334265273\n",
      "468\n",
      "468\n",
      "71744\n",
      "48612\n",
      "Acc: 0.6775758251561106\n",
      "Prec 0.5542524741946601\n",
      "Recall 0.4984600233952674\n",
      "F1 0.5248777836046439\n",
      "Epoch: 109, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.882s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47844\n",
      "Acc: 0.6557565789473684\n",
      "Prec 0.5315091152310096\n",
      "Recall 0.4849166777981975\n",
      "F1 0.5071450097879884\n",
      "468\n",
      "468\n",
      "71744\n",
      "48959\n",
      "Acc: 0.6824124665477252\n",
      "Prec 0.554213901393475\n",
      "Recall 0.509173005792594\n",
      "F1 0.5307395758168365\n",
      "Epoch: 110, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47976\n",
      "Acc: 0.6575657894736842\n",
      "Prec 0.5325127092885321\n",
      "Recall 0.4882765243012601\n",
      "F1 0.5094361231128328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "71744\n",
      "48679\n",
      "Acc: 0.6785097011596789\n",
      "Prec 0.5493532233462352\n",
      "Recall 0.502440021916869\n",
      "F1 0.524850386368739\n",
      "Epoch: 111, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47858\n",
      "Acc: 0.6559484649122806\n",
      "Prec 0.5306912586896619\n",
      "Recall 0.4837285262896702\n",
      "F1 0.5061228187421257\n",
      "468\n",
      "468\n",
      "71744\n",
      "49087\n",
      "Acc: 0.684196587867975\n",
      "Prec 0.5457796460160734\n",
      "Recall 0.5191949539254911\n",
      "F1 0.532155486492043\n",
      "Epoch: 112, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48060\n",
      "Acc: 0.6587171052631579\n",
      "Prec 0.5337886889160118\n",
      "Recall 0.48706767773846926\n",
      "F1 0.5093590550165626\n",
      "468\n",
      "468\n",
      "71744\n",
      "49070\n",
      "Acc: 0.6839596342551294\n",
      "Prec 0.5575233337697708\n",
      "Recall 0.5100536239565768\n",
      "F1 0.5327331107543735\n",
      "Epoch: 113, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47911\n",
      "Acc: 0.6566748903508772\n",
      "Prec 0.5328337694307039\n",
      "Recall 0.4839741002628079\n",
      "F1 0.5072300320169539\n",
      "468\n",
      "468\n",
      "71744\n",
      "48295\n",
      "Acc: 0.6731573371989296\n",
      "Prec 0.5475014864179546\n",
      "Recall 0.49073987633477706\n",
      "F1 0.5175690766653513\n",
      "Epoch: 114, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.864s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47664\n",
      "Acc: 0.6532894736842105\n",
      "Prec 0.5294965206475447\n",
      "Recall 0.4782405383704102\n",
      "F1 0.5025650269257967\n",
      "468\n",
      "468\n",
      "71744\n",
      "48730\n",
      "Acc: 0.6792205619982159\n",
      "Prec 0.5484271092012463\n",
      "Recall 0.5125359200775916\n",
      "F1 0.5298744353062279\n",
      "Epoch: 115, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47676\n",
      "Acc: 0.6534539473684211\n",
      "Prec 0.5305019901857989\n",
      "Recall 0.48000651610890355\n",
      "F1 0.5039926146325011\n",
      "468\n",
      "468\n",
      "71744\n",
      "48575\n",
      "Acc: 0.6770601025869759\n",
      "Prec 0.5449933572114221\n",
      "Recall 0.5066005132146458\n",
      "F1 0.5250960893296495\n",
      "Epoch: 116, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48013\n",
      "Acc: 0.6580729166666667\n",
      "Prec 0.5341331780827564\n",
      "Recall 0.48550490108792416\n",
      "F1 0.5086594569001734\n",
      "468\n",
      "468\n",
      "71744\n",
      "49179\n",
      "Acc: 0.6854789250669046\n",
      "Prec 0.5529578086523949\n",
      "Recall 0.5192649497068521\n",
      "F1 0.5355820074911968\n",
      "Epoch: 117, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47847\n",
      "Acc: 0.6557976973684211\n",
      "Prec 0.5312330527506329\n",
      "Recall 0.4850254790459157\n",
      "F1 0.5070787753976423\n",
      "468\n",
      "468\n",
      "71744\n",
      "48471\n",
      "Acc: 0.6756105040142729\n",
      "Prec 0.5496439977730988\n",
      "Recall 0.4941891745138369\n",
      "F1 0.5204435358973359\n",
      "Epoch: 118, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47731\n",
      "Acc: 0.6542077850877193\n",
      "Prec 0.5313888617910468\n",
      "Recall 0.4788490593778609\n",
      "F1 0.5037527325010621\n",
      "468\n",
      "468\n",
      "71744\n",
      "48898\n",
      "Acc: 0.6815622212310437\n",
      "Prec 0.5491588004564257\n",
      "Recall 0.5174121586978019\n",
      "F1 0.5328130078422048\n",
      "Epoch: 119, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47952\n",
      "Acc: 0.6572368421052631\n",
      "Prec 0.5362901231354504\n",
      "Recall 0.4843606845706419\n",
      "F1 0.5090043513592374\n",
      "468\n",
      "468\n",
      "71744\n",
      "48928\n",
      "Acc: 0.6819803746654772\n",
      "Prec 0.552273576760873\n",
      "Recall 0.5115409239541275\n",
      "F1 0.5311274391199398\n",
      "Epoch: 120, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48282\n",
      "Acc: 0.6617598684210526\n",
      "Prec 0.5394835774855234\n",
      "Recall 0.49330863030008\n",
      "F1 0.5153638896044358\n",
      "468\n",
      "468\n",
      "71744\n",
      "49328\n",
      "Acc: 0.6875557537912578\n",
      "Prec 0.5623070389860451\n",
      "Recall 0.5167523750304482\n",
      "F1 0.5385681161166094\n",
      "Epoch: 121, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.886s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47588\n",
      "Acc: 0.6522478070175438\n",
      "Prec 0.5254790019678882\n",
      "Recall 0.4792903480273361\n",
      "F1 0.5013230424185281\n",
      "468\n",
      "468\n",
      "71744\n",
      "48825\n",
      "Acc: 0.6805447145405887\n",
      "Prec 0.5534811018675024\n",
      "Recall 0.5063043015086587\n",
      "F1 0.5288426539685102\n",
      "Epoch: 122, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.894s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47900\n",
      "Acc: 0.6565241228070176\n",
      "Prec 0.5317150860674987\n",
      "Recall 0.4911637147526984\n",
      "F1 0.5106355839099461\n",
      "468\n",
      "468\n",
      "71744\n",
      "48821\n",
      "Acc: 0.680488960749331\n",
      "Prec 0.5578096692237212\n",
      "Recall 0.49710058464720425\n",
      "F1 0.5257082518166578\n",
      "Epoch: 123, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.895s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47721\n",
      "Acc: 0.6540707236842105\n",
      "Prec 0.5313558792572474\n",
      "Recall 0.480057770036089\n",
      "F1 0.5044059246580709\n",
      "468\n",
      "468\n",
      "71744\n",
      "48315\n",
      "Acc: 0.6734361061552185\n",
      "Prec 0.5393122551240731\n",
      "Recall 0.5095012977382946\n",
      "F1 0.5239831104812963\n",
      "Epoch: 124, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47808\n",
      "Acc: 0.6552631578947369\n",
      "Prec 0.5284322478951898\n",
      "Recall 0.48279721236067\n",
      "F1 0.5045850150384833\n",
      "468\n",
      "468\n",
      "71744\n",
      "48590\n",
      "Acc: 0.6772691793041927\n",
      "Prec 0.5424371583428577\n",
      "Recall 0.5209282389012705\n",
      "F1 0.5314651658639249\n",
      "Epoch: 125, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48270\n",
      "Acc: 0.6615953947368421\n",
      "Prec 0.5384820418012736\n",
      "Recall 0.49168359637611636\n",
      "F1 0.5140198373636949\n",
      "468\n",
      "468\n",
      "71744\n",
      "49090\n",
      "Acc: 0.6842384032114184\n",
      "Prec 0.5527085616854298\n",
      "Recall 0.524806659167299\n",
      "F1 0.5383963551284972\n",
      "Epoch: 126, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47724\n",
      "Acc: 0.6541118421052632\n",
      "Prec 0.5261163373711986\n",
      "Recall 0.48339646370898676\n",
      "F1 0.5038525053127303\n",
      "468\n",
      "468\n",
      "71744\n",
      "49056\n",
      "Acc: 0.6837644959857271\n",
      "Prec 0.5537950141777089\n",
      "Recall 0.5207471794699318\n",
      "F1 0.5367628992931281\n",
      "Epoch: 127, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47902\n",
      "Acc: 0.6565515350877194\n",
      "Prec 0.5327096689981828\n",
      "Recall 0.48813789665767127\n",
      "F1 0.5094507468152988\n",
      "468\n",
      "468\n",
      "71744\n",
      "48576\n",
      "Acc: 0.6770740410347904\n",
      "Prec 0.5537786214959645\n",
      "Recall 0.4914015242173448\n",
      "F1 0.52072871800751\n",
      "Epoch: 128, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.879s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47590\n",
      "Acc: 0.6522752192982456\n",
      "Prec 0.5285637329662997\n",
      "Recall 0.48341050578419464\n",
      "F1 0.5049797745996152\n",
      "468\n",
      "468\n",
      "71744\n",
      "48583\n",
      "Acc: 0.6771716101694916\n",
      "Prec 0.5536916734343915\n",
      "Recall 0.49266515630254776\n",
      "F1 0.5213987945289247\n",
      "Epoch: 129, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47176\n",
      "Acc: 0.6466008771929824\n",
      "Prec 0.5217020072434124\n",
      "Recall 0.4686245526719926\n",
      "F1 0.4937409126811843\n",
      "468\n",
      "468\n",
      "71744\n",
      "47733\n",
      "Acc: 0.6653239295272079\n",
      "Prec 0.5457830980096346\n",
      "Recall 0.4655729254576854\n",
      "F1 0.5024972961243555\n",
      "Epoch: 130, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47416\n",
      "Acc: 0.6498903508771929\n",
      "Prec 0.5279771648797716\n",
      "Recall 0.47284754731513373\n",
      "F1 0.498893970961779\n",
      "468\n",
      "468\n",
      "71744\n",
      "48480\n",
      "Acc: 0.6757359500446031\n",
      "Prec 0.5533540980688288\n",
      "Recall 0.4899785863798784\n",
      "F1 0.5197415221062345\n",
      "Epoch: 131, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47532\n",
      "Acc: 0.6514802631578948\n",
      "Prec 0.5267824279261938\n",
      "Recall 0.47529090289431625\n",
      "F1 0.49971371973923434\n",
      "468\n",
      "468\n",
      "71744\n",
      "48317\n",
      "Acc: 0.6734639830508474\n",
      "Prec 0.5483871124144698\n",
      "Recall 0.49287518269969516\n",
      "F1 0.5191514174472353\n",
      "Epoch: 132, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47501\n",
      "Acc: 0.6510553728070175\n",
      "Prec 0.5297257241381476\n",
      "Recall 0.47356252742313226\n",
      "F1 0.5000721425244118\n",
      "468\n",
      "468\n",
      "71744\n",
      "48445\n",
      "Acc: 0.6752481043710973\n",
      "Prec 0.5487803172392769\n",
      "Recall 0.49701237643764634\n",
      "F1 0.5216150605419305\n",
      "Epoch: 133, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47612\n",
      "Acc: 0.652576754385965\n",
      "Prec 0.5298728788294896\n",
      "Recall 0.4790940135675909\n",
      "F1 0.5032056574144306\n",
      "468\n",
      "468\n",
      "71744\n",
      "48552\n",
      "Acc: 0.6767395182872435\n",
      "Prec 0.5511996788242648\n",
      "Recall 0.5017675715207933\n",
      "F1 0.5253233168952957\n",
      "Epoch: 134, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47601\n",
      "Acc: 0.6524259868421053\n",
      "Prec 0.528286652730995\n",
      "Recall 0.47642626657469184\n",
      "F1 0.5010180177951735\n",
      "468\n",
      "468\n",
      "71744\n",
      "48477\n",
      "Acc: 0.6756941347011597\n",
      "Prec 0.5473534369639037\n",
      "Recall 0.5048481464359931\n",
      "F1 0.5252422586244591\n",
      "Epoch: 135, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47760\n",
      "Acc: 0.6546052631578947\n",
      "Prec 0.5312410937215911\n",
      "Recall 0.4782604848488818\n",
      "F1 0.5033605265178925\n",
      "468\n",
      "468\n",
      "71744\n",
      "48514\n",
      "Acc: 0.6762098572702944\n",
      "Prec 0.5473593686442053\n",
      "Recall 0.5052489417919882\n",
      "F1 0.5254618247747141\n",
      "Epoch: 136, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.872s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47799\n",
      "Acc: 0.6551398026315789\n",
      "Prec 0.5321813057685078\n",
      "Recall 0.48087130310504006\n",
      "F1 0.5052269067795029\n",
      "468\n",
      "468\n",
      "71744\n",
      "48767\n",
      "Acc: 0.6797362845673506\n",
      "Prec 0.5498854155890415\n",
      "Recall 0.5128350100572227\n",
      "F1 0.5307143550241548\n",
      "Epoch: 137, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.879s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48085\n",
      "Acc: 0.6590597587719298\n",
      "Prec 0.5386268041977788\n",
      "Recall 0.4878967599048347\n",
      "F1 0.512008261195108\n",
      "468\n",
      "468\n",
      "71744\n",
      "48968\n",
      "Acc: 0.6825379125780553\n",
      "Prec 0.552871762738738\n",
      "Recall 0.5186320914477484\n",
      "F1 0.5352048664898051\n",
      "Epoch: 138, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.872s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "48035\n",
      "Acc: 0.6583744517543859\n",
      "Prec 0.5332087942555589\n",
      "Recall 0.48854095481318455\n",
      "F1 0.5098985024421504\n",
      "468\n",
      "468\n",
      "71744\n",
      "48454\n",
      "Acc: 0.6753735504014273\n",
      "Prec 0.5545919598878691\n",
      "Recall 0.4901137980973327\n",
      "F1 0.5203631161736879\n",
      "Epoch: 139, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47822\n",
      "Acc: 0.6554550438596491\n",
      "Prec 0.5307470666521487\n",
      "Recall 0.4852547537364944\n",
      "F1 0.5069824324254412\n",
      "468\n",
      "468\n",
      "71744\n",
      "48407\n",
      "Acc: 0.6747184433541481\n",
      "Prec 0.5504834332789489\n",
      "Recall 0.4911483538978716\n",
      "F1 0.5191259242112751\n",
      "Epoch: 140, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47592\n",
      "Acc: 0.6523026315789474\n",
      "Prec 0.5256781204961835\n",
      "Recall 0.48136606922953123\n",
      "F1 0.5025471833805751\n",
      "468\n",
      "468\n",
      "71744\n",
      "48815\n",
      "Acc: 0.6804053300624442\n",
      "Prec 0.5529530489081086\n",
      "Recall 0.5038827997338533\n",
      "F1 0.5272787268963678\n",
      "Epoch: 141, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.880s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48023\n",
      "Acc: 0.6582099780701754\n",
      "Prec 0.536123890557644\n",
      "Recall 0.4836919531634709\n",
      "F1 0.5085600765236604\n",
      "468\n",
      "468\n",
      "71744\n",
      "48911\n",
      "Acc: 0.6817434210526315\n",
      "Prec 0.5535421866476483\n",
      "Recall 0.5134972313705273\n",
      "F1 0.5327682848273434\n",
      "Epoch: 142, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47990\n",
      "Acc: 0.6577576754385965\n",
      "Prec 0.5322659262708351\n",
      "Recall 0.49092235952478647\n",
      "F1 0.5107588662752115\n",
      "468\n",
      "468\n",
      "71744\n",
      "49128\n",
      "Acc: 0.6847680642283676\n",
      "Prec 0.5575714582737772\n",
      "Recall 0.5109982162981058\n",
      "F1 0.5332698979143029\n",
      "Epoch: 143, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.773s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48119\n",
      "Acc: 0.6595257675438596\n",
      "Prec 0.5395282370441477\n",
      "Recall 0.492290524037821\n",
      "F1 0.5148280852523969\n",
      "468\n",
      "468\n",
      "71744\n",
      "48984\n",
      "Acc: 0.6827609277430865\n",
      "Prec 0.5552314495428837\n",
      "Recall 0.5111003173070144\n",
      "F1 0.5322526794423963\n",
      "Epoch: 144, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48151\n",
      "Acc: 0.6599643640350877\n",
      "Prec 0.5380666800289303\n",
      "Recall 0.49054507492302707\n",
      "F1 0.5132081343571735\n",
      "468\n",
      "468\n",
      "71744\n",
      "48819\n",
      "Acc: 0.6804610838537021\n",
      "Prec 0.5511681944874056\n",
      "Recall 0.513182897667538\n",
      "F1 0.5314977233246563\n",
      "Epoch: 145, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47716\n",
      "Acc: 0.6540021929824561\n",
      "Prec 0.5284004181460807\n",
      "Recall 0.4798398260085175\n",
      "F1 0.5029506929048265\n",
      "468\n",
      "468\n",
      "71744\n",
      "48536\n",
      "Acc: 0.6765165031222123\n",
      "Prec 0.5516764685291831\n",
      "Recall 0.49850890782765794\n",
      "F1 0.5237468355439282\n",
      "Epoch: 146, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.883s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48141\n",
      "Acc: 0.659827302631579\n",
      "Prec 0.5371741338256228\n",
      "Recall 0.4893443475136093\n",
      "F1 0.5121449458467561\n",
      "468\n",
      "468\n",
      "71744\n",
      "49174\n",
      "Acc: 0.6854092328278323\n",
      "Prec 0.5598365597405236\n",
      "Recall 0.5165087554324915\n",
      "F1 0.5373005867930125\n",
      "Epoch: 147, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48276\n",
      "Acc: 0.6616776315789473\n",
      "Prec 0.5398591777747396\n",
      "Recall 0.4969739015191692\n",
      "F1 0.5175296336655358\n",
      "468\n",
      "468\n",
      "71744\n",
      "49075\n",
      "Acc: 0.6840293264942016\n",
      "Prec 0.556854359325686\n",
      "Recall 0.5084756507432898\n",
      "F1 0.5315665193906127\n",
      "Epoch: 148, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47923\n",
      "Acc: 0.6568393640350877\n",
      "Prec 0.5316362116401379\n",
      "Recall 0.4892326848810797\n",
      "F1 0.5095537969410645\n",
      "468\n",
      "468\n",
      "71744\n",
      "48812\n",
      "Acc: 0.6803635147190009\n",
      "Prec 0.5546215172055514\n",
      "Recall 0.5054812544448058\n",
      "F1 0.5289124559549946\n",
      "Epoch: 149, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48358\n",
      "Acc: 0.6628015350877193\n",
      "Prec 0.5407957416723131\n",
      "Recall 0.49118707743805107\n",
      "F1 0.5147990352629291\n",
      "468\n",
      "468\n",
      "71744\n",
      "49134\n",
      "Acc: 0.6848516949152542\n",
      "Prec 0.5598277360867162\n",
      "Recall 0.5172535655035077\n",
      "F1 0.5376992287046105\n",
      "Epoch: 150, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47988\n",
      "Acc: 0.6577302631578947\n",
      "Prec 0.5356625089457491\n",
      "Recall 0.48982854178072094\n",
      "F1 0.5117212587230743\n",
      "468\n",
      "468\n",
      "71744\n",
      "48982\n",
      "Acc: 0.6827330508474576\n",
      "Prec 0.555190315017258\n",
      "Recall 0.5113570689245712\n",
      "F1 0.5323729568081125\n",
      "Epoch: 151, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48191\n",
      "Acc: 0.6605126096491228\n",
      "Prec 0.537656990882642\n",
      "Recall 0.4872677678488175\n",
      "F1 0.5112237158558858\n",
      "468\n",
      "468\n",
      "71744\n",
      "49075\n",
      "Acc: 0.6840293264942016\n",
      "Prec 0.5594590364777169\n",
      "Recall 0.5125359222293128\n",
      "F1 0.5349705255265004\n",
      "Epoch: 152, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48281\n",
      "Acc: 0.6617461622807017\n",
      "Prec 0.5399052751560562\n",
      "Recall 0.4916020674846166\n",
      "F1 0.5146227051241204\n",
      "468\n",
      "468\n",
      "71744\n",
      "48847\n",
      "Acc: 0.6808513603925067\n",
      "Prec 0.5592477067768534\n",
      "Recall 0.5008660323672779\n",
      "F1 0.5284492968272688\n",
      "Epoch: 153, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.899s\n",
      "468\n",
      "468\n",
      "72960\n",
      "47984\n",
      "Acc: 0.6576754385964912\n",
      "Prec 0.5350557027257387\n",
      "Recall 0.4840230771308753\n",
      "F1 0.5082616040855521\n",
      "468\n",
      "468\n",
      "71744\n",
      "48829\n",
      "Acc: 0.6806004683318466\n",
      "Prec 0.5598048031202671\n",
      "Recall 0.4995594803886531\n",
      "F1 0.5279690865913134\n",
      "Epoch: 154, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48103\n",
      "Acc: 0.6593064692982457\n",
      "Prec 0.5365078426612255\n",
      "Recall 0.4898337491646479\n",
      "F1 0.5121095162078769\n",
      "468\n",
      "468\n",
      "71744\n",
      "48662\n",
      "Acc: 0.6782727475468332\n",
      "Prec 0.5579992520398124\n",
      "Recall 0.4960250915304145\n",
      "F1 0.5251902041074813\n",
      "Epoch: 155, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48286\n",
      "Acc: 0.6618146929824561\n",
      "Prec 0.54451863838989\n",
      "Recall 0.4884436794511018\n",
      "F1 0.5149591280749957\n",
      "468\n",
      "468\n",
      "71744\n",
      "48728\n",
      "Acc: 0.679192685102587\n",
      "Prec 0.5554119899679201\n",
      "Recall 0.5050091126343482\n",
      "F1 0.5290127016745713\n",
      "Epoch: 156, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48542\n",
      "Acc: 0.6653234649122807\n",
      "Prec 0.5430114597199994\n",
      "Recall 0.49812081897258503\n",
      "F1 0.5195983614433518\n",
      "468\n",
      "468\n",
      "71744\n",
      "49093\n",
      "Acc: 0.6842802185548618\n",
      "Prec 0.5625328535277072\n",
      "Recall 0.5088353637008881\n",
      "F1 0.5343384366187441\n",
      "Epoch: 157, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48735\n",
      "Acc: 0.66796875\n",
      "Prec 0.5463008426955468\n",
      "Recall 0.5026939003892757\n",
      "F1 0.5235909964486188\n",
      "468\n",
      "468\n",
      "71744\n",
      "49094\n",
      "Acc: 0.6842941570026762\n",
      "Prec 0.563877181355508\n",
      "Recall 0.5074185169214093\n",
      "F1 0.534160126936825\n",
      "Epoch: 158, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48569\n",
      "Acc: 0.6656935307017544\n",
      "Prec 0.5442504294058149\n",
      "Recall 0.4993064776775675\n",
      "F1 0.5208106295623566\n",
      "468\n",
      "468\n",
      "71744\n",
      "49362\n",
      "Acc: 0.6880296610169492\n",
      "Prec 0.5655256995985803\n",
      "Recall 0.5187611318501463\n",
      "F1 0.541134953418418\n",
      "Epoch: 159, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48338\n",
      "Acc: 0.6625274122807018\n",
      "Prec 0.5413894575761388\n",
      "Recall 0.4976261461896299\n",
      "F1 0.5185861470893609\n",
      "468\n",
      "468\n",
      "71744\n",
      "49001\n",
      "Acc: 0.6829978813559322\n",
      "Prec 0.5626918722428452\n",
      "Recall 0.5032747524194999\n",
      "F1 0.5313273532952975\n",
      "Epoch: 160, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48383\n",
      "Acc: 0.6631441885964913\n",
      "Prec 0.541781148566702\n",
      "Recall 0.48808836973820197\n",
      "F1 0.5135351087855436\n",
      "468\n",
      "468\n",
      "71744\n",
      "49160\n",
      "Acc: 0.68521409455843\n",
      "Prec 0.5593684068352663\n",
      "Recall 0.520037031722448\n",
      "F1 0.5389861409603653\n",
      "Epoch: 161, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48677\n",
      "Acc: 0.6671737938596491\n",
      "Prec 0.5455642479406694\n",
      "Recall 0.5007941545020239\n",
      "F1 0.5222214217158608\n",
      "468\n",
      "468\n",
      "71744\n",
      "49027\n",
      "Acc: 0.683360280999108\n",
      "Prec 0.5602611603099715\n",
      "Recall 0.5113726665468785\n",
      "F1 0.5347017541442906\n",
      "Epoch: 162, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48888\n",
      "Acc: 0.6700657894736842\n",
      "Prec 0.5481734255079814\n",
      "Recall 0.5056327601580124\n",
      "F1 0.5260444395848788\n",
      "468\n",
      "468\n",
      "71744\n",
      "49531\n",
      "Acc: 0.6903852586975915\n",
      "Prec 0.5684615458920157\n",
      "Recall 0.5242657662022081\n",
      "F1 0.5454698983269691\n",
      "Epoch: 163, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49014\n",
      "Acc: 0.6717927631578947\n",
      "Prec 0.5513931789583998\n",
      "Recall 0.5089276935957557\n",
      "F1 0.5293100722534304\n",
      "468\n",
      "468\n",
      "71744\n",
      "49571\n",
      "Acc: 0.6909427966101694\n",
      "Prec 0.5667678047703452\n",
      "Recall 0.5317529999508956\n",
      "F1 0.548702362607857\n",
      "Epoch: 164, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.878s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49044\n",
      "Acc: 0.672203947368421\n",
      "Prec 0.551984637373888\n",
      "Recall 0.5112151428312797\n",
      "F1 0.5308182158978831\n",
      "468\n",
      "468\n",
      "71744\n",
      "49598\n",
      "Acc: 0.6913191347011597\n",
      "Prec 0.5695253036639532\n",
      "Recall 0.5223934555481039\n",
      "F1 0.5449421743020285\n",
      "Epoch: 165, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.880s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48824\n",
      "Acc: 0.6691885964912281\n",
      "Prec 0.5472734494882816\n",
      "Recall 0.5042489085477213\n",
      "F1 0.5248809737094793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "71744\n",
      "49387\n",
      "Acc: 0.6883781222123104\n",
      "Prec 0.5687832397410325\n",
      "Recall 0.5210203110623168\n",
      "F1 0.5438551200873813\n",
      "Epoch: 166, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48710\n",
      "Acc: 0.6676260964912281\n",
      "Prec 0.5454538890098692\n",
      "Recall 0.5038075435005903\n",
      "F1 0.5238042215225832\n",
      "468\n",
      "468\n",
      "71744\n",
      "49181\n",
      "Acc: 0.6855068019625334\n",
      "Prec 0.5646558228617963\n",
      "Recall 0.5098335081074871\n",
      "F1 0.5358461005531922\n",
      "Epoch: 167, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48765\n",
      "Acc: 0.6683799342105263\n",
      "Prec 0.5485627285272382\n",
      "Recall 0.5008695056154396\n",
      "F1 0.5236323674790783\n",
      "468\n",
      "468\n",
      "71744\n",
      "49319\n",
      "Acc: 0.6874303077609277\n",
      "Prec 0.5624937431104582\n",
      "Recall 0.5200386906550721\n",
      "F1 0.5404337099652958\n",
      "Epoch: 168, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48908\n",
      "Acc: 0.6703399122807018\n",
      "Prec 0.5489519256463694\n",
      "Recall 0.5060171082683501\n",
      "F1 0.5266108427147882\n",
      "468\n",
      "468\n",
      "71744\n",
      "49455\n",
      "Acc: 0.6893259366636931\n",
      "Prec 0.566334306191003\n",
      "Recall 0.5205146145483058\n",
      "F1 0.5424586204529143\n",
      "Epoch: 169, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49166\n",
      "Acc: 0.673876096491228\n",
      "Prec 0.5536018597037823\n",
      "Recall 0.5141750750538664\n",
      "F1 0.5331605665892349\n",
      "468\n",
      "468\n",
      "71744\n",
      "49289\n",
      "Acc: 0.6870121543264942\n",
      "Prec 0.5681556164676088\n",
      "Recall 0.5114030511001112\n",
      "F1 0.5382875882342417\n",
      "Epoch: 170, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49011\n",
      "Acc: 0.6717516447368421\n",
      "Prec 0.5513676638156756\n",
      "Recall 0.5075159271020466\n",
      "F1 0.5285337755266915\n",
      "468\n",
      "468\n",
      "71744\n",
      "49381\n",
      "Acc: 0.6882944915254238\n",
      "Prec 0.5644992042150278\n",
      "Recall 0.5214315434859588\n",
      "F1 0.5421113491327104\n",
      "Epoch: 171, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48832\n",
      "Acc: 0.6692982456140351\n",
      "Prec 0.5463538873992778\n",
      "Recall 0.5038921231006996\n",
      "F1 0.5242646342543733\n",
      "468\n",
      "468\n",
      "71744\n",
      "49404\n",
      "Acc: 0.6886150758251561\n",
      "Prec 0.5675936636372576\n",
      "Recall 0.5256516440906208\n",
      "F1 0.5458181075323815\n",
      "Epoch: 172, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48840\n",
      "Acc: 0.6694078947368421\n",
      "Prec 0.5468151629167987\n",
      "Recall 0.5085635922037369\n",
      "F1 0.5269961749280766\n",
      "468\n",
      "468\n",
      "71744\n",
      "49419\n",
      "Acc: 0.6888241525423728\n",
      "Prec 0.5700814469230849\n",
      "Recall 0.5162562956972097\n",
      "F1 0.5418354246338402\n",
      "Epoch: 173, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.892s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48433\n",
      "Acc: 0.663829495614035\n",
      "Prec 0.5390072394515911\n",
      "Recall 0.5002053074502307\n",
      "F1 0.5188818836561924\n",
      "468\n",
      "468\n",
      "71744\n",
      "48981\n",
      "Acc: 0.6827191123996432\n",
      "Prec 0.5633448925977961\n",
      "Recall 0.5054119337712909\n",
      "F1 0.5328082581990564\n",
      "Epoch: 174, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.871s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49043\n",
      "Acc: 0.6721902412280701\n",
      "Prec 0.5513979890957613\n",
      "Recall 0.5066582657462594\n",
      "F1 0.5280822217396113\n",
      "468\n",
      "468\n",
      "71744\n",
      "49532\n",
      "Acc: 0.6903991971454059\n",
      "Prec 0.5647720335900454\n",
      "Recall 0.5341988824785003\n",
      "F1 0.5490601885593385\n",
      "Epoch: 175, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.871s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49341\n",
      "Acc: 0.6762746710526316\n",
      "Prec 0.5563506777407138\n",
      "Recall 0.5128402006224609\n",
      "F1 0.5337101147473029\n",
      "468\n",
      "468\n",
      "71744\n",
      "49684\n",
      "Acc: 0.6925178412132025\n",
      "Prec 0.5686522076798218\n",
      "Recall 0.5353668724092818\n",
      "F1 0.5515077762779406\n",
      "Epoch: 176, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49341\n",
      "Acc: 0.6762746710526316\n",
      "Prec 0.5549288253536346\n",
      "Recall 0.5201237060368281\n",
      "F1 0.5369628530733894\n",
      "468\n",
      "468\n",
      "71744\n",
      "49416\n",
      "Acc: 0.6887823371989296\n",
      "Prec 0.5658630268812391\n",
      "Recall 0.5224654591298685\n",
      "F1 0.5432989946403118\n",
      "Epoch: 177, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49190\n",
      "Acc: 0.6742050438596491\n",
      "Prec 0.5539829677559583\n",
      "Recall 0.5148162321220386\n",
      "F1 0.5336819566340668\n",
      "468\n",
      "468\n",
      "71744\n",
      "49479\n",
      "Acc: 0.68966045941124\n",
      "Prec 0.5683055743400097\n",
      "Recall 0.5225089618424127\n",
      "F1 0.5444459086452713\n",
      "Epoch: 178, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49138\n",
      "Acc: 0.6734923245614035\n",
      "Prec 0.5541358623058081\n",
      "Recall 0.5109291170520758\n",
      "F1 0.5316561005047592\n",
      "468\n",
      "468\n",
      "71744\n",
      "49603\n",
      "Acc: 0.691388826940232\n",
      "Prec 0.5664576324519287\n",
      "Recall 0.5342809988763492\n",
      "F1 0.5498990242985093\n",
      "Epoch: 179, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49130\n",
      "Acc: 0.6733826754385965\n",
      "Prec 0.552932239125524\n",
      "Recall 0.512145414702343\n",
      "F1 0.531757867403353\n",
      "468\n",
      "468\n",
      "71744\n",
      "49369\n",
      "Acc: 0.6881272301516503\n",
      "Prec 0.5665999411060595\n",
      "Recall 0.5219253320971906\n",
      "F1 0.5433458821912189\n",
      "Epoch: 180, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49096\n",
      "Acc: 0.6729166666666667\n",
      "Prec 0.5520159803165586\n",
      "Recall 0.5106419638791114\n",
      "F1 0.5305235345412269\n",
      "468\n",
      "468\n",
      "71744\n",
      "49612\n",
      "Acc: 0.691514272970562\n",
      "Prec 0.5735935562495796\n",
      "Recall 0.5209329232571754\n",
      "F1 0.5459964169221883\n",
      "Epoch: 181, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49029\n",
      "Acc: 0.6719983552631579\n",
      "Prec 0.5506581993978282\n",
      "Recall 0.5092930359430469\n",
      "F1 0.5291684688646293\n",
      "468\n",
      "468\n",
      "71744\n",
      "49338\n",
      "Acc: 0.6876951382694023\n",
      "Prec 0.5681299951325056\n",
      "Recall 0.5140001236716266\n",
      "F1 0.5397112282252714\n",
      "Epoch: 182, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48844\n",
      "Acc: 0.6694627192982456\n",
      "Prec 0.5471673360310948\n",
      "Recall 0.5077952710617362\n",
      "F1 0.5267466047573166\n",
      "468\n",
      "468\n",
      "71744\n",
      "49261\n",
      "Acc: 0.6866218777876896\n",
      "Prec 0.5667586596245199\n",
      "Recall 0.5133094990832173\n",
      "F1 0.5387115643164899\n",
      "Epoch: 183, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48979\n",
      "Acc: 0.671313048245614\n",
      "Prec 0.5490349336861748\n",
      "Recall 0.5083458796532535\n",
      "F1 0.5279075292535516\n",
      "468\n",
      "468\n",
      "71744\n",
      "49577\n",
      "Acc: 0.6910264272970562\n",
      "Prec 0.5723194271553126\n",
      "Recall 0.5247368666627313\n",
      "F1 0.5474962490584794\n",
      "Epoch: 184, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49115\n",
      "Acc: 0.6731770833333334\n",
      "Prec 0.5541183398092634\n",
      "Recall 0.5085090354286087\n",
      "F1 0.5303348832447209\n",
      "468\n",
      "468\n",
      "71744\n",
      "49354\n",
      "Acc: 0.6879181534344335\n",
      "Prec 0.5639057292955743\n",
      "Recall 0.5257078661145663\n",
      "F1 0.5441372590916842\n",
      "Epoch: 185, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49353\n",
      "Acc: 0.6764391447368421\n",
      "Prec 0.5557542041569585\n",
      "Recall 0.5138518012880727\n",
      "F1 0.5339822278964357\n",
      "468\n",
      "468\n",
      "71744\n",
      "49992\n",
      "Acc: 0.6968108831400536\n",
      "Prec 0.5734415655395101\n",
      "Recall 0.5409409149850429\n",
      "F1 0.5567173041115725\n",
      "Epoch: 186, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49423\n",
      "Acc: 0.6773985745614035\n",
      "Prec 0.5552697882827103\n",
      "Recall 0.5196487533920032\n",
      "F1 0.5368690595434349\n",
      "468\n",
      "468\n",
      "71744\n",
      "49581\n",
      "Acc: 0.691082181088314\n",
      "Prec 0.5726773901669316\n",
      "Recall 0.5258973821046528\n",
      "F1 0.5482913824000692\n",
      "Epoch: 187, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49397\n",
      "Acc: 0.6770422149122807\n",
      "Prec 0.5577699475282728\n",
      "Recall 0.516333214757796\n",
      "F1 0.5362523083715822\n",
      "468\n",
      "468\n",
      "71744\n",
      "49413\n",
      "Acc: 0.6887405218554862\n",
      "Prec 0.5686311424890059\n",
      "Recall 0.5225586394249774\n",
      "F1 0.5446222482628575\n",
      "Epoch: 188, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49479\n",
      "Acc: 0.6781661184210527\n",
      "Prec 0.5586030262521792\n",
      "Recall 0.5186457090833435\n",
      "F1 0.5378833191322838\n",
      "468\n",
      "468\n",
      "71744\n",
      "49909\n",
      "Acc: 0.695653991971454\n",
      "Prec 0.5722175413750944\n",
      "Recall 0.5398718924990266\n",
      "F1 0.5555743226641965\n",
      "Epoch: 189, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49133\n",
      "Acc: 0.6734237938596491\n",
      "Prec 0.5524115416156362\n",
      "Recall 0.5143838087818979\n",
      "F1 0.5327198936242902\n",
      "468\n",
      "468\n",
      "71744\n",
      "49329\n",
      "Acc: 0.6875696922390723\n",
      "Prec 0.5650231214448315\n",
      "Recall 0.5208721715294816\n",
      "F1 0.542050089240597\n",
      "Epoch: 190, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49399\n",
      "Acc: 0.6770696271929825\n",
      "Prec 0.5556196816880173\n",
      "Recall 0.5188594223445264\n",
      "F1 0.5366107279368044\n",
      "468\n",
      "468\n",
      "71744\n",
      "49377\n",
      "Acc: 0.6882387377341659\n",
      "Prec 0.5686076951969196\n",
      "Recall 0.5218228062269362\n",
      "F1 0.5442115985612059\n",
      "Epoch: 191, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49271\n",
      "Acc: 0.6753152412280702\n",
      "Prec 0.5552921744208759\n",
      "Recall 0.516361999010544\n",
      "F1 0.5351199749463289\n",
      "468\n",
      "468\n",
      "71744\n",
      "49596\n",
      "Acc: 0.6912912578055308\n",
      "Prec 0.5717423091505214\n",
      "Recall 0.5293717745114197\n",
      "F1 0.5497418391956391\n",
      "Epoch: 192, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49272\n",
      "Acc: 0.6753289473684211\n",
      "Prec 0.5541544499782715\n",
      "Recall 0.5185474218922397\n",
      "F1 0.5357599700376624\n",
      "468\n",
      "468\n",
      "71744\n",
      "49738\n",
      "Acc: 0.6932705173951829\n",
      "Prec 0.5735556680405968\n",
      "Recall 0.5310127718519219\n",
      "F1 0.5514649415970171\n",
      "Epoch: 193, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.872s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "49394\n",
      "Acc: 0.6770010964912281\n",
      "Prec 0.5583910982310002\n",
      "Recall 0.5155548035835095\n",
      "F1 0.5361186489652173\n",
      "468\n",
      "468\n",
      "71744\n",
      "49604\n",
      "Acc: 0.6914027653880463\n",
      "Prec 0.567955781585539\n",
      "Recall 0.5318409078965601\n",
      "F1 0.5493053787346758\n",
      "Epoch: 194, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49282\n",
      "Acc: 0.6754660087719299\n",
      "Prec 0.5560321211444162\n",
      "Recall 0.5136747370211604\n",
      "F1 0.5340148124206302\n",
      "468\n",
      "468\n",
      "71744\n",
      "49799\n",
      "Acc: 0.6941207627118644\n",
      "Prec 0.5718053238284181\n",
      "Recall 0.5378590996050957\n",
      "F1 0.5543129799045597\n",
      "Epoch: 195, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49412\n",
      "Acc: 0.6772478070175438\n",
      "Prec 0.5573121082687525\n",
      "Recall 0.5221409372918906\n",
      "F1 0.5391535421986413\n",
      "468\n",
      "468\n",
      "71744\n",
      "49713\n",
      "Acc: 0.6929220561998216\n",
      "Prec 0.5724590369623993\n",
      "Recall 0.5324141486327002\n",
      "F1 0.5517109017851127\n",
      "Epoch: 196, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.878s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49398\n",
      "Acc: 0.6770559210526316\n",
      "Prec 0.5567853404017745\n",
      "Recall 0.5204492156409054\n",
      "F1 0.5380044523580565\n",
      "468\n",
      "468\n",
      "71744\n",
      "49638\n",
      "Acc: 0.6918766726137378\n",
      "Prec 0.5720538078467592\n",
      "Recall 0.5275399778674127\n",
      "F1 0.5488958869196328\n",
      "Epoch: 197, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49379\n",
      "Acc: 0.6767955043859649\n",
      "Prec 0.5564077722046874\n",
      "Recall 0.5157488044819053\n",
      "F1 0.5353073414068931\n",
      "468\n",
      "468\n",
      "71744\n",
      "49656\n",
      "Acc: 0.6921275646743978\n",
      "Prec 0.5722510821579095\n",
      "Recall 0.5304821547508786\n",
      "F1 0.5505755643542998\n",
      "Epoch: 198, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49466\n",
      "Acc: 0.6779879385964912\n",
      "Prec 0.5570335724371893\n",
      "Recall 0.5183079370963922\n",
      "F1 0.5369734531099437\n",
      "468\n",
      "468\n",
      "71744\n",
      "49787\n",
      "Acc: 0.693953501338091\n",
      "Prec 0.5723065394839819\n",
      "Recall 0.5364361364661908\n",
      "F1 0.5537910925130111\n",
      "Epoch: 199, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49355\n",
      "Acc: 0.6764665570175439\n",
      "Prec 0.5563396963457861\n",
      "Recall 0.5173146172228288\n",
      "F1 0.5361179169566895\n",
      "468\n",
      "468\n",
      "71744\n",
      "49756\n",
      "Acc: 0.693521409455843\n",
      "Prec 0.5725798605245896\n",
      "Recall 0.5326257274670558\n",
      "F1 0.5518806058501403\n",
      "Epoch: 200, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49391\n",
      "Acc: 0.6769599780701754\n",
      "Prec 0.5555102755818703\n",
      "Recall 0.5197749944585001\n",
      "F1 0.5370488343086222\n",
      "468\n",
      "468\n",
      "71744\n",
      "49590\n",
      "Acc: 0.691207627118644\n",
      "Prec 0.571246859951069\n",
      "Recall 0.5286143002722821\n",
      "F1 0.5491043234847044\n",
      "Epoch: 201, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.796s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49654\n",
      "Acc: 0.6805646929824561\n",
      "Prec 0.5622342868551566\n",
      "Recall 0.5239297851243562\n",
      "F1 0.5424066155396163\n",
      "468\n",
      "468\n",
      "71744\n",
      "49913\n",
      "Acc: 0.6957097457627118\n",
      "Prec 0.5740998140865071\n",
      "Recall 0.5384262694640434\n",
      "F1 0.5556910993261286\n",
      "Epoch: 202, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49567\n",
      "Acc: 0.6793722587719299\n",
      "Prec 0.5601284393681768\n",
      "Recall 0.5238921307778736\n",
      "F1 0.5414046369440073\n",
      "468\n",
      "468\n",
      "71744\n",
      "49612\n",
      "Acc: 0.691514272970562\n",
      "Prec 0.5716694950762082\n",
      "Recall 0.528439134758676\n",
      "F1 0.5492049151388656\n",
      "Epoch: 203, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49299\n",
      "Acc: 0.6756990131578947\n",
      "Prec 0.5554968996335451\n",
      "Recall 0.5166692247742394\n",
      "F1 0.5353800049534065\n",
      "468\n",
      "468\n",
      "71744\n",
      "49591\n",
      "Acc: 0.6912215655664585\n",
      "Prec 0.5726207327490148\n",
      "Recall 0.5271389719919354\n",
      "F1 0.5489393784866591\n",
      "Epoch: 204, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49435\n",
      "Acc: 0.6775630482456141\n",
      "Prec 0.5578246456099487\n",
      "Recall 0.5183738099599539\n",
      "F1 0.5373761416174198\n",
      "468\n",
      "468\n",
      "71744\n",
      "49994\n",
      "Acc: 0.6968387600356825\n",
      "Prec 0.5755734886642404\n",
      "Recall 0.5389788855532059\n",
      "F1 0.5566754235161668\n",
      "Epoch: 205, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49751\n",
      "Acc: 0.6818941885964912\n",
      "Prec 0.5627944246173743\n",
      "Recall 0.5261897346824705\n",
      "F1 0.5438768717454787\n",
      "468\n",
      "468\n",
      "71744\n",
      "49907\n",
      "Acc: 0.6956261150758252\n",
      "Prec 0.574222166278703\n",
      "Recall 0.5368460408219081\n",
      "F1 0.5549054406359883\n",
      "Epoch: 206, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49067\n",
      "Acc: 0.6725191885964912\n",
      "Prec 0.549965075331814\n",
      "Recall 0.5168528266443093\n",
      "F1 0.5328950764968705\n",
      "468\n",
      "468\n",
      "71744\n",
      "49294\n",
      "Acc: 0.6870818465655665\n",
      "Prec 0.5672518394920866\n",
      "Recall 0.5202495485581875\n",
      "F1 0.5427349641247845\n",
      "Epoch: 207, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.864s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49493\n",
      "Acc: 0.6783580043859649\n",
      "Prec 0.5608718057267442\n",
      "Recall 0.5192876145937274\n",
      "F1 0.5392792519502457\n",
      "468\n",
      "468\n",
      "71744\n",
      "50123\n",
      "Acc: 0.6986368198037467\n",
      "Prec 0.5750001079153518\n",
      "Recall 0.5473585662586803\n",
      "F1 0.5608389580073427\n",
      "Epoch: 208, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49623\n",
      "Acc: 0.6801398026315789\n",
      "Prec 0.5601221513272608\n",
      "Recall 0.5235269793705999\n",
      "F1 0.5412066501157611\n",
      "468\n",
      "468\n",
      "71744\n",
      "49707\n",
      "Acc: 0.6928384255129348\n",
      "Prec 0.5717122837771984\n",
      "Recall 0.5314712211354226\n",
      "F1 0.5508578114957503\n",
      "Epoch: 209, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49105\n",
      "Acc: 0.6730400219298246\n",
      "Prec 0.5514485708074492\n",
      "Recall 0.5200702337884815\n",
      "F1 0.5352999609751193\n",
      "468\n",
      "468\n",
      "71744\n",
      "49321\n",
      "Acc: 0.6874581846565566\n",
      "Prec 0.5701462059056392\n",
      "Recall 0.5158632908975773\n",
      "F1 0.5416481143802456\n",
      "Epoch: 210, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49118\n",
      "Acc: 0.673218201754386\n",
      "Prec 0.5555558900577167\n",
      "Recall 0.5112798128358803\n",
      "F1 0.532499073134057\n",
      "468\n",
      "468\n",
      "71744\n",
      "49505\n",
      "Acc: 0.6900228590544157\n",
      "Prec 0.5714048174678313\n",
      "Recall 0.521194813620443\n",
      "F1 0.5451461246519648\n",
      "Epoch: 211, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.778s\n",
      "468\n",
      "468\n",
      "72960\n",
      "48821\n",
      "Acc: 0.6691474780701754\n",
      "Prec 0.54681466813584\n",
      "Recall 0.5107678571900921\n",
      "F1 0.5281769500451596\n",
      "468\n",
      "468\n",
      "71744\n",
      "49610\n",
      "Acc: 0.6914863960749331\n",
      "Prec 0.5725209557434316\n",
      "Recall 0.5261957917865135\n",
      "F1 0.5483817704591344\n",
      "Epoch: 212, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49342\n",
      "Acc: 0.6762883771929824\n",
      "Prec 0.5583853759813023\n",
      "Recall 0.5152840812092708\n",
      "F1 0.535969601251585\n",
      "468\n",
      "468\n",
      "71744\n",
      "49699\n",
      "Acc: 0.6927269179304193\n",
      "Prec 0.5733363136851852\n",
      "Recall 0.5278901407105107\n",
      "F1 0.549675475189712\n",
      "Epoch: 213, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49288\n",
      "Acc: 0.675548245614035\n",
      "Prec 0.5553078189765812\n",
      "Recall 0.5161855299829243\n",
      "F1 0.5350324593623237\n",
      "468\n",
      "468\n",
      "71744\n",
      "49648\n",
      "Acc: 0.6920160570918823\n",
      "Prec 0.5726735995699794\n",
      "Recall 0.5274153988921413\n",
      "F1 0.5491135269499727\n",
      "Epoch: 214, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49347\n",
      "Acc: 0.6763569078947368\n",
      "Prec 0.555721195256079\n",
      "Recall 0.5142148853067164\n",
      "F1 0.5341629577176308\n",
      "468\n",
      "468\n",
      "71744\n",
      "49714\n",
      "Acc: 0.692935994647636\n",
      "Prec 0.5721950699300686\n",
      "Recall 0.5292297918515497\n",
      "F1 0.5498744186103445\n",
      "Epoch: 215, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.907s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49708\n",
      "Acc: 0.6813048245614035\n",
      "Prec 0.5626787086610203\n",
      "Recall 0.5248444896187993\n",
      "F1 0.5431034853025227\n",
      "468\n",
      "468\n",
      "71744\n",
      "49594\n",
      "Acc: 0.6912633809099019\n",
      "Prec 0.5720339487432237\n",
      "Recall 0.5272258790327052\n",
      "F1 0.5487166797915066\n",
      "Epoch: 216, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49522\n",
      "Acc: 0.6787554824561404\n",
      "Prec 0.5593793845851879\n",
      "Recall 0.5203155283128605\n",
      "F1 0.5391407823466293\n",
      "468\n",
      "468\n",
      "71744\n",
      "49824\n",
      "Acc: 0.6944692239072257\n",
      "Prec 0.5741715062858564\n",
      "Recall 0.5338773761369745\n",
      "F1 0.5532917944165806\n",
      "Epoch: 217, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49732\n",
      "Acc: 0.6816337719298246\n",
      "Prec 0.5625547784946806\n",
      "Recall 0.5260566470236424\n",
      "F1 0.5436938720372791\n",
      "468\n",
      "468\n",
      "71744\n",
      "49829\n",
      "Acc: 0.6945389161462979\n",
      "Prec 0.5729322386505055\n",
      "Recall 0.533832937501805\n",
      "F1 0.5526919468347894\n",
      "Epoch: 218, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.886s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49520\n",
      "Acc: 0.6787280701754386\n",
      "Prec 0.5576202839812593\n",
      "Recall 0.5234257220659672\n",
      "F1 0.53998219899768\n",
      "468\n",
      "468\n",
      "71744\n",
      "49912\n",
      "Acc: 0.6956958073148974\n",
      "Prec 0.5724490088115025\n",
      "Recall 0.5400793805717169\n",
      "F1 0.5557932885815361\n",
      "Epoch: 219, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.799s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49850\n",
      "Acc: 0.6832510964912281\n",
      "Prec 0.5673441973470473\n",
      "Recall 0.5274528392978429\n",
      "F1 0.5466717532720544\n",
      "468\n",
      "468\n",
      "71744\n",
      "50026\n",
      "Acc: 0.6972847903657449\n",
      "Prec 0.57596789457511\n",
      "Recall 0.5414230377567174\n",
      "F1 0.5581614779715971\n",
      "Epoch: 220, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49554\n",
      "Acc: 0.6791940789473684\n",
      "Prec 0.559955413172524\n",
      "Recall 0.5222670809876682\n",
      "F1 0.5404550001481847\n",
      "468\n",
      "468\n",
      "71744\n",
      "49826\n",
      "Acc: 0.6944971008028545\n",
      "Prec 0.5721478633729075\n",
      "Recall 0.5356540557694462\n",
      "F1 0.5532998602363655\n",
      "Epoch: 221, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "49557\n",
      "Acc: 0.6792351973684211\n",
      "Prec 0.5615949145709225\n",
      "Recall 0.5211892683739856\n",
      "F1 0.5406381941260079\n",
      "468\n",
      "468\n",
      "71744\n",
      "50011\n",
      "Acc: 0.697075713648528\n",
      "Prec 0.5748460631487208\n",
      "Recall 0.5395443106669432\n",
      "F1 0.5566360409579177\n",
      "Epoch: 222, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.754s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49521\n",
      "Acc: 0.6787417763157895\n",
      "Prec 0.558370870649659\n",
      "Recall 0.5223148330981223\n",
      "F1 0.5397413643926511\n",
      "468\n",
      "468\n",
      "71744\n",
      "49713\n",
      "Acc: 0.6929220561998216\n",
      "Prec 0.570704001430435\n",
      "Recall 0.5333089697041603\n",
      "F1 0.5513731649296008\n",
      "Epoch: 223, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49609\n",
      "Acc: 0.6799479166666667\n",
      "Prec 0.5590674199460243\n",
      "Recall 0.5226899736395688\n",
      "F1 0.5402670445833335\n",
      "468\n",
      "468\n",
      "71744\n",
      "49995\n",
      "Acc: 0.6968526984834968\n",
      "Prec 0.5740917059984815\n",
      "Recall 0.5411443662610166\n",
      "F1 0.5571313556758176\n",
      "Epoch: 224, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49633\n",
      "Acc: 0.6802768640350877\n",
      "Prec 0.5598429943326111\n",
      "Recall 0.5297035120499831\n",
      "F1 0.5443563878317446\n",
      "468\n",
      "468\n",
      "71744\n",
      "49596\n",
      "Acc: 0.6912912578055308\n",
      "Prec 0.572065071130751\n",
      "Recall 0.5257348774655967\n",
      "F1 0.5479223431515359\n",
      "Epoch: 225, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49511\n",
      "Acc: 0.6786047149122807\n",
      "Prec 0.5600062790936593\n",
      "Recall 0.5193212615163533\n",
      "F1 0.5388969638477514\n",
      "468\n",
      "468\n",
      "71744\n",
      "49742\n",
      "Acc: 0.6933262711864406\n",
      "Prec 0.5720970474628863\n",
      "Recall 0.5350817431904572\n",
      "F1 0.5529706457796487\n",
      "Epoch: 226, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.894s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49684\n",
      "Acc: 0.6809758771929825\n",
      "Prec 0.5633164217518836\n",
      "Recall 0.524895249071225\n",
      "F1 0.5434275728318853\n",
      "468\n",
      "468\n",
      "71744\n",
      "49976\n",
      "Acc: 0.6965878679750223\n",
      "Prec 0.5760154196444182\n",
      "Recall 0.5382212518063428\n",
      "F1 0.5564773591899768\n",
      "Epoch: 227, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.896s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49690\n",
      "Acc: 0.6810581140350878\n",
      "Prec 0.5610277291573015\n",
      "Recall 0.5276238232909708\n",
      "F1 0.5438132977710364\n",
      "468\n",
      "468\n",
      "71744\n",
      "50172\n",
      "Acc: 0.6993198037466548\n",
      "Prec 0.5763579371841036\n",
      "Recall 0.5458165822220374\n",
      "F1 0.5606716494986023\n",
      "Epoch: 228, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.839s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49124\n",
      "Acc: 0.6733004385964912\n",
      "Prec 0.5529697342387144\n",
      "Recall 0.5173927253854713\n",
      "F1 0.5345899704926153\n",
      "468\n",
      "468\n",
      "71744\n",
      "49202\n",
      "Acc: 0.6857995093666369\n",
      "Prec 0.5680121091902371\n",
      "Recall 0.5162888682786637\n",
      "F1 0.5409168397264777\n",
      "Epoch: 229, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49299\n",
      "Acc: 0.6756990131578947\n",
      "Prec 0.5551045840663239\n",
      "Recall 0.5176191973392731\n",
      "F1 0.5357069438085311\n",
      "468\n",
      "468\n",
      "71744\n",
      "49876\n",
      "Acc: 0.6951940231935771\n",
      "Prec 0.5749477511135088\n",
      "Recall 0.533740143518574\n",
      "F1 0.5535781470705803\n",
      "Epoch: 230, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49329\n",
      "Acc: 0.676110197368421\n",
      "Prec 0.5575663168864923\n",
      "Recall 0.5159785043964282\n",
      "F1 0.5359668801627041\n",
      "468\n",
      "468\n",
      "71744\n",
      "49719\n",
      "Acc: 0.6930056868867083\n",
      "Prec 0.5734219493940449\n",
      "Recall 0.5303708599143192\n",
      "F1 0.5510568465913999\n",
      "Epoch: 231, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49362\n",
      "Acc: 0.6765625\n",
      "Prec 0.5569044742768079\n",
      "Recall 0.5221414796899264\n",
      "F1 0.5389630074157111\n",
      "468\n",
      "468\n",
      "71744\n",
      "49622\n",
      "Acc: 0.6916536574487065\n",
      "Prec 0.5720294059914971\n",
      "Recall 0.5259366262535218\n",
      "F1 0.548015525197663\n",
      "Epoch: 232, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49596\n",
      "Acc: 0.6797697368421053\n",
      "Prec 0.5608603541502332\n",
      "Recall 0.5214924800965685\n",
      "F1 0.5404604632040932\n",
      "468\n",
      "468\n",
      "71744\n",
      "49962\n",
      "Acc: 0.6963927297056199\n",
      "Prec 0.576536582721199\n",
      "Recall 0.5357373831775493\n",
      "F1 0.5553887074640006\n",
      "Epoch: 233, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49251\n",
      "Acc: 0.6750411184210526\n",
      "Prec 0.5550284252164485\n",
      "Recall 0.5194334857701829\n",
      "F1 0.5366413581789632\n",
      "468\n",
      "468\n",
      "71744\n",
      "49639\n",
      "Acc: 0.6918906110615521\n",
      "Prec 0.5735204919830861\n",
      "Recall 0.525075005457075\n",
      "F1 0.5482295825159542\n",
      "Epoch: 234, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.807s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49365\n",
      "Acc: 0.6766036184210527\n",
      "Prec 0.5577213479577664\n",
      "Recall 0.5147731730758508\n",
      "F1 0.5353873280465196\n",
      "468\n",
      "468\n",
      "71744\n",
      "49746\n",
      "Acc: 0.6933820249776985\n",
      "Prec 0.5728921430641427\n",
      "Recall 0.5314279674918282\n",
      "F1 0.5513816225393902\n",
      "Epoch: 235, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49079\n",
      "Acc: 0.6726836622807018\n",
      "Prec 0.5509702583040347\n",
      "Recall 0.5190488881223175\n",
      "F1 0.5345334257172732\n",
      "468\n",
      "468\n",
      "71744\n",
      "49683\n",
      "Acc: 0.6925039027653881\n",
      "Prec 0.5747652968989292\n",
      "Recall 0.5281658311537708\n",
      "F1 0.5504811370968246\n",
      "Epoch: 236, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49543\n",
      "Acc: 0.6790433114035088\n",
      "Prec 0.5624474556462056\n",
      "Recall 0.5178585203969044\n",
      "F1 0.539232798190731\n",
      "468\n",
      "468\n",
      "71744\n",
      "50050\n",
      "Acc: 0.6976193131132917\n",
      "Prec 0.5753695798987686\n",
      "Recall 0.5401941085920353\n",
      "F1 0.5572272753783727\n",
      "Epoch: 237, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49705\n",
      "Acc: 0.6812637061403509\n",
      "Prec 0.5612496585086443\n",
      "Recall 0.5232639547640027\n",
      "F1 0.541591571238945\n",
      "468\n",
      "468\n",
      "71744\n",
      "49974\n",
      "Acc: 0.6965599910793934\n",
      "Prec 0.572727359719665\n",
      "Recall 0.5423412132644189\n",
      "F1 0.5571202680546248\n",
      "Epoch: 238, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49782\n",
      "Acc: 0.6823190789473684\n",
      "Prec 0.562268884634214\n",
      "Recall 0.5290546864852944\n",
      "F1 0.5451563520715248\n",
      "468\n",
      "468\n",
      "71744\n",
      "49962\n",
      "Acc: 0.6963927297056199\n",
      "Prec 0.575612343927221\n",
      "Recall 0.5385225347671591\n",
      "F1 0.5564500751618313\n",
      "Epoch: 239, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49800\n",
      "Acc: 0.6825657894736842\n",
      "Prec 0.563201044643174\n",
      "Recall 0.5272687880189266\n",
      "F1 0.5446429113862831\n",
      "468\n",
      "468\n",
      "71744\n",
      "49917\n",
      "Acc: 0.6957654995539697\n",
      "Prec 0.5748626695292103\n",
      "Recall 0.5375727391162352\n",
      "F1 0.5555927067276274\n",
      "Epoch: 240, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49639\n",
      "Acc: 0.680359100877193\n",
      "Prec 0.5621889300589463\n",
      "Recall 0.5277009779134137\n",
      "F1 0.5443992938995547\n",
      "468\n",
      "468\n",
      "71744\n",
      "49687\n",
      "Acc: 0.6925596565566459\n",
      "Prec 0.5728187844792761\n",
      "Recall 0.5298493429899038\n",
      "F1 0.5504968340841119\n",
      "Epoch: 241, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49777\n",
      "Acc: 0.682250548245614\n",
      "Prec 0.5649489030082203\n",
      "Recall 0.5237283962164424\n",
      "F1 0.5435582851363838\n",
      "468\n",
      "468\n",
      "71744\n",
      "49916\n",
      "Acc: 0.6957515611061552\n",
      "Prec 0.575270638027967\n",
      "Recall 0.5387663969303721\n",
      "F1 0.5564204405857199\n",
      "Epoch: 242, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49706\n",
      "Acc: 0.6812774122807017\n",
      "Prec 0.5614137973305372\n",
      "Recall 0.5335487011385864\n",
      "F1 0.5471266875089903\n",
      "468\n",
      "468\n",
      "71744\n",
      "49675\n",
      "Acc: 0.6923923951828724\n",
      "Prec 0.572293296717337\n",
      "Recall 0.5293760721950972\n",
      "F1 0.5499987312144061\n",
      "Epoch: 243, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.796s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49779\n",
      "Acc: 0.6822779605263158\n",
      "Prec 0.5637429443429574\n",
      "Recall 0.5275286382176188\n",
      "F1 0.545034897795523\n",
      "468\n",
      "468\n",
      "71744\n",
      "50028\n",
      "Acc: 0.6973126672613738\n",
      "Prec 0.5768993319749945\n",
      "Recall 0.5391124550360483\n",
      "F1 0.557366183385334\n",
      "Epoch: 244, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49940\n",
      "Acc: 0.684484649122807\n",
      "Prec 0.5668128100330139\n",
      "Recall 0.5299669110514911\n",
      "F1 0.5477709485375638\n",
      "468\n",
      "468\n",
      "71744\n",
      "50199\n",
      "Acc: 0.699696141837645\n",
      "Prec 0.5767466447866011\n",
      "Recall 0.5449576247138738\n",
      "F1 0.5604016854541702\n",
      "Epoch: 245, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49921\n",
      "Acc: 0.6842242324561404\n",
      "Prec 0.5648703937039323\n",
      "Recall 0.5325427257935589\n",
      "F1 0.5482304044641242\n",
      "468\n",
      "468\n",
      "71744\n",
      "49772\n",
      "Acc: 0.6937444246208743\n",
      "Prec 0.5757221543301771\n",
      "Recall 0.5311346367155837\n",
      "F1 0.5525303359260497\n",
      "Epoch: 246, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.883s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49574\n",
      "Acc: 0.6794682017543859\n",
      "Prec 0.5608805370977727\n",
      "Recall 0.5215501712652493\n",
      "F1 0.5405008152902135\n",
      "468\n",
      "468\n",
      "71744\n",
      "50044\n",
      "Acc: 0.697535682426405\n",
      "Prec 0.5758503184726768\n",
      "Recall 0.5417762949649697\n",
      "F1 0.5582938849978101\n",
      "Epoch: 247, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.885s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49871\n",
      "Acc: 0.6835389254385965\n",
      "Prec 0.566672913990497\n",
      "Recall 0.5267711431123492\n",
      "F1 0.5459939843003844\n",
      "468\n",
      "468\n",
      "71744\n",
      "49977\n",
      "Acc: 0.6966018064228368\n",
      "Prec 0.5763904543201667\n",
      "Recall 0.5389215659464076\n",
      "F1 0.5570266267990925\n",
      "Epoch: 248, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49583\n",
      "Acc: 0.6795915570175438\n",
      "Prec 0.5605962230543305\n",
      "Recall 0.5238035787534906\n",
      "F1 0.5415757313529797\n",
      "468\n",
      "468\n",
      "71744\n",
      "49713\n",
      "Acc: 0.6929220561998216\n",
      "Prec 0.572447159468162\n",
      "Recall 0.530627679739217\n",
      "F1 0.5507446951109178\n",
      "Epoch: 249, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "49621\n",
      "Acc: 0.6801123903508772\n",
      "Prec 0.5600126374474238\n",
      "Recall 0.5241993658894735\n",
      "F1 0.5415145166010743\n",
      "468\n",
      "468\n",
      "71744\n",
      "50119\n",
      "Acc: 0.6985810660124888\n",
      "Prec 0.5783901178887084\n",
      "Recall 0.5416202294866909\n",
      "F1 0.5594015968117069\n",
      "Epoch: 250, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49706\n",
      "Acc: 0.6812774122807017\n",
      "Prec 0.5619117324340699\n",
      "Recall 0.5264412214674552\n",
      "F1 0.5435984672418154\n",
      "468\n",
      "468\n",
      "71744\n",
      "49832\n",
      "Acc: 0.6945807314897413\n",
      "Prec 0.5737867080586966\n",
      "Recall 0.5341496037013401\n",
      "F1 0.5532591349619567\n",
      "Epoch: 251, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49817\n",
      "Acc: 0.6827987938596491\n",
      "Prec 0.5657132995678956\n",
      "Recall 0.5273619657332737\n",
      "F1 0.5458648405503584\n",
      "468\n",
      "468\n",
      "71744\n",
      "49965\n",
      "Acc: 0.6964345450490633\n",
      "Prec 0.5755784217134151\n",
      "Recall 0.5374703166310123\n",
      "F1 0.5558720043552284\n",
      "Epoch: 252, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49937\n",
      "Acc: 0.6844435307017543\n",
      "Prec 0.5648640713943843\n",
      "Recall 0.5289227405276397\n",
      "F1 0.546302898171746\n",
      "468\n",
      "468\n",
      "71744\n",
      "50171\n",
      "Acc: 0.6993058652988403\n",
      "Prec 0.5755643174488477\n",
      "Recall 0.549138491736384\n",
      "F1 0.5620409562417793\n",
      "Epoch: 253, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.886s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49686\n",
      "Acc: 0.6810032894736842\n",
      "Prec 0.5591979762058302\n",
      "Recall 0.5289411683566163\n",
      "F1 0.5436489117316057\n",
      "468\n",
      "468\n",
      "71744\n",
      "49990\n",
      "Acc: 0.6967830062444246\n",
      "Prec 0.575999698087368\n",
      "Recall 0.5387083428671811\n",
      "F1 0.5567302494434856\n",
      "Epoch: 254, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49887\n",
      "Acc: 0.6837582236842106\n",
      "Prec 0.5646719494998717\n",
      "Recall 0.5302685823962986\n",
      "F1 0.5469297837786957\n",
      "468\n",
      "468\n",
      "71744\n",
      "50080\n",
      "Acc: 0.6980374665477252\n",
      "Prec 0.5755782317179562\n",
      "Recall 0.5432901422949407\n",
      "F1 0.5589683052535978\n",
      "Epoch: 255, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.879s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49818\n",
      "Acc: 0.6828125\n",
      "Prec 0.5639914232009011\n",
      "Recall 0.5295039259741992\n",
      "F1 0.5462038279832372\n",
      "468\n",
      "468\n",
      "71744\n",
      "49860\n",
      "Acc: 0.694971008028546\n",
      "Prec 0.5733334261666566\n",
      "Recall 0.5363022385370063\n",
      "F1 0.554199922842935\n",
      "Epoch: 256, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49617\n",
      "Acc: 0.6800575657894737\n",
      "Prec 0.5610890565611021\n",
      "Recall 0.5254591845592551\n",
      "F1 0.5426899367518467\n",
      "468\n",
      "468\n",
      "71744\n",
      "49870\n",
      "Acc: 0.6951103925066905\n",
      "Prec 0.5765975112300299\n",
      "Recall 0.5359698036560636\n",
      "F1 0.5555418548569783\n",
      "Epoch: 257, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49812\n",
      "Acc: 0.6827302631578948\n",
      "Prec 0.5650362777168588\n",
      "Recall 0.5272513320162217\n",
      "F1 0.5454902672319107\n",
      "468\n",
      "468\n",
      "71744\n",
      "50020\n",
      "Acc: 0.6972011596788582\n",
      "Prec 0.5768470396285307\n",
      "Recall 0.541632508479541\n",
      "F1 0.5586854218505732\n",
      "Epoch: 258, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50004\n",
      "Acc: 0.6853618421052632\n",
      "Prec 0.5668344183553787\n",
      "Recall 0.5357608540636506\n",
      "F1 0.5508597754541017\n",
      "468\n",
      "468\n",
      "71744\n",
      "49951\n",
      "Acc: 0.696239406779661\n",
      "Prec 0.5758112409971572\n",
      "Recall 0.538303161171955\n",
      "F1 0.5564258224534951\n",
      "Epoch: 259, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.810s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49839\n",
      "Acc: 0.6831003289473684\n",
      "Prec 0.5632266472206137\n",
      "Recall 0.5289973687722028\n",
      "F1 0.5455756512207179\n",
      "468\n",
      "468\n",
      "71744\n",
      "50210\n",
      "Acc: 0.6998494647636039\n",
      "Prec 0.5787782936154934\n",
      "Recall 0.5466447997220459\n",
      "F1 0.562252803003426\n",
      "Epoch: 260, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49454\n",
      "Acc: 0.6778234649122807\n",
      "Prec 0.558197339185523\n",
      "Recall 0.5212441198377409\n",
      "F1 0.5390882077529249\n",
      "468\n",
      "468\n",
      "71744\n",
      "49943\n",
      "Acc: 0.6961278991971455\n",
      "Prec 0.5766735215399198\n",
      "Recall 0.5353697339796698\n",
      "F1 0.5552545699774853\n",
      "Epoch: 261, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49792\n",
      "Acc: 0.6824561403508772\n",
      "Prec 0.5644266373020437\n",
      "Recall 0.5276716572098544\n",
      "F1 0.5454306458956018\n",
      "468\n",
      "468\n",
      "71744\n",
      "50006\n",
      "Acc: 0.6970060214094559\n",
      "Prec 0.5773131753802508\n",
      "Recall 0.5406371948593368\n",
      "F1 0.5583735807986279\n",
      "Epoch: 262, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.820s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49873\n",
      "Acc: 0.6835663377192982\n",
      "Prec 0.5654002271008859\n",
      "Recall 0.5307475044675877\n",
      "F1 0.5475261242931414\n",
      "468\n",
      "468\n",
      "71744\n",
      "50048\n",
      "Acc: 0.6975914362176628\n",
      "Prec 0.5782591114208334\n",
      "Recall 0.5398669035314954\n",
      "F1 0.5584038860502663\n",
      "Epoch: 263, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49886\n",
      "Acc: 0.6837445175438597\n",
      "Prec 0.5661267712954375\n",
      "Recall 0.5308040662324146\n",
      "F1 0.547896698544618\n",
      "468\n",
      "468\n",
      "71744\n",
      "49913\n",
      "Acc: 0.6957097457627118\n",
      "Prec 0.5761063614860088\n",
      "Recall 0.5374779374533121\n",
      "F1 0.5561221709396691\n",
      "Epoch: 264, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49914\n",
      "Acc: 0.6841282894736842\n",
      "Prec 0.5665114422007238\n",
      "Recall 0.5324069283802769\n",
      "F1 0.548929974980587\n",
      "468\n",
      "468\n",
      "71744\n",
      "49907\n",
      "Acc: 0.6956261150758252\n",
      "Prec 0.5758195982674034\n",
      "Recall 0.5366174781323491\n",
      "F1 0.5555277997052295\n",
      "Epoch: 265, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49972\n",
      "Acc: 0.6849232456140351\n",
      "Prec 0.5667694093209195\n",
      "Recall 0.5326997564548487\n",
      "F1 0.5492067184954362\n",
      "468\n",
      "468\n",
      "71744\n",
      "50306\n",
      "Acc: 0.7011875557537912\n",
      "Prec 0.5802775371608725\n",
      "Recall 0.5491259525738136\n",
      "F1 0.5642721281576796\n",
      "Epoch: 266, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49980\n",
      "Acc: 0.6850328947368421\n",
      "Prec 0.5662858628958282\n",
      "Recall 0.5347481029774638\n",
      "F1 0.5500653028198208\n",
      "468\n",
      "468\n",
      "71744\n",
      "49959\n",
      "Acc: 0.6963509143621767\n",
      "Prec 0.5784944558514618\n",
      "Recall 0.5365080869096911\n",
      "F1 0.5567107551667976\n",
      "Epoch: 267, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49831\n",
      "Acc: 0.6829906798245614\n",
      "Prec 0.5639916504480424\n",
      "Recall 0.5251437499684913\n",
      "F1 0.5438748757113806\n",
      "468\n",
      "468\n",
      "71744\n",
      "50166\n",
      "Acc: 0.699236173059768\n",
      "Prec 0.5776074544454215\n",
      "Recall 0.5464354650690625\n",
      "F1 0.5615892285208673\n",
      "Epoch: 268, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50153\n",
      "Acc: 0.6874040570175438\n",
      "Prec 0.5688476769417851\n",
      "Recall 0.5347807807470765\n",
      "F1 0.5512884389337703\n",
      "468\n",
      "468\n",
      "71744\n",
      "50224\n",
      "Acc: 0.7000446030330062\n",
      "Prec 0.5764885856462307\n",
      "Recall 0.5500711584507395\n",
      "F1 0.5629701323905194\n",
      "Epoch: 269, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50017\n",
      "Acc: 0.6855400219298246\n",
      "Prec 0.566815564057488\n",
      "Recall 0.5332829035244686\n",
      "F1 0.549538170756369\n",
      "468\n",
      "468\n",
      "71744\n",
      "50152\n",
      "Acc: 0.6990410347903657\n",
      "Prec 0.5775401294774999\n",
      "Recall 0.5440497748246583\n",
      "F1 0.5602949459320186\n",
      "Epoch: 270, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49991\n",
      "Acc: 0.6851836622807017\n",
      "Prec 0.5663369322092401\n",
      "Recall 0.5352624799886497\n",
      "F1 0.5503614244649329\n",
      "468\n",
      "468\n",
      "71744\n",
      "50050\n",
      "Acc: 0.6976193131132917\n",
      "Prec 0.5765817514986736\n",
      "Recall 0.5421080564391834\n",
      "F1 0.558813730965196\n",
      "Epoch: 271, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49818\n",
      "Acc: 0.6828125\n",
      "Prec 0.5625566573275377\n",
      "Recall 0.5284165004125819\n",
      "F1 0.5449523996806322\n",
      "468\n",
      "468\n",
      "71744\n",
      "50304\n",
      "Acc: 0.7011596788581623\n",
      "Prec 0.5809281836818464\n",
      "Recall 0.5461963415106313\n",
      "F1 0.5630271394427434\n",
      "Epoch: 272, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50047\n",
      "Acc: 0.6859512061403509\n",
      "Prec 0.5658187174972062\n",
      "Recall 0.5341288384048762\n",
      "F1 0.5495172796245993\n",
      "468\n",
      "468\n",
      "71744\n",
      "50364\n",
      "Acc: 0.7019959857270295\n",
      "Prec 0.5776922971743806\n",
      "Recall 0.5524309851372521\n",
      "F1 0.564779311831297\n",
      "Epoch: 273, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.893s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50168\n",
      "Acc: 0.687609649122807\n",
      "Prec 0.5675139304285332\n",
      "Recall 0.5372240597950227\n",
      "F1 0.5519537490212506\n",
      "468\n",
      "468\n",
      "71744\n",
      "50133\n",
      "Acc: 0.6987762042818911\n",
      "Prec 0.5769904085484051\n",
      "Recall 0.5450210929463212\n",
      "F1 0.5605503021451411\n",
      "Epoch: 274, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.888s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49909\n",
      "Acc: 0.6840597587719298\n",
      "Prec 0.5651774361714801\n",
      "Recall 0.5343660157423179\n",
      "F1 0.549340026951639\n",
      "468\n",
      "468\n",
      "71744\n",
      "49978\n",
      "Acc: 0.6966157448706513\n",
      "Prec 0.5767037909875563\n",
      "Recall 0.5383838560445303\n",
      "F1 0.5568853921281852\n",
      "Epoch: 275, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.867s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49814\n",
      "Acc: 0.6827576754385964\n",
      "Prec 0.5612942315030751\n",
      "Recall 0.5316945219034032\n",
      "F1 0.5460935753200346\n",
      "468\n",
      "468\n",
      "71744\n",
      "50149\n",
      "Acc: 0.6989992194469223\n",
      "Prec 0.579093148642735\n",
      "Recall 0.5432063303365658\n",
      "F1 0.5605759783179393\n",
      "Epoch: 276, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50131\n",
      "Acc: 0.6871025219298246\n",
      "Prec 0.5709909893444985\n",
      "Recall 0.5382649572485819\n",
      "F1 0.5541452203394647\n",
      "468\n",
      "468\n",
      "71744\n",
      "50275\n",
      "Acc: 0.7007554638715433\n",
      "Prec 0.5799811940640187\n",
      "Recall 0.5470060813702854\n",
      "F1 0.5630112196451533\n",
      "Epoch: 277, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.814s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50269\n",
      "Acc: 0.6889939692982456\n",
      "Prec 0.571761407803664\n",
      "Recall 0.5391919986539079\n",
      "F1 0.5549992905820456\n",
      "468\n",
      "468\n",
      "71744\n",
      "50239\n",
      "Acc: 0.700253679750223\n",
      "Prec 0.5798891291106147\n",
      "Recall 0.5450834695707993\n",
      "F1 0.5619478711436907\n",
      "Epoch: 278, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.902s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50198\n",
      "Acc: 0.6880208333333333\n",
      "Prec 0.5705813805316758\n",
      "Recall 0.5378829449858437\n",
      "F1 0.55374987944908\n",
      "468\n",
      "468\n",
      "71744\n",
      "50136\n",
      "Acc: 0.6988180196253345\n",
      "Prec 0.5776953527018557\n",
      "Recall 0.5442236870656048\n",
      "F1 0.5604602180799667\n",
      "Epoch: 279, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50113\n",
      "Acc: 0.6868558114035088\n",
      "Prec 0.5685188264111033\n",
      "Recall 0.5374358772764144\n",
      "F1 0.5525405574055742\n",
      "468\n",
      "468\n",
      "71744\n",
      "50254\n",
      "Acc: 0.7004627564674398\n",
      "Prec 0.5773143595316977\n",
      "Recall 0.5490831472764183\n",
      "F1 0.5628449700635475\n",
      "Epoch: 280, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50173\n",
      "Acc: 0.6876781798245614\n",
      "Prec 0.5690574469722579\n",
      "Recall 0.5382060500279567\n",
      "F1 0.5532019462461752\n",
      "468\n",
      "468\n",
      "71744\n",
      "50051\n",
      "Acc: 0.6976332515611061\n",
      "Prec 0.5784452020710743\n",
      "Recall 0.5379917255100628\n",
      "F1 0.5574855590803053\n",
      "Epoch: 281, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.821s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49958\n",
      "Acc: 0.6847313596491228\n",
      "Prec 0.565035066626873\n",
      "Recall 0.5336093460617611\n",
      "F1 0.5488727543188797\n",
      "468\n",
      "468\n",
      "71744\n",
      "50180\n",
      "Acc: 0.6994313113291704\n",
      "Prec 0.5781766346884673\n",
      "Recall 0.5437636030828114\n",
      "F1 0.5604423471272058\n",
      "Epoch: 282, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50026\n",
      "Acc: 0.6856633771929824\n",
      "Prec 0.5680037526944335\n",
      "Recall 0.5335392148898862\n",
      "F1 0.5502323289879284\n",
      "468\n",
      "468\n",
      "71744\n",
      "50219\n",
      "Acc: 0.699974910793934\n",
      "Prec 0.5789415387484597\n",
      "Recall 0.5445042444917562\n",
      "F1 0.5611950836682625\n",
      "Epoch: 283, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50060\n",
      "Acc: 0.6861293859649122\n",
      "Prec 0.5684604399884732\n",
      "Recall 0.534795512786833\n",
      "F1 0.551114347922454\n",
      "468\n",
      "468\n",
      "71744\n",
      "50151\n",
      "Acc: 0.6990270963425513\n",
      "Prec 0.5790025287728867\n",
      "Recall 0.5437477820281289\n",
      "F1 0.5608216498008745\n",
      "Epoch: 284, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.826s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49972\n",
      "Acc: 0.6849232456140351\n",
      "Prec 0.5668303377279317\n",
      "Recall 0.5338409911966518\n",
      "F1 0.5498412857336189\n",
      "468\n",
      "468\n",
      "71744\n",
      "50089\n",
      "Acc: 0.6981629125780553\n",
      "Prec 0.5776284122235641\n",
      "Recall 0.5407787793885369\n",
      "F1 0.558596529144525\n",
      "Epoch: 285, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.818s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50086\n",
      "Acc: 0.6864857456140351\n",
      "Prec 0.568571736908521\n",
      "Recall 0.5348889337806652\n",
      "F1 0.5512162566571119\n",
      "468\n",
      "468\n",
      "71744\n",
      "50165\n",
      "Acc: 0.6992222346119537\n",
      "Prec 0.5792309966748103\n",
      "Recall 0.5445171912098632\n",
      "F1 0.5613379203124924\n",
      "Epoch: 286, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49905\n",
      "Acc: 0.6840049342105263\n",
      "Prec 0.5649065469784527\n",
      "Recall 0.5336727132464792\n",
      "F1 0.5488456237467365\n",
      "468\n",
      "468\n",
      "71744\n",
      "49934\n",
      "Acc: 0.6960024531668153\n",
      "Prec 0.5769558729174997\n",
      "Recall 0.5363278335154251\n",
      "F1 0.5559005158663698\n",
      "Epoch: 287, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.779s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49900\n",
      "Acc: 0.6839364035087719\n",
      "Prec 0.5655906264257381\n",
      "Recall 0.5300299195324317\n",
      "F1 0.5472331735994609\n",
      "468\n",
      "468\n",
      "71744\n",
      "50179\n",
      "Acc: 0.699417372881356\n",
      "Prec 0.577943370550979\n",
      "Recall 0.5464160705555142\n",
      "F1 0.5617377041443188\n",
      "Epoch: 288, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50097\n",
      "Acc: 0.6866365131578948\n",
      "Prec 0.5678769046158376\n",
      "Recall 0.5328801253978227\n",
      "F1 0.5498221821730443\n",
      "468\n",
      "468\n",
      "71744\n",
      "50201\n",
      "Acc: 0.6997240187332738\n",
      "Prec 0.5776311355238211\n",
      "Recall 0.5458473409757257\n",
      "F1 0.5612896481521406\n",
      "Epoch: 289, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.802s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50063\n",
      "Acc: 0.6861705043859649\n",
      "Prec 0.5676645732959117\n",
      "Recall 0.5415068162189167\n",
      "F1 0.5542772535815207\n",
      "468\n",
      "468\n",
      "71744\n",
      "49937\n",
      "Acc: 0.6960442685102587\n",
      "Prec 0.5766545536697553\n",
      "Recall 0.5340509788245987\n",
      "F1 0.5545356889316843\n",
      "Epoch: 290, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49758\n",
      "Acc: 0.6819901315789474\n",
      "Prec 0.5634938267361648\n",
      "Recall 0.5291795193186857\n",
      "F1 0.5457978698719385\n",
      "468\n",
      "468\n",
      "71744\n",
      "50026\n",
      "Acc: 0.6972847903657449\n",
      "Prec 0.5783212798474463\n",
      "Recall 0.5345644222658049\n",
      "F1 0.555582626784814\n",
      "Epoch: 291, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.881s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49884\n",
      "Acc: 0.6837171052631579\n",
      "Prec 0.5651658198374923\n",
      "Recall 0.5267393754332416\n",
      "F1 0.5452764438648983\n",
      "468\n",
      "468\n",
      "71744\n",
      "50288\n",
      "Acc: 0.7009366636931311\n",
      "Prec 0.5796145304847853\n",
      "Recall 0.546737279533346\n",
      "F1 0.5626960755186214\n",
      "Epoch: 292, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50005\n",
      "Acc: 0.6853755482456141\n",
      "Prec 0.5663480895558165\n",
      "Recall 0.5323450732761925\n",
      "F1 0.5488204085247798\n",
      "468\n",
      "468\n",
      "71744\n",
      "50041\n",
      "Acc: 0.6974938670829617\n",
      "Prec 0.5771557163529172\n",
      "Recall 0.5385776929409741\n",
      "F1 0.5571997604298167\n",
      "Epoch: 293, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.823s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50028\n",
      "Acc: 0.6856907894736842\n",
      "Prec 0.5661408739466461\n",
      "Recall 0.5326707205624271\n",
      "F1 0.5488960414541969\n",
      "468\n",
      "468\n",
      "71744\n",
      "50138\n",
      "Acc: 0.6988458965209634\n",
      "Prec 0.5781746761090171\n",
      "Recall 0.5432351727891523\n",
      "F1 0.5601606234990626\n",
      "Epoch: 294, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50261\n",
      "Acc: 0.6888843201754385\n",
      "Prec 0.5748200715763943\n",
      "Recall 0.5373934040295625\n",
      "F1 0.5554770226114331\n",
      "468\n",
      "468\n",
      "71744\n",
      "50189\n",
      "Acc: 0.6995567573595004\n",
      "Prec 0.579849319838447\n",
      "Recall 0.5417262384166349\n",
      "F1 0.5601398649828375\n",
      "Epoch: 295, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.885s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49725\n",
      "Acc: 0.6815378289473685\n",
      "Prec 0.5627734256994587\n",
      "Recall 0.5300190979187582\n",
      "F1 0.5459053882145428\n",
      "468\n",
      "468\n",
      "71744\n",
      "49967\n",
      "Acc: 0.6964624219446922\n",
      "Prec 0.5765840859638852\n",
      "Recall 0.5351713917177903\n",
      "F1 0.5551064310851535\n",
      "Epoch: 296, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50030\n",
      "Acc: 0.6857182017543859\n",
      "Prec 0.5656547154614214\n",
      "Recall 0.5317930030254677\n",
      "F1 0.54820145824439\n",
      "468\n",
      "468\n",
      "71744\n",
      "50238\n",
      "Acc: 0.7002397413024085\n",
      "Prec 0.5788944919529451\n",
      "Recall 0.5458415541247247\n",
      "F1 0.5618823550001488\n",
      "Epoch: 297, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50031\n",
      "Acc: 0.6857319078947368\n",
      "Prec 0.5674210191931568\n",
      "Recall 0.5347150884027257\n",
      "F1 0.5505827789296667\n",
      "468\n",
      "468\n",
      "71744\n",
      "50176\n",
      "Acc: 0.6993755575379126\n",
      "Prec 0.5785324843183787\n",
      "Recall 0.5430758139776114\n",
      "F1 0.5602437148709111\n",
      "Epoch: 298, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50145\n",
      "Acc: 0.6872944078947368\n",
      "Prec 0.5694482864451196\n",
      "Recall 0.5345960532677073\n",
      "F1 0.5514720659730094\n",
      "468\n",
      "468\n",
      "71744\n",
      "50269\n",
      "Acc: 0.7006718331846565\n",
      "Prec 0.5801630216974876\n",
      "Recall 0.5441793363262427\n",
      "F1 0.5615953643573445\n",
      "Epoch: 299, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.814s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50102\n",
      "Acc: 0.6867050438596491\n",
      "Prec 0.5684294575269386\n",
      "Recall 0.5371062318153089\n",
      "F1 0.5523241030178961\n",
      "468\n",
      "468\n",
      "71744\n",
      "50084\n",
      "Acc: 0.698093220338983\n",
      "Prec 0.5784391123410155\n",
      "Recall 0.5384417042798102\n",
      "F1 0.5577242205901981\n",
      "Epoch: 300, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.871s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50173\n",
      "Acc: 0.6876781798245614\n",
      "Prec 0.5712023282052434\n",
      "Recall 0.5341175372454928\n",
      "F1 0.5520378133898184\n",
      "468\n",
      "468\n",
      "71744\n",
      "50251\n",
      "Acc: 0.7004209411239964\n",
      "Prec 0.5797740074848213\n",
      "Recall 0.545104710402467\n",
      "F1 0.5619050968311731\n",
      "Epoch: 301, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50157\n",
      "Acc: 0.6874588815789474\n",
      "Prec 0.5698683479181749\n",
      "Recall 0.5359547883082995\n",
      "F1 0.552391534896471\n",
      "468\n",
      "468\n",
      "71744\n",
      "50188\n",
      "Acc: 0.699542818911686\n",
      "Prec 0.5786405316936617\n",
      "Recall 0.5437629542550371\n",
      "F1 0.5606598498747574\n",
      "Epoch: 302, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50147\n",
      "Acc: 0.6873218201754386\n",
      "Prec 0.5702543521553615\n",
      "Recall 0.5369875447029672\n",
      "F1 0.5531212019504523\n",
      "468\n",
      "468\n",
      "71744\n",
      "50274\n",
      "Acc: 0.7007415254237288\n",
      "Prec 0.5777141837691756\n",
      "Recall 0.5490701470119483\n",
      "F1 0.5630280846967965\n",
      "Epoch: 303, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50311\n",
      "Acc: 0.6895696271929824\n",
      "Prec 0.5725837404879214\n",
      "Recall 0.5396839654423021\n",
      "F1 0.5556472816153003\n",
      "468\n",
      "468\n",
      "71744\n",
      "50305\n",
      "Acc: 0.7011736173059768\n",
      "Prec 0.5804115451829585\n",
      "Recall 0.547026072374814\n",
      "F1 0.563224506576589\n",
      "Epoch: 304, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49992\n",
      "Acc: 0.6851973684210526\n",
      "Prec 0.5675760377058371\n",
      "Recall 0.5377421471284741\n",
      "F1 0.5522564658073729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "71744\n",
      "50108\n",
      "Acc: 0.6984277430865299\n",
      "Prec 0.5776314255998249\n",
      "Recall 0.5413214387185766\n",
      "F1 0.5588873031666586\n",
      "Epoch: 305, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.815s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50365\n",
      "Acc: 0.6903097587719298\n",
      "Prec 0.5745893608206158\n",
      "Recall 0.5380422969616873\n",
      "F1 0.555715590767705\n",
      "468\n",
      "468\n",
      "71744\n",
      "50586\n",
      "Acc: 0.7050903211418377\n",
      "Prec 0.5829462323044343\n",
      "Recall 0.5580347349321547\n",
      "F1 0.5702185322364797\n",
      "Epoch: 306, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.814s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50484\n",
      "Acc: 0.6919407894736842\n",
      "Prec 0.57523208674064\n",
      "Recall 0.548121417044713\n",
      "F1 0.5613496115896085\n",
      "468\n",
      "468\n",
      "71744\n",
      "50307\n",
      "Acc: 0.7012014942016057\n",
      "Prec 0.5824490929960365\n",
      "Recall 0.5463898022433288\n",
      "F1 0.5638435140409089\n",
      "Epoch: 307, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50032\n",
      "Acc: 0.6857456140350877\n",
      "Prec 0.5672791952924243\n",
      "Recall 0.5359862095304252\n",
      "F1 0.551188905772094\n",
      "468\n",
      "468\n",
      "71744\n",
      "50091\n",
      "Acc: 0.6981907894736842\n",
      "Prec 0.5792765890058406\n",
      "Recall 0.5400612141440767\n",
      "F1 0.5589819571953348\n",
      "Epoch: 308, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50182\n",
      "Acc: 0.6878015350877194\n",
      "Prec 0.5703183046998839\n",
      "Recall 0.5353496135016972\n",
      "F1 0.5522809859413165\n",
      "468\n",
      "468\n",
      "71744\n",
      "50556\n",
      "Acc: 0.7046721677074042\n",
      "Prec 0.5825745647081367\n",
      "Recall 0.5555763639186\n",
      "F1 0.5687552506986627\n",
      "Epoch: 309, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.791s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50140\n",
      "Acc: 0.6872258771929824\n",
      "Prec 0.5675446522042317\n",
      "Recall 0.5404802157820005\n",
      "F1 0.553681898217243\n",
      "468\n",
      "468\n",
      "71744\n",
      "50142\n",
      "Acc: 0.6989016503122212\n",
      "Prec 0.5790373067193212\n",
      "Recall 0.5397032500259499\n",
      "F1 0.5586788007969684\n",
      "Epoch: 310, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50123\n",
      "Acc: 0.6869928728070176\n",
      "Prec 0.5672000792381467\n",
      "Recall 0.5367446658245235\n",
      "F1 0.5515522735135432\n",
      "468\n",
      "468\n",
      "71744\n",
      "50142\n",
      "Acc: 0.6989016503122212\n",
      "Prec 0.5774741414316468\n",
      "Recall 0.5414457641529953\n",
      "F1 0.5588799095010837\n",
      "Epoch: 311, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50086\n",
      "Acc: 0.6864857456140351\n",
      "Prec 0.5675277674778437\n",
      "Recall 0.5338370582018855\n",
      "F1 0.5501671140646307\n",
      "468\n",
      "468\n",
      "71744\n",
      "50372\n",
      "Acc: 0.702107493309545\n",
      "Prec 0.5790215368224313\n",
      "Recall 0.5530576130948874\n",
      "F1 0.5657418372362665\n",
      "Epoch: 312, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.872s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50097\n",
      "Acc: 0.6866365131578948\n",
      "Prec 0.5681124528849928\n",
      "Recall 0.533646814837472\n",
      "F1 0.5503405504875667\n",
      "468\n",
      "468\n",
      "71744\n",
      "50436\n",
      "Acc: 0.70299955396967\n",
      "Prec 0.5817179699560368\n",
      "Recall 0.5500345517591242\n",
      "F1 0.5654327721224641\n",
      "Epoch: 313, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50114\n",
      "Acc: 0.6868695175438596\n",
      "Prec 0.5710420542919269\n",
      "Recall 0.5343624617980188\n",
      "F1 0.5520937059330826\n",
      "468\n",
      "468\n",
      "71744\n",
      "50185\n",
      "Acc: 0.6995010035682426\n",
      "Prec 0.5787777741287056\n",
      "Recall 0.5406663619298597\n",
      "F1 0.5590733175945783\n",
      "Epoch: 314, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50007\n",
      "Acc: 0.6854029605263158\n",
      "Prec 0.5681438945174581\n",
      "Recall 0.5303073988321727\n",
      "F1 0.5485740017569161\n",
      "468\n",
      "468\n",
      "71744\n",
      "50516\n",
      "Acc: 0.7041146297948261\n",
      "Prec 0.5812302085702683\n",
      "Recall 0.5531608580008102\n",
      "F1 0.5668482595522523\n",
      "Epoch: 315, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50202\n",
      "Acc: 0.6880756578947368\n",
      "Prec 0.5712113282290441\n",
      "Recall 0.5380966606599906\n",
      "F1 0.5541597308048463\n",
      "468\n",
      "468\n",
      "71744\n",
      "50379\n",
      "Acc: 0.7022050624442462\n",
      "Prec 0.5809723997354583\n",
      "Recall 0.5482188810263073\n",
      "F1 0.5641206132503568\n",
      "Epoch: 316, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50303\n",
      "Acc: 0.6894599780701754\n",
      "Prec 0.5732222396024675\n",
      "Recall 0.539879774357969\n",
      "F1 0.5560516277792836\n",
      "468\n",
      "468\n",
      "71744\n",
      "50070\n",
      "Acc: 0.6978980820695807\n",
      "Prec 0.5772821066005488\n",
      "Recall 0.5408377533145944\n",
      "F1 0.5584659905535563\n",
      "Epoch: 317, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.819s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50098\n",
      "Acc: 0.6866502192982457\n",
      "Prec 0.56672085129247\n",
      "Recall 0.5365406740074937\n",
      "F1 0.5512179670072148\n",
      "468\n",
      "468\n",
      "71744\n",
      "50230\n",
      "Acc: 0.700128233719893\n",
      "Prec 0.5795551235619097\n",
      "Recall 0.5432691729534319\n",
      "F1 0.5608258275770233\n",
      "Epoch: 318, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50263\n",
      "Acc: 0.6889117324561403\n",
      "Prec 0.5715073000982631\n",
      "Recall 0.5391086885181121\n",
      "F1 0.5548354322151328\n",
      "468\n",
      "468\n",
      "71744\n",
      "50220\n",
      "Acc: 0.6999888492417484\n",
      "Prec 0.579162572186753\n",
      "Recall 0.5450126496243349\n",
      "F1 0.5615689118680665\n",
      "Epoch: 319, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50151\n",
      "Acc: 0.6873766447368421\n",
      "Prec 0.568724477460299\n",
      "Recall 0.5374486941358777\n",
      "F1 0.5526444422677292\n",
      "468\n",
      "468\n",
      "71744\n",
      "50376\n",
      "Acc: 0.7021632471008028\n",
      "Prec 0.581053708328518\n",
      "Recall 0.5505890163658765\n",
      "F1 0.5654112958853512\n",
      "Epoch: 320, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.810s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50415\n",
      "Acc: 0.6909950657894737\n",
      "Prec 0.5741453139296561\n",
      "Recall 0.5410551984135678\n",
      "F1 0.5571093329103917\n",
      "468\n",
      "468\n",
      "71744\n",
      "50376\n",
      "Acc: 0.7021632471008028\n",
      "Prec 0.5815717336100791\n",
      "Recall 0.5478693352370892\n",
      "F1 0.5642176964768238\n",
      "Epoch: 321, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50221\n",
      "Acc: 0.6883360745614036\n",
      "Prec 0.5705690875565118\n",
      "Recall 0.5389562514966182\n",
      "F1 0.5543123096435709\n",
      "468\n",
      "468\n",
      "71744\n",
      "50425\n",
      "Acc: 0.702846231043711\n",
      "Prec 0.5809433786476502\n",
      "Recall 0.5499647086309286\n",
      "F1 0.5650297483288216\n",
      "Epoch: 322, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.820s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50044\n",
      "Acc: 0.6859100877192983\n",
      "Prec 0.5662383510841208\n",
      "Recall 0.5368724772583461\n",
      "F1 0.5511645402339124\n",
      "468\n",
      "468\n",
      "71744\n",
      "50010\n",
      "Acc: 0.6970617752007137\n",
      "Prec 0.5780019196025429\n",
      "Recall 0.534220982343039\n",
      "F1 0.5552497664741317\n",
      "Epoch: 323, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50301\n",
      "Acc: 0.6894325657894737\n",
      "Prec 0.5728481277423033\n",
      "Recall 0.5381652608871806\n",
      "F1 0.5549653411386232\n",
      "468\n",
      "468\n",
      "71744\n",
      "50136\n",
      "Acc: 0.6988180196253345\n",
      "Prec 0.578632116689752\n",
      "Recall 0.5411225340485247\n",
      "F1 0.5592490766768952\n",
      "Epoch: 324, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.810s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50130\n",
      "Acc: 0.6870888157894737\n",
      "Prec 0.5693929188373671\n",
      "Recall 0.5371513269205139\n",
      "F1 0.5528024081552327\n",
      "468\n",
      "468\n",
      "71744\n",
      "50017\n",
      "Acc: 0.6971593443354148\n",
      "Prec 0.5787785206701561\n",
      "Recall 0.5383775577971135\n",
      "F1 0.5578475066641354\n",
      "Epoch: 325, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50217\n",
      "Acc: 0.68828125\n",
      "Prec 0.5709923769524575\n",
      "Recall 0.5383654630280076\n",
      "F1 0.5541991309294493\n",
      "468\n",
      "468\n",
      "71744\n",
      "50310\n",
      "Acc: 0.7012433095450491\n",
      "Prec 0.581733779718617\n",
      "Recall 0.5463857669600796\n",
      "F1 0.5635059836236855\n",
      "Epoch: 326, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.821s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50255\n",
      "Acc: 0.6888020833333334\n",
      "Prec 0.5711996394864487\n",
      "Recall 0.5355647376277158\n",
      "F1 0.5528085135017862\n",
      "468\n",
      "468\n",
      "71744\n",
      "50313\n",
      "Acc: 0.7012851248884924\n",
      "Prec 0.5799329940744012\n",
      "Recall 0.5487897915070962\n",
      "F1 0.5639317482940938\n",
      "Epoch: 327, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50289\n",
      "Acc: 0.6892680921052632\n",
      "Prec 0.5706083770657087\n",
      "Recall 0.5423044887330546\n",
      "F1 0.5560965169889063\n",
      "468\n",
      "468\n",
      "71744\n",
      "50465\n",
      "Acc: 0.703403768956289\n",
      "Prec 0.5821551979144258\n",
      "Recall 0.5510515004767789\n",
      "F1 0.5661764897375413\n",
      "Epoch: 328, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.814s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50251\n",
      "Acc: 0.6887472587719298\n",
      "Prec 0.5733569596907996\n",
      "Recall 0.5391599873776306\n",
      "F1 0.5557328937134001\n",
      "468\n",
      "468\n",
      "71744\n",
      "50293\n",
      "Acc: 0.7010063559322034\n",
      "Prec 0.5800600762772323\n",
      "Recall 0.5466704538545566\n",
      "F1 0.5628705296985131\n",
      "Epoch: 329, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50242\n",
      "Acc: 0.6886239035087719\n",
      "Prec 0.5693528257463046\n",
      "Recall 0.5390665247600935\n",
      "F1 0.5537959058494945\n",
      "468\n",
      "468\n",
      "71744\n",
      "50631\n",
      "Acc: 0.705717551293488\n",
      "Prec 0.5840382484541423\n",
      "Recall 0.5568693386418101\n",
      "F1 0.5701303012385467\n",
      "Epoch: 330, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50049\n",
      "Acc: 0.6859786184210527\n",
      "Prec 0.5674253380801388\n",
      "Recall 0.538396657824606\n",
      "F1 0.5525299853298624\n",
      "468\n",
      "468\n",
      "71744\n",
      "50077\n",
      "Acc: 0.6979956512042819\n",
      "Prec 0.5790806804417479\n",
      "Recall 0.5352701613302735\n",
      "F1 0.5563142192281177\n",
      "Epoch: 331, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.812s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50271\n",
      "Acc: 0.6890213815789473\n",
      "Prec 0.5704084891494622\n",
      "Recall 0.5373661586372894\n",
      "F1 0.5533945361193204\n",
      "468\n",
      "468\n",
      "71744\n",
      "50419\n",
      "Acc: 0.7027626003568243\n",
      "Prec 0.5812534460436619\n",
      "Recall 0.5487473051096842\n",
      "F1 0.5645328319943608\n",
      "Epoch: 332, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50326\n",
      "Acc: 0.6897752192982456\n",
      "Prec 0.573121336410842\n",
      "Recall 0.5385923476481397\n",
      "F1 0.5553206198519325\n",
      "468\n",
      "468\n",
      "71744\n",
      "50373\n",
      "Acc: 0.7021214317573595\n",
      "Prec 0.5803900342906158\n",
      "Recall 0.5482542025559005\n",
      "F1 0.5638646174466142\n",
      "Epoch: 333, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.815s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50372\n",
      "Acc: 0.690405701754386\n",
      "Prec 0.5729186278995984\n",
      "Recall 0.5421595776793925\n",
      "F1 0.5571148638591158\n",
      "468\n",
      "468\n",
      "71744\n",
      "50260\n",
      "Acc: 0.7005463871543265\n",
      "Prec 0.579329841619333\n",
      "Recall 0.5451080026363844\n",
      "F1 0.5616981577879898\n",
      "Epoch: 334, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50371\n",
      "Acc: 0.6903919956140351\n",
      "Prec 0.5731389555956575\n",
      "Recall 0.5413822722189802\n",
      "F1 0.5568081833416562\n",
      "468\n",
      "468\n",
      "71744\n",
      "50350\n",
      "Acc: 0.7018008474576272\n",
      "Prec 0.580170130226232\n",
      "Recall 0.5488575721162181\n",
      "F1 0.5640796384883303\n",
      "Epoch: 335, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50433\n",
      "Acc: 0.6912417763157894\n",
      "Prec 0.5742607266412173\n",
      "Recall 0.543811838709557\n",
      "F1 0.5586216697043658\n",
      "468\n",
      "468\n",
      "71744\n",
      "50466\n",
      "Acc: 0.7034177074041035\n",
      "Prec 0.5820390035383477\n",
      "Recall 0.5514001296967018\n",
      "F1 0.5663054550156054\n",
      "Epoch: 336, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50022\n",
      "Acc: 0.6856085526315789\n",
      "Prec 0.5661508133120104\n",
      "Recall 0.5420867735923689\n",
      "F1 0.5538575326835282\n",
      "468\n",
      "468\n",
      "71744\n",
      "50241\n",
      "Acc: 0.7002815566458519\n",
      "Prec 0.5799481744430635\n",
      "Recall 0.5421586698236619\n",
      "F1 0.5604170982990164\n",
      "Epoch: 337, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50234\n",
      "Acc: 0.6885142543859649\n",
      "Prec 0.5714580500052682\n",
      "Recall 0.5388879755952592\n",
      "F1 0.5546953194854705\n",
      "468\n",
      "468\n",
      "71744\n",
      "50218\n",
      "Acc: 0.6999609723461195\n",
      "Prec 0.5810542899803193\n",
      "Recall 0.5402981302897186\n",
      "F1 0.559935557810781\n",
      "Epoch: 338, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50228\n",
      "Acc: 0.6884320175438596\n",
      "Prec 0.5710655808569914\n",
      "Recall 0.5373129212667109\n",
      "F1 0.5536753282334878\n",
      "468\n",
      "468\n",
      "71744\n",
      "50229\n",
      "Acc: 0.7001142952720785\n",
      "Prec 0.578894138581413\n",
      "Recall 0.5444385163638009\n",
      "F1 0.561137904348265\n",
      "Epoch: 339, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50265\n",
      "Acc: 0.6889391447368421\n",
      "Prec 0.5714027265958216\n",
      "Recall 0.5384902711837035\n",
      "F1 0.5544585105325868\n",
      "468\n",
      "468\n",
      "71744\n",
      "50174\n",
      "Acc: 0.6993476806422837\n",
      "Prec 0.5795481045373578\n",
      "Recall 0.541288035762518\n",
      "F1 0.5597650608428577\n",
      "Epoch: 340, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50358\n",
      "Acc: 0.6902138157894737\n",
      "Prec 0.5728644988799312\n",
      "Recall 0.5428916437698484\n",
      "F1 0.5574754869208656\n",
      "468\n",
      "468\n",
      "71744\n",
      "50403\n",
      "Acc: 0.702539585191793\n",
      "Prec 0.5827156150241264\n",
      "Recall 0.548187977305941\n",
      "F1 0.5649247142039879\n",
      "Epoch: 341, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50316\n",
      "Acc: 0.6896381578947368\n",
      "Prec 0.5711196293120879\n",
      "Recall 0.5396732693560428\n",
      "F1 0.5549513287559311\n",
      "468\n",
      "468\n",
      "71744\n",
      "50319\n",
      "Acc: 0.7013687555753791\n",
      "Prec 0.5819863324164406\n",
      "Recall 0.5452420997221068\n",
      "F1 0.5630153407225378\n",
      "Epoch: 342, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50525\n",
      "Acc: 0.6925027412280702\n",
      "Prec 0.5776034418578756\n",
      "Recall 0.5434429305303842\n",
      "F1 0.5600027168527638\n",
      "468\n",
      "468\n",
      "71744\n",
      "50309\n",
      "Acc: 0.7012293710972346\n",
      "Prec 0.580577140247894\n",
      "Recall 0.5465970739266345\n",
      "F1 0.56307492144077\n",
      "Epoch: 343, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50220\n",
      "Acc: 0.6883223684210527\n",
      "Prec 0.5677373471537209\n",
      "Recall 0.5429127027130306\n",
      "F1 0.5550475914737183\n",
      "468\n",
      "468\n",
      "71744\n",
      "50266\n",
      "Acc: 0.7006300178412131\n",
      "Prec 0.5810382408398229\n",
      "Recall 0.5444867892665911\n",
      "F1 0.5621690104325305\n",
      "Epoch: 344, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50451\n",
      "Acc: 0.6914884868421053\n",
      "Prec 0.5760192247638926\n",
      "Recall 0.5437062540298999\n",
      "F1 0.559396496510836\n",
      "468\n",
      "468\n",
      "71744\n",
      "50592\n",
      "Acc: 0.7051739518287243\n",
      "Prec 0.5836245891040551\n",
      "Recall 0.5543783566128018\n",
      "F1 0.5686256644661252\n",
      "Epoch: 345, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50363\n",
      "Acc: 0.6902823464912281\n",
      "Prec 0.5733067174443202\n",
      "Recall 0.5439582632759674\n",
      "F1 0.55824702595513\n",
      "468\n",
      "468\n",
      "71744\n",
      "50325\n",
      "Acc: 0.7014523862622658\n",
      "Prec 0.5848328944887075\n",
      "Recall 0.5411844296837196\n",
      "F1 0.5621626766653264\n",
      "Epoch: 346, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50340\n",
      "Acc: 0.6899671052631579\n",
      "Prec 0.5729744099028876\n",
      "Recall 0.5383595487840462\n",
      "F1 0.5551279025875958\n",
      "468\n",
      "468\n",
      "71744\n",
      "50491\n",
      "Acc: 0.7037661685994647\n",
      "Prec 0.5832979215148374\n",
      "Recall 0.5516359774525915\n",
      "F1 0.5670253031892859\n",
      "Epoch: 347, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50360\n",
      "Acc: 0.6902412280701754\n",
      "Prec 0.5738507678159119\n",
      "Recall 0.5402512519639752\n",
      "F1 0.5565443563494952\n",
      "468\n",
      "468\n",
      "71744\n",
      "50338\n",
      "Acc: 0.7016335860838537\n",
      "Prec 0.5798383030423439\n",
      "Recall 0.5498420445587596\n",
      "F1 0.5644419303837637\n",
      "Epoch: 348, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "49908\n",
      "Acc: 0.6840460526315789\n",
      "Prec 0.5641241717204679\n",
      "Recall 0.5386519310186936\n",
      "F1 0.5510938687858461\n",
      "468\n",
      "468\n",
      "71744\n",
      "50193\n",
      "Acc: 0.6996125111507583\n",
      "Prec 0.5808663675960258\n",
      "Recall 0.5386442517839136\n",
      "F1 0.5589591104254024\n",
      "Epoch: 349, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50144\n",
      "Acc: 0.6872807017543859\n",
      "Prec 0.5704893952870163\n",
      "Recall 0.5341440929909017\n",
      "F1 0.5517188168567365\n",
      "468\n",
      "468\n",
      "71744\n",
      "50471\n",
      "Acc: 0.7034873996431757\n",
      "Prec 0.582833110380723\n",
      "Recall 0.5510056785991672\n",
      "F1 0.5664726883869016\n",
      "Epoch: 350, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.797s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50222\n",
      "Acc: 0.6883497807017543\n",
      "Prec 0.5698909053238176\n",
      "Recall 0.5367419516470121\n",
      "F1 0.5528199435297473\n",
      "468\n",
      "468\n",
      "71744\n",
      "50490\n",
      "Acc: 0.7037522301516503\n",
      "Prec 0.5815223407553846\n",
      "Recall 0.5551158837796955\n",
      "F1 0.5680123739602417\n",
      "Epoch: 351, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.812s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50385\n",
      "Acc: 0.6905838815789473\n",
      "Prec 0.5730339095262503\n",
      "Recall 0.5438425997884423\n",
      "F1 0.5580567744502232\n",
      "468\n",
      "468\n",
      "71744\n",
      "50266\n",
      "Acc: 0.7006300178412131\n",
      "Prec 0.5804132845509056\n",
      "Recall 0.5452833097076288\n",
      "F1 0.5623001409303484\n",
      "Epoch: 352, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50305\n",
      "Acc: 0.6894873903508771\n",
      "Prec 0.5720951124570771\n",
      "Recall 0.5399682955386661\n",
      "F1 0.5555676421656559\n",
      "468\n",
      "468\n",
      "71744\n",
      "50540\n",
      "Acc: 0.7044491525423728\n",
      "Prec 0.5832540196934278\n",
      "Recall 0.5546789181500489\n",
      "F1 0.568607688364001\n",
      "Epoch: 353, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50334\n",
      "Acc: 0.6898848684210527\n",
      "Prec 0.5729317606953702\n",
      "Recall 0.5418641957839349\n",
      "F1 0.5569650767818044\n",
      "468\n",
      "468\n",
      "71744\n",
      "50340\n",
      "Acc: 0.7016614629794826\n",
      "Prec 0.5820338989423011\n",
      "Recall 0.5475334724344934\n",
      "F1 0.5642568116570723\n",
      "Epoch: 354, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50355\n",
      "Acc: 0.690172697368421\n",
      "Prec 0.5743735355975326\n",
      "Recall 0.5428121427107576\n",
      "F1 0.5581470218024308\n",
      "468\n",
      "468\n",
      "71744\n",
      "50465\n",
      "Acc: 0.703403768956289\n",
      "Prec 0.5846259281724998\n",
      "Recall 0.5494937425331042\n",
      "F1 0.5665156818125354\n",
      "Epoch: 355, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50316\n",
      "Acc: 0.6896381578947368\n",
      "Prec 0.5725200411564014\n",
      "Recall 0.5402561854850255\n",
      "F1 0.5559203838896466\n",
      "468\n",
      "468\n",
      "71744\n",
      "50527\n",
      "Acc: 0.704267952720785\n",
      "Prec 0.5848311406164338\n",
      "Recall 0.5533722256349245\n",
      "F1 0.5686669351003445\n",
      "Epoch: 356, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50441\n",
      "Acc: 0.6913514254385965\n",
      "Prec 0.5746382754985443\n",
      "Recall 0.5428917954070726\n",
      "F1 0.5583141129119137\n",
      "468\n",
      "468\n",
      "71744\n",
      "50443\n",
      "Acc: 0.7030971231043711\n",
      "Prec 0.5822619529728713\n",
      "Recall 0.5518137803140079\n",
      "F1 0.5666291235625974\n",
      "Epoch: 357, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50281\n",
      "Acc: 0.6891584429824561\n",
      "Prec 0.571271720100824\n",
      "Recall 0.5458887276375496\n",
      "F1 0.5582918604977056\n",
      "468\n",
      "468\n",
      "71744\n",
      "50244\n",
      "Acc: 0.7003233719892953\n",
      "Prec 0.5811477070923113\n",
      "Recall 0.5402458133170661\n",
      "F1 0.5599508289664779\n",
      "Epoch: 358, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.839s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50462\n",
      "Acc: 0.691639254385965\n",
      "Prec 0.5761765676679308\n",
      "Recall 0.5422062611777011\n",
      "F1 0.5586754990791267\n",
      "468\n",
      "468\n",
      "71744\n",
      "50572\n",
      "Acc: 0.7048951828724354\n",
      "Prec 0.5845547566888517\n",
      "Recall 0.5523443248557375\n",
      "F1 0.5679932505281922\n",
      "Epoch: 359, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.882s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50310\n",
      "Acc: 0.6895559210526315\n",
      "Prec 0.5711212028188566\n",
      "Recall 0.5385270818262676\n",
      "F1 0.5543454425678829\n",
      "468\n",
      "468\n",
      "71744\n",
      "50446\n",
      "Acc: 0.7031389384478145\n",
      "Prec 0.581981890810885\n",
      "Recall 0.5504964706606116\n",
      "F1 0.565801498341203\n",
      "Epoch: 360, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.870s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50550\n",
      "Acc: 0.6928453947368421\n",
      "Prec 0.5768914385987425\n",
      "Recall 0.5452016938436303\n",
      "F1 0.5605990811178518\n",
      "468\n",
      "468\n",
      "71744\n",
      "50357\n",
      "Acc: 0.7018984165923283\n",
      "Prec 0.581796548257238\n",
      "Recall 0.5467968544170435\n",
      "F1 0.5637539998797317\n",
      "Epoch: 361, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50529\n",
      "Acc: 0.6925575657894737\n",
      "Prec 0.5750781420712332\n",
      "Recall 0.5475455875778371\n",
      "F1 0.5609742443302806\n",
      "468\n",
      "468\n",
      "71744\n",
      "50504\n",
      "Acc: 0.7039473684210527\n",
      "Prec 0.5830451818276713\n",
      "Recall 0.551726827487106\n",
      "F1 0.5669538300396901\n",
      "Epoch: 362, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50319\n",
      "Acc: 0.6896792763157895\n",
      "Prec 0.5721721476299596\n",
      "Recall 0.547252581445413\n",
      "F1 0.5594349967242475\n",
      "468\n",
      "468\n",
      "71744\n",
      "50303\n",
      "Acc: 0.7011457404103479\n",
      "Prec 0.5831738531537823\n",
      "Recall 0.5406490049005828\n",
      "F1 0.5611068704145876\n",
      "Epoch: 363, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50441\n",
      "Acc: 0.6913514254385965\n",
      "Prec 0.5743469769532021\n",
      "Recall 0.5429119932143994\n",
      "F1 0.5581872607521804\n",
      "468\n",
      "468\n",
      "71744\n",
      "50260\n",
      "Acc: 0.7005463871543265\n",
      "Prec 0.5808021319050299\n",
      "Recall 0.5408018352150338\n",
      "F1 0.5600887087401344\n",
      "Epoch: 364, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50403\n",
      "Acc: 0.6908305921052632\n",
      "Prec 0.5740875205255523\n",
      "Recall 0.53914970315409\n",
      "F1 0.5560703679180778\n",
      "468\n",
      "468\n",
      "71744\n",
      "50646\n",
      "Acc: 0.7059266280107047\n",
      "Prec 0.5847836232712889\n",
      "Recall 0.5574362427330147\n",
      "F1 0.5707825532898195\n",
      "Epoch: 365, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.785s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50428\n",
      "Acc: 0.691173245614035\n",
      "Prec 0.5736687794415752\n",
      "Recall 0.5429331335216122\n",
      "F1 0.5578779409381176\n",
      "468\n",
      "468\n",
      "71744\n",
      "50385\n",
      "Acc: 0.702288693131133\n",
      "Prec 0.5823522381244243\n",
      "Recall 0.5480665132587236\n",
      "F1 0.5646894307914526\n",
      "Epoch: 366, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50403\n",
      "Acc: 0.6908305921052632\n",
      "Prec 0.5732947232986126\n",
      "Recall 0.5457568365312452\n",
      "F1 0.5591869504834559\n",
      "468\n",
      "468\n",
      "71744\n",
      "50462\n",
      "Acc: 0.7033619536128457\n",
      "Prec 0.584215286341537\n",
      "Recall 0.5480551283402161\n",
      "F1 0.5655578024163436\n",
      "Epoch: 367, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50142\n",
      "Acc: 0.6872532894736842\n",
      "Prec 0.5702431533059079\n",
      "Recall 0.5402367181930509\n",
      "F1 0.554834531666393\n",
      "468\n",
      "468\n",
      "71744\n",
      "50140\n",
      "Acc: 0.6988737734165923\n",
      "Prec 0.5799963732328802\n",
      "Recall 0.5390034321751811\n",
      "F1 0.5587490441210182\n",
      "Epoch: 368, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50404\n",
      "Acc: 0.690844298245614\n",
      "Prec 0.5742621914696859\n",
      "Recall 0.5410572908896301\n",
      "F1 0.5571654588507063\n",
      "468\n",
      "468\n",
      "71744\n",
      "50443\n",
      "Acc: 0.7030971231043711\n",
      "Prec 0.5815791474785008\n",
      "Recall 0.5511796368146761\n",
      "F1 0.5659714808324525\n",
      "Epoch: 369, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50477\n",
      "Acc: 0.691844846491228\n",
      "Prec 0.5758402734528253\n",
      "Recall 0.541486754804209\n",
      "F1 0.5581353946909242\n",
      "468\n",
      "468\n",
      "71744\n",
      "50808\n",
      "Acc: 0.7081846565566459\n",
      "Prec 0.5871800615749766\n",
      "Recall 0.5625567590258794\n",
      "F1 0.5746047382071452\n",
      "Epoch: 370, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50379\n",
      "Acc: 0.6905016447368421\n",
      "Prec 0.5730140913499485\n",
      "Recall 0.5447428463731658\n",
      "F1 0.5585209388541097\n",
      "468\n",
      "468\n",
      "71744\n",
      "50564\n",
      "Acc: 0.7047836752899197\n",
      "Prec 0.5852229539720631\n",
      "Recall 0.5516697235472083\n",
      "F1 0.5679512087908158\n",
      "Epoch: 371, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.867s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50238\n",
      "Acc: 0.6885690789473684\n",
      "Prec 0.5698627635581034\n",
      "Recall 0.5389371575266525\n",
      "F1 0.5539686865630847\n",
      "468\n",
      "468\n",
      "71744\n",
      "50585\n",
      "Acc: 0.7050763826940232\n",
      "Prec 0.5855976219343029\n",
      "Recall 0.5515816581360958\n",
      "F1 0.568080887451768\n",
      "Epoch: 372, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50481\n",
      "Acc: 0.6918996710526316\n",
      "Prec 0.5779639605635142\n",
      "Recall 0.542936658901609\n",
      "F1 0.5599030213109085\n",
      "468\n",
      "468\n",
      "71744\n",
      "50425\n",
      "Acc: 0.702846231043711\n",
      "Prec 0.5824021921964636\n",
      "Recall 0.5481267888146603\n",
      "F1 0.5647449092755723\n",
      "Epoch: 373, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50257\n",
      "Acc: 0.6888294956140351\n",
      "Prec 0.5707501380875364\n",
      "Recall 0.5389338883014392\n",
      "F1 0.5543859041912136\n",
      "468\n",
      "468\n",
      "71744\n",
      "50490\n",
      "Acc: 0.7037522301516503\n",
      "Prec 0.5831388353519166\n",
      "Recall 0.5515052050919212\n",
      "F1 0.5668810508395589\n",
      "Epoch: 374, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50263\n",
      "Acc: 0.6889117324561403\n",
      "Prec 0.5735903437196282\n",
      "Recall 0.5394427888570879\n",
      "F1 0.5559927474239589\n",
      "468\n",
      "468\n",
      "71744\n",
      "50377\n",
      "Acc: 0.7021771855486173\n",
      "Prec 0.5823709181809448\n",
      "Recall 0.5463023675579542\n",
      "F1 0.5637603289084118\n",
      "Epoch: 375, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50420\n",
      "Acc: 0.6910635964912281\n",
      "Prec 0.5724344442795005\n",
      "Recall 0.5413385100152603\n",
      "F1 0.556452386373297\n",
      "468\n",
      "468\n",
      "71744\n",
      "50490\n",
      "Acc: 0.7037522301516503\n",
      "Prec 0.5827652027493136\n",
      "Recall 0.5518856677810349\n",
      "F1 0.5669052418362426\n",
      "Epoch: 376, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50191\n",
      "Acc: 0.6879248903508772\n",
      "Prec 0.5686548797959142\n",
      "Recall 0.5408650219285339\n",
      "F1 0.5544119281728208\n",
      "468\n",
      "468\n",
      "71744\n",
      "50503\n",
      "Acc: 0.7039334299732382\n",
      "Prec 0.5828062720600576\n",
      "Recall 0.5489064392740374\n",
      "F1 0.5653486302295708\n",
      "Epoch: 377, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.839s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50333\n",
      "Acc: 0.6898711622807018\n",
      "Prec 0.573574951131952\n",
      "Recall 0.5375930886341532\n",
      "F1 0.5550014372391696\n",
      "468\n",
      "468\n",
      "71744\n",
      "50530\n",
      "Acc: 0.7043097680642284\n",
      "Prec 0.584478251476961\n",
      "Recall 0.5520541122646371\n",
      "F1 0.5678036676313456\n",
      "Epoch: 378, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.818s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50525\n",
      "Acc: 0.6925027412280702\n",
      "Prec 0.575261368121058\n",
      "Recall 0.5444106891524121\n",
      "F1 0.5594110093703152\n",
      "468\n",
      "468\n",
      "71744\n",
      "50507\n",
      "Acc: 0.703989183764496\n",
      "Prec 0.5842114449898478\n",
      "Recall 0.5516758852741809\n",
      "F1 0.5674777022597259\n",
      "Epoch: 379, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.911s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50378\n",
      "Acc: 0.6904879385964913\n",
      "Prec 0.5735072579703121\n",
      "Recall 0.5438916990157424\n",
      "F1 0.5583070128804956\n",
      "468\n",
      "468\n",
      "71744\n",
      "50471\n",
      "Acc: 0.7034873996431757\n",
      "Prec 0.5831599603627687\n",
      "Recall 0.5496878108158278\n",
      "F1 0.5659293863177294\n",
      "Epoch: 380, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50669\n",
      "Acc: 0.6944764254385964\n",
      "Prec 0.5796641581266031\n",
      "Recall 0.5488332529184611\n",
      "F1 0.5638275504952144\n",
      "468\n",
      "468\n",
      "71744\n",
      "50539\n",
      "Acc: 0.7044352140945584\n",
      "Prec 0.584039386147637\n",
      "Recall 0.5501779514768274\n",
      "F1 0.5666032115599355\n",
      "Epoch: 381, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50219\n",
      "Acc: 0.6883086622807018\n",
      "Prec 0.5696015418533542\n",
      "Recall 0.5446689955795152\n",
      "F1 0.5568563275424495\n",
      "468\n",
      "468\n",
      "71744\n",
      "50223\n",
      "Acc: 0.7000306645851918\n",
      "Prec 0.5818485685923593\n",
      "Recall 0.5352025041350291\n",
      "F1 0.5575516080525899\n",
      "Epoch: 382, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50422\n",
      "Acc: 0.6910910087719299\n",
      "Prec 0.574860649523126\n",
      "Recall 0.5415131582423627\n",
      "F1 0.5576888381063059\n",
      "468\n",
      "468\n",
      "71744\n",
      "50552\n",
      "Acc: 0.7046164139161463\n",
      "Prec 0.5839170204695721\n",
      "Recall 0.5493729218206193\n",
      "F1 0.5661184974215854\n",
      "Epoch: 383, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.821s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50356\n",
      "Acc: 0.6901864035087719\n",
      "Prec 0.5720345706636639\n",
      "Recall 0.5445938358436492\n",
      "F1 0.5579770302410973\n",
      "468\n",
      "468\n",
      "71744\n",
      "50261\n",
      "Acc: 0.700560325602141\n",
      "Prec 0.5827010314810065\n",
      "Recall 0.5383871172582749\n",
      "F1 0.5596682632231452\n",
      "Epoch: 384, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50319\n",
      "Acc: 0.6896792763157895\n",
      "Prec 0.5736373322865838\n",
      "Recall 0.53882215315999\n",
      "F1 0.5556849603229056\n",
      "468\n",
      "468\n",
      "71744\n",
      "50428\n",
      "Acc: 0.7028880463871543\n",
      "Prec 0.5833449494473676\n",
      "Recall 0.5483723975449123\n",
      "F1 0.5653183091596647\n",
      "Epoch: 385, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.806s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50258\n",
      "Acc: 0.688843201754386\n",
      "Prec 0.5714102267874605\n",
      "Recall 0.5384773234781045\n",
      "F1 0.5544551778329372\n",
      "468\n",
      "468\n",
      "71744\n",
      "50325\n",
      "Acc: 0.7014523862622658\n",
      "Prec 0.5826128678914073\n",
      "Recall 0.5443194454754453\n",
      "F1 0.5628155469782409\n",
      "Epoch: 386, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.871s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50504\n",
      "Acc: 0.6922149122807018\n",
      "Prec 0.5753508793082154\n",
      "Recall 0.5442632966532032\n",
      "F1 0.5593754938583401\n",
      "468\n",
      "468\n",
      "71744\n",
      "50535\n",
      "Acc: 0.7043794603033007\n",
      "Prec 0.5843363668643365\n",
      "Recall 0.5516751164728063\n",
      "F1 0.5675362229652902\n",
      "Epoch: 387, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50456\n",
      "Acc: 0.6915570175438597\n",
      "Prec 0.574716469116798\n",
      "Recall 0.5449300341546469\n",
      "F1 0.5594270409990786\n",
      "468\n",
      "468\n",
      "71744\n",
      "50413\n",
      "Acc: 0.7026789696699376\n",
      "Prec 0.5827316548275132\n",
      "Recall 0.5494063764327124\n",
      "F1 0.5655785391381011\n",
      "Epoch: 388, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.826s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50470\n",
      "Acc: 0.6917489035087719\n",
      "Prec 0.5773675915194519\n",
      "Recall 0.5415668170838589\n",
      "F1 0.5588944739251769\n",
      "468\n",
      "468\n",
      "71744\n",
      "50651\n",
      "Acc: 0.705996320249777\n",
      "Prec 0.5838901383534972\n",
      "Recall 0.5569949341258874\n",
      "F1 0.5701255227087532\n",
      "Epoch: 389, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50347\n",
      "Acc: 0.690063048245614\n",
      "Prec 0.5729394733874233\n",
      "Recall 0.5446054590079517\n",
      "F1 0.5584132786842444\n",
      "468\n",
      "468\n",
      "71744\n",
      "50479\n",
      "Acc: 0.7035989072256913\n",
      "Prec 0.585723247312073\n",
      "Recall 0.5445612911671095\n",
      "F1 0.564392764767045\n",
      "Epoch: 390, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.818s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50395\n",
      "Acc: 0.6907209429824561\n",
      "Prec 0.5746305858223975\n",
      "Recall 0.5395455736641973\n",
      "F1 0.5565356724477095\n",
      "468\n",
      "468\n",
      "71744\n",
      "50217\n",
      "Acc: 0.699947033898305\n",
      "Prec 0.5805366215292879\n",
      "Recall 0.5408495398032679\n",
      "F1 0.5599907960696604\n",
      "Epoch: 391, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50217\n",
      "Acc: 0.68828125\n",
      "Prec 0.5710150259276746\n",
      "Recall 0.5356407625286203\n",
      "F1 0.5527625248856298\n",
      "468\n",
      "468\n",
      "71744\n",
      "50554\n",
      "Acc: 0.7046442908117752\n",
      "Prec 0.5834399172084157\n",
      "Recall 0.5527889172140673\n",
      "F1 0.5677009952964864\n",
      "Epoch: 392, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50323\n",
      "Acc: 0.689734100877193\n",
      "Prec 0.5732663665028496\n",
      "Recall 0.5387603024789634\n",
      "F1 0.5554779748238984\n",
      "468\n",
      "468\n",
      "71744\n",
      "50526\n",
      "Acc: 0.7042540142729705\n",
      "Prec 0.5828955027915272\n",
      "Recall 0.5518934213743598\n",
      "F1 0.5669709784589281\n",
      "Epoch: 393, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50365\n",
      "Acc: 0.6903097587719298\n",
      "Prec 0.5714289480124283\n",
      "Recall 0.5426374722257904\n",
      "F1 0.556661172571386\n",
      "468\n",
      "468\n",
      "71744\n",
      "50539\n",
      "Acc: 0.7044352140945584\n",
      "Prec 0.5831784224502904\n",
      "Recall 0.5502506657999761\n",
      "F1 0.5662362446138263\n",
      "Epoch: 394, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50240\n",
      "Acc: 0.6885964912280702\n",
      "Prec 0.5703854663664187\n",
      "Recall 0.541414098601383\n",
      "F1 0.5555223132994255\n",
      "468\n",
      "468\n",
      "71744\n",
      "50640\n",
      "Acc: 0.705842997323818\n",
      "Prec 0.5860941712841371\n",
      "Recall 0.5517644132269172\n",
      "F1 0.5684114193386683\n",
      "Epoch: 395, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50417\n",
      "Acc: 0.6910224780701755\n",
      "Prec 0.5763190322768083\n",
      "Recall 0.5399948530270079\n",
      "F1 0.5575659592306939\n",
      "468\n",
      "468\n",
      "71744\n",
      "50378\n",
      "Acc: 0.7021911239964318\n",
      "Prec 0.5830990480833246\n",
      "Recall 0.5451266750403609\n",
      "F1 0.5634738488691868\n",
      "Epoch: 396, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50458\n",
      "Acc: 0.6915844298245614\n",
      "Prec 0.5754292190843261\n",
      "Recall 0.5400046232417065\n",
      "F1 0.5571544037177879\n",
      "468\n",
      "468\n",
      "71744\n",
      "50703\n",
      "Acc: 0.7067211195361285\n",
      "Prec 0.5845147254775884\n",
      "Recall 0.5582399811323868\n",
      "F1 0.5710752927724811\n",
      "Epoch: 397, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.786s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50723\n",
      "Acc: 0.6952165570175438\n",
      "Prec 0.577424923323474\n",
      "Recall 0.5524298505473054\n",
      "F1 0.5646509117292242\n",
      "468\n",
      "468\n",
      "71744\n",
      "50657\n",
      "Acc: 0.7060799509366636\n",
      "Prec 0.5860138788036467\n",
      "Recall 0.5544028988418609\n",
      "F1 0.5697702796710244\n",
      "Epoch: 398, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50309\n",
      "Acc: 0.6895422149122807\n",
      "Prec 0.5720876846147307\n",
      "Recall 0.5501631363803975\n",
      "F1 0.5609112490078656\n",
      "468\n",
      "468\n",
      "71744\n",
      "50207\n",
      "Acc: 0.6998076494201606\n",
      "Prec 0.5811953479397247\n",
      "Recall 0.5374593451744251\n",
      "F1 0.5584723740844876\n",
      "Epoch: 399, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50442\n",
      "Acc: 0.6913651315789474\n",
      "Prec 0.5764252191075757\n",
      "Recall 0.5385714041292502\n",
      "F1 0.5568557485475699\n",
      "468\n",
      "468\n",
      "71744\n",
      "50470\n",
      "Acc: 0.7034734611953612\n",
      "Prec 0.5832330376509508\n",
      "Recall 0.5493305019659125\n",
      "F1 0.5657743448889149\n",
      "Epoch: 400, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50430\n",
      "Acc: 0.6912006578947368\n",
      "Prec 0.5762051832517282\n",
      "Recall 0.5406370949833043\n",
      "F1 0.5578547704691742\n",
      "468\n",
      "468\n",
      "71744\n",
      "50457\n",
      "Acc: 0.7032922613737734\n",
      "Prec 0.58307002404041\n",
      "Recall 0.5494164177575901\n",
      "F1 0.5657431861197575\n",
      "Epoch: 401, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50459\n",
      "Acc: 0.6915981359649123\n",
      "Prec 0.5749226226129392\n",
      "Recall 0.5419527938135528\n",
      "F1 0.5579510784624816\n",
      "468\n",
      "468\n",
      "71744\n",
      "50470\n",
      "Acc: 0.7034734611953612\n",
      "Prec 0.5825392000082198\n",
      "Recall 0.5498325470841703\n",
      "F1 0.5657135352225654\n",
      "Epoch: 402, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.867s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50577\n",
      "Acc: 0.6932154605263158\n",
      "Prec 0.5772637646504903\n",
      "Recall 0.5469628955534698\n",
      "F1 0.5617049859928533\n",
      "468\n",
      "468\n",
      "71744\n",
      "50604\n",
      "Acc: 0.7053412132024978\n",
      "Prec 0.584729423514251\n",
      "Recall 0.5517937710919746\n",
      "F1 0.5677843711428244\n",
      "Epoch: 403, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50569\n",
      "Acc: 0.6931058114035088\n",
      "Prec 0.5769746477553415\n",
      "Recall 0.5455370897567297\n",
      "F1 0.5608156417098994\n",
      "468\n",
      "468\n",
      "71744\n",
      "50795\n",
      "Acc: 0.7080034567350579\n",
      "Prec 0.5868963890746682\n",
      "Recall 0.5581928578498075\n",
      "F1 0.5721848730292523\n",
      "Epoch: 404, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50587\n",
      "Acc: 0.6933525219298246\n",
      "Prec 0.5760526862427863\n",
      "Recall 0.5485666753047566\n",
      "F1 0.56197379788614\n",
      "468\n",
      "468\n",
      "71744\n",
      "50727\n",
      "Acc: 0.7070556422836753\n",
      "Prec 0.5856168125777607\n",
      "Recall 0.5541117750955203\n",
      "F1 0.5694288535934579\n",
      "Epoch: 405, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50528\n",
      "Acc: 0.6925438596491228\n",
      "Prec 0.5769325030579099\n",
      "Recall 0.5428515111113384\n",
      "F1 0.5593733740279967\n",
      "468\n",
      "468\n",
      "71744\n",
      "50583\n",
      "Acc: 0.7050485057983943\n",
      "Prec 0.5840955014164314\n",
      "Recall 0.5522162219936325\n",
      "F1 0.5677086743551264\n",
      "Epoch: 406, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.839s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50456\n",
      "Acc: 0.6915570175438597\n",
      "Prec 0.5744003180326561\n",
      "Recall 0.5498815227409289\n",
      "F1 0.5618735624607124\n",
      "468\n",
      "468\n",
      "71744\n",
      "50545\n",
      "Acc: 0.7045188447814451\n",
      "Prec 0.5843324285575027\n",
      "Recall 0.5474517343893742\n",
      "F1 0.5652911782063431\n",
      "Epoch: 407, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50269\n",
      "Acc: 0.6889939692982456\n",
      "Prec 0.572504968423634\n",
      "Recall 0.5390173992042172\n",
      "F1 0.5552567327453347\n",
      "468\n",
      "468\n",
      "71744\n",
      "50507\n",
      "Acc: 0.703989183764496\n",
      "Prec 0.583923446089523\n",
      "Recall 0.5482002987488462\n",
      "F1 0.5654982665140255\n",
      "Epoch: 408, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50579\n",
      "Acc: 0.6932428728070176\n",
      "Prec 0.5777553525632267\n",
      "Recall 0.5424014025707885\n",
      "F1 0.5595204637864858\n",
      "468\n",
      "468\n",
      "71744\n",
      "50702\n",
      "Acc: 0.706707181088314\n",
      "Prec 0.5844278696239834\n",
      "Recall 0.5577611236694991\n",
      "F1 0.5707832016929392\n",
      "Epoch: 409, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.881s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50697\n",
      "Acc: 0.6948601973684211\n",
      "Prec 0.5786945115845455\n",
      "Recall 0.5502508882447381\n",
      "F1 0.5641143833349297\n",
      "468\n",
      "468\n",
      "71744\n",
      "50590\n",
      "Acc: 0.7051460749330954\n",
      "Prec 0.5837166395717491\n",
      "Recall 0.553693936845698\n",
      "F1 0.5683090536837133\n",
      "Epoch: 410, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50591\n",
      "Acc: 0.693407346491228\n",
      "Prec 0.5775439688436019\n",
      "Recall 0.5477020235362852\n",
      "F1 0.562227286404814\n",
      "468\n",
      "468\n",
      "71744\n",
      "50648\n",
      "Acc: 0.7059545049063336\n",
      "Prec 0.5847187228694052\n",
      "Recall 0.5552118450590118\n",
      "F1 0.5695833941094169\n",
      "Epoch: 411, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.867s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50614\n",
      "Acc: 0.6937225877192983\n",
      "Prec 0.5768231335339803\n",
      "Recall 0.5502646624894797\n",
      "F1 0.5632309887660129\n",
      "468\n",
      "468\n",
      "71744\n",
      "50377\n",
      "Acc: 0.7021771855486173\n",
      "Prec 0.5830423411171594\n",
      "Recall 0.5447971347602382\n",
      "F1 0.5632712875871336\n",
      "Epoch: 412, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50583\n",
      "Acc: 0.6932976973684211\n",
      "Prec 0.5783901268744006\n",
      "Recall 0.5451026600452998\n",
      "F1 0.5612532637037899\n",
      "468\n",
      "468\n",
      "71744\n",
      "50601\n",
      "Acc: 0.7052993978590544\n",
      "Prec 0.5857947799870535\n",
      "Recall 0.553659130236247\n",
      "F1 0.5692737994483799\n",
      "Epoch: 413, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50797\n",
      "Acc: 0.6962308114035087\n",
      "Prec 0.5806615285136744\n",
      "Recall 0.550972187750109\n",
      "F1 0.5654273960019168\n",
      "468\n",
      "468\n",
      "71744\n",
      "50653\n",
      "Acc: 0.7060241971454059\n",
      "Prec 0.5843459638175534\n",
      "Recall 0.5545349197783762\n",
      "F1 0.5690502788057212\n",
      "Epoch: 414, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50502\n",
      "Acc: 0.6921875\n",
      "Prec 0.5767165266951437\n",
      "Recall 0.5449092849190641\n",
      "F1 0.5603619084161175\n",
      "468\n",
      "468\n",
      "71744\n",
      "50558\n",
      "Acc: 0.704700044603033\n",
      "Prec 0.5845633624823044\n",
      "Recall 0.550605255238914\n",
      "F1 0.5670763873811253\n",
      "Epoch: 415, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50530\n",
      "Acc: 0.6925712719298246\n",
      "Prec 0.5755295696278918\n",
      "Recall 0.5448947891040045\n",
      "F1 0.5597933693987992\n",
      "468\n",
      "468\n",
      "71744\n",
      "50720\n",
      "Acc: 0.7069580731489741\n",
      "Prec 0.5849556963443775\n",
      "Recall 0.5547456601687543\n",
      "F1 0.5694502899089883\n",
      "Epoch: 416, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50691\n",
      "Acc: 0.6947779605263158\n",
      "Prec 0.5779759405984657\n",
      "Recall 0.5505293429901971\n",
      "F1 0.5639188747614139\n",
      "468\n",
      "468\n",
      "71744\n",
      "50470\n",
      "Acc: 0.7034734611953612\n",
      "Prec 0.5828214873814471\n",
      "Recall 0.5474238968212567\n",
      "F1 0.5645683923736203\n",
      "Epoch: 417, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50576\n",
      "Acc: 0.6932017543859649\n",
      "Prec 0.575427885159762\n",
      "Recall 0.5440829622654137\n",
      "F1 0.5593166141228851\n",
      "468\n",
      "468\n",
      "71744\n",
      "50724\n",
      "Acc: 0.707013826940232\n",
      "Prec 0.5847131973984859\n",
      "Recall 0.5582301676328003\n",
      "F1 0.5711648646596459\n",
      "Epoch: 418, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50737\n",
      "Acc: 0.6954084429824562\n",
      "Prec 0.5795414693821287\n",
      "Recall 0.5476567595806857\n",
      "F1 0.5631481579890173\n",
      "468\n",
      "468\n",
      "71744\n",
      "50874\n",
      "Acc: 0.7091045941123997\n",
      "Prec 0.5872563682437577\n",
      "Recall 0.5614210146229658\n",
      "F1 0.5740481548968777\n",
      "Epoch: 419, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50764\n",
      "Acc: 0.6957785087719298\n",
      "Prec 0.5796078237902863\n",
      "Recall 0.5516974573588415\n",
      "F1 0.5653083530655609\n",
      "468\n",
      "468\n",
      "71744\n",
      "50626\n",
      "Acc: 0.7056478590544157\n",
      "Prec 0.5853450962815759\n",
      "Recall 0.5536195499910294\n",
      "F1 0.5690404699625771\n",
      "Epoch: 420, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50574\n",
      "Acc: 0.6931743421052632\n",
      "Prec 0.576475123893617\n",
      "Recall 0.5477936488516939\n",
      "F1 0.56176853657298\n",
      "468\n",
      "468\n",
      "71744\n",
      "50518\n",
      "Acc: 0.704142506690455\n",
      "Prec 0.5826658838491526\n",
      "Recall 0.5517020051324432\n",
      "F1 0.5667613471154245\n",
      "Epoch: 421, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50619\n",
      "Acc: 0.6937911184210527\n",
      "Prec 0.578128511673651\n",
      "Recall 0.5467770640111068\n",
      "F1 0.5620159008308007\n",
      "468\n",
      "468\n",
      "71744\n",
      "50427\n",
      "Acc: 0.7028741079393399\n",
      "Prec 0.5843329957017988\n",
      "Recall 0.5437889704973317\n",
      "F1 0.5633324191547824\n",
      "Epoch: 422, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50456\n",
      "Acc: 0.6915570175438597\n",
      "Prec 0.5741137242599536\n",
      "Recall 0.5414520799122934\n",
      "F1 0.5573047666827688\n",
      "468\n",
      "468\n",
      "71744\n",
      "50714\n",
      "Acc: 0.7068744424620874\n",
      "Prec 0.5846896232712163\n",
      "Recall 0.5582741563718218\n",
      "F1 0.5711766409133993\n",
      "Epoch: 423, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50660\n",
      "Acc: 0.6943530701754386\n",
      "Prec 0.5779232039925327\n",
      "Recall 0.5482865574699431\n",
      "F1 0.5627149308093138\n",
      "468\n",
      "468\n",
      "71744\n",
      "50664\n",
      "Acc: 0.7061775200713648\n",
      "Prec 0.5854097533542556\n",
      "Recall 0.5533139171981724\n",
      "F1 0.5689095118876704\n",
      "Epoch: 424, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50582\n",
      "Acc: 0.6932839912280702\n",
      "Prec 0.5778289959497592\n",
      "Recall 0.5452553386953979\n",
      "F1 0.5610697882170237\n",
      "468\n",
      "468\n",
      "71744\n",
      "50498\n",
      "Acc: 0.7038637377341659\n",
      "Prec 0.5833556951679931\n",
      "Recall 0.5514358449215432\n",
      "F1 0.5669468431697601\n",
      "Epoch: 425, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50811\n",
      "Acc: 0.6964226973684211\n",
      "Prec 0.5809389069702132\n",
      "Recall 0.5539527071087197\n",
      "F1 0.567124959227248\n",
      "468\n",
      "468\n",
      "71744\n",
      "50545\n",
      "Acc: 0.7045188447814451\n",
      "Prec 0.5844819441579552\n",
      "Recall 0.5499511058901076\n",
      "F1 0.5666909855083105\n",
      "Epoch: 426, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50562\n",
      "Acc: 0.6930098684210526\n",
      "Prec 0.5773680955154176\n",
      "Recall 0.5473093322668776\n",
      "F1 0.5619370301613456\n",
      "468\n",
      "468\n",
      "71744\n",
      "50731\n",
      "Acc: 0.7071113960749331\n",
      "Prec 0.5867014851099787\n",
      "Recall 0.5567572691339736\n",
      "F1 0.5713372964863215\n",
      "Epoch: 427, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50685\n",
      "Acc: 0.6946957236842105\n",
      "Prec 0.577303841537062\n",
      "Recall 0.5477101211870105\n",
      "F1 0.5621177469555422\n",
      "468\n",
      "468\n",
      "71744\n",
      "50537\n",
      "Acc: 0.7044073371989296\n",
      "Prec 0.5840827146458626\n",
      "Recall 0.5503482059233081\n",
      "F1 0.56671387968672\n",
      "Epoch: 428, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50416\n",
      "Acc: 0.6910087719298246\n",
      "Prec 0.5728876669578689\n",
      "Recall 0.5482697183427588\n",
      "F1 0.5603084168612222\n",
      "468\n",
      "468\n",
      "71744\n",
      "50642\n",
      "Acc: 0.7058708742194469\n",
      "Prec 0.5861009513443955\n",
      "Recall 0.5517555759430465\n",
      "F1 0.5684099184995087\n",
      "Epoch: 429, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50571\n",
      "Acc: 0.6931332236842105\n",
      "Prec 0.5782296979699661\n",
      "Recall 0.5420627193720359\n",
      "F1 0.559562410048135\n",
      "468\n",
      "468\n",
      "71744\n",
      "50662\n",
      "Acc: 0.7061496431757359\n",
      "Prec 0.583855838873597\n",
      "Recall 0.5571995833063291\n",
      "F1 0.5702163519977332\n",
      "Epoch: 430, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50350\n",
      "Acc: 0.6901041666666666\n",
      "Prec 0.5714569801954714\n",
      "Recall 0.5442843194755058\n",
      "F1 0.5575397695988155\n",
      "468\n",
      "468\n",
      "71744\n",
      "50536\n",
      "Acc: 0.7043933987511151\n",
      "Prec 0.5852645439200478\n",
      "Recall 0.5482692691983069\n",
      "F1 0.5661631970200802\n",
      "Epoch: 431, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50513\n",
      "Acc: 0.6923382675438596\n",
      "Prec 0.5775312911636652\n",
      "Recall 0.543803379900562\n",
      "F1 0.5601600953532774\n",
      "468\n",
      "468\n",
      "71744\n",
      "50704\n",
      "Acc: 0.7067350579839429\n",
      "Prec 0.5864627920893699\n",
      "Recall 0.5524698883357653\n",
      "F1 0.5689590593497643\n",
      "Epoch: 432, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50624\n",
      "Acc: 0.6938596491228071\n",
      "Prec 0.5789312288623147\n",
      "Recall 0.5435052316148394\n",
      "F1 0.5606591779780845\n",
      "468\n",
      "468\n",
      "71744\n",
      "50770\n",
      "Acc: 0.7076549955396967\n",
      "Prec 0.5852011465986782\n",
      "Recall 0.5608947119461181\n",
      "F1 0.5727901834821509\n",
      "Epoch: 433, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50712\n",
      "Acc: 0.6950657894736842\n",
      "Prec 0.5776932151342852\n",
      "Recall 0.5480702977672135\n",
      "F1 0.5624920133016422\n",
      "468\n",
      "468\n",
      "71744\n",
      "50577\n",
      "Acc: 0.7049648751115076\n",
      "Prec 0.5849925424812178\n",
      "Recall 0.5508185828762601\n",
      "F1 0.5673914545277408\n",
      "Epoch: 434, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50591\n",
      "Acc: 0.693407346491228\n",
      "Prec 0.5753717915096058\n",
      "Recall 0.5469331095679559\n",
      "F1 0.5607921390807263\n",
      "468\n",
      "468\n",
      "71744\n",
      "50841\n",
      "Acc: 0.7086446253345228\n",
      "Prec 0.587194450898708\n",
      "Recall 0.5600435406743635\n",
      "F1 0.5732977146175781\n",
      "Epoch: 435, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50797\n",
      "Acc: 0.6962308114035087\n",
      "Prec 0.5811202816921127\n",
      "Recall 0.5518265734890596\n",
      "F1 0.5660947155016822\n",
      "468\n",
      "468\n",
      "71744\n",
      "50706\n",
      "Acc: 0.7067629348795718\n",
      "Prec 0.5876876723033729\n",
      "Recall 0.5535745326994986\n",
      "F1 0.570121269489998\n",
      "Epoch: 436, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50593\n",
      "Acc: 0.6934347587719298\n",
      "Prec 0.5780270164078862\n",
      "Recall 0.5496169951759701\n",
      "F1 0.5634641227640813\n",
      "468\n",
      "468\n",
      "71744\n",
      "50755\n",
      "Acc: 0.70744591882248\n",
      "Prec 0.5870497504416069\n",
      "Recall 0.5555492340232066\n",
      "F1 0.5708652705377801\n",
      "Epoch: 437, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50550\n",
      "Acc: 0.6928453947368421\n",
      "Prec 0.575574473760693\n",
      "Recall 0.5469859700822651\n",
      "F1 0.5609161869391963\n",
      "468\n",
      "468\n",
      "71744\n",
      "50647\n",
      "Acc: 0.7059405664585192\n",
      "Prec 0.5863747761936645\n",
      "Recall 0.5512076486199973\n",
      "F1 0.5682476355921728\n",
      "Epoch: 438, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50477\n",
      "Acc: 0.691844846491228\n",
      "Prec 0.5755133760306229\n",
      "Recall 0.5420128662065646\n",
      "F1 0.5582609923470022\n",
      "468\n",
      "468\n",
      "71744\n",
      "50601\n",
      "Acc: 0.7052993978590544\n",
      "Prec 0.5840012162292715\n",
      "Recall 0.5540724725150434\n",
      "F1 0.5686433155044002\n",
      "Epoch: 439, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50627\n",
      "Acc: 0.6939007675438597\n",
      "Prec 0.5768519725442398\n",
      "Recall 0.5449173946830047\n",
      "F1 0.5604301261560157\n",
      "468\n",
      "468\n",
      "71744\n",
      "50727\n",
      "Acc: 0.7070556422836753\n",
      "Prec 0.5859732052629699\n",
      "Recall 0.5564679002124752\n",
      "F1 0.5708395427136826\n",
      "Epoch: 440, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50814\n",
      "Acc: 0.6964638157894737\n",
      "Prec 0.5817624810675374\n",
      "Recall 0.5493364847038315\n",
      "F1 0.5650846936532665\n",
      "468\n",
      "468\n",
      "71744\n",
      "50754\n",
      "Acc: 0.7074319803746655\n",
      "Prec 0.5861478890865167\n",
      "Recall 0.559633275795292\n",
      "F1 0.5725837940507952\n",
      "Epoch: 441, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.894s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50723\n",
      "Acc: 0.6952165570175438\n",
      "Prec 0.5803208953002685\n",
      "Recall 0.5491654378583775\n",
      "F1 0.5643134745591907\n",
      "468\n",
      "468\n",
      "71744\n",
      "50538\n",
      "Acc: 0.704421275646744\n",
      "Prec 0.5824133935619206\n",
      "Recall 0.5542334131602733\n",
      "F1 0.567974081438605\n",
      "Epoch: 442, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50623\n",
      "Acc: 0.6938459429824562\n",
      "Prec 0.578586976667736\n",
      "Recall 0.5478130790419395\n",
      "F1 0.562779647559985\n",
      "468\n",
      "468\n",
      "71744\n",
      "50708\n",
      "Acc: 0.7067908117752008\n",
      "Prec 0.585932550580892\n",
      "Recall 0.5573879468794246\n",
      "F1 0.571303920647926\n",
      "Epoch: 443, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50605\n",
      "Acc: 0.6935992324561403\n",
      "Prec 0.5773858183501347\n",
      "Recall 0.550934095530016\n",
      "F1 0.5638498969865351\n",
      "468\n",
      "468\n",
      "71744\n",
      "50635\n",
      "Acc: 0.7057733050847458\n",
      "Prec 0.5854716262544528\n",
      "Recall 0.5525189583683038\n",
      "F1 0.5685181889260393\n",
      "Epoch: 444, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.790s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50721\n",
      "Acc: 0.6951891447368421\n",
      "Prec 0.5784320306190364\n",
      "Recall 0.5474345424929891\n",
      "F1 0.562506573349905\n",
      "468\n",
      "468\n",
      "71744\n",
      "51035\n",
      "Acc: 0.7113486842105263\n",
      "Prec 0.5902063371711675\n",
      "Recall 0.5666034712795374\n",
      "F1 0.5781641147393761\n",
      "Epoch: 445, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50837\n",
      "Acc: 0.6967790570175438\n",
      "Prec 0.5799691624722781\n",
      "Recall 0.5530306450040463\n",
      "F1 0.5661796549090814\n",
      "468\n",
      "468\n",
      "71744\n",
      "50659\n",
      "Acc: 0.7061078278322926\n",
      "Prec 0.5870142608562046\n",
      "Recall 0.5530961280494696\n",
      "F1 0.5695506644773671\n",
      "Epoch: 446, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50642\n",
      "Acc: 0.6941063596491228\n",
      "Prec 0.5787913573299266\n",
      "Recall 0.5495679686348273\n",
      "F1 0.5638012345743453\n",
      "468\n",
      "468\n",
      "71744\n",
      "50498\n",
      "Acc: 0.7038637377341659\n",
      "Prec 0.5847457663483654\n",
      "Recall 0.5483564390953525\n",
      "F1 0.5659667851150424\n",
      "Epoch: 447, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50221\n",
      "Acc: 0.6883360745614036\n",
      "Prec 0.5712799337765421\n",
      "Recall 0.5413846704308493\n",
      "F1 0.5559306865732255\n",
      "468\n",
      "468\n",
      "71744\n",
      "50329\n",
      "Acc: 0.7015081400535237\n",
      "Prec 0.5828855711589995\n",
      "Recall 0.5427206661413129\n",
      "F1 0.5620865183233186\n",
      "Epoch: 448, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50523\n",
      "Acc: 0.6924753289473684\n",
      "Prec 0.5761500195549886\n",
      "Recall 0.5430688708984027\n",
      "F1 0.5591205496202268\n",
      "468\n",
      "468\n",
      "71744\n",
      "50628\n",
      "Acc: 0.7056757359500446\n",
      "Prec 0.5839361782227671\n",
      "Recall 0.5516953134884331\n",
      "F1 0.5673580827111715\n",
      "Epoch: 449, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.879s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50730\n",
      "Acc: 0.6953125\n",
      "Prec 0.580863021728237\n",
      "Recall 0.5456549313738255\n",
      "F1 0.5627087813131343\n",
      "468\n",
      "468\n",
      "71744\n",
      "50801\n",
      "Acc: 0.7080870874219447\n",
      "Prec 0.586538732570079\n",
      "Recall 0.5612121517540668\n",
      "F1 0.5735960105778369\n",
      "Epoch: 450, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.811s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50417\n",
      "Acc: 0.6910224780701755\n",
      "Prec 0.5742847107409176\n",
      "Recall 0.5481845381846354\n",
      "F1 0.5609311778391297\n",
      "468\n",
      "468\n",
      "71744\n",
      "50516\n",
      "Acc: 0.7041146297948261\n",
      "Prec 0.585255000042649\n",
      "Recall 0.54701133201498\n",
      "F1 0.5654873029033285\n",
      "Epoch: 451, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.790s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50219\n",
      "Acc: 0.6883086622807018\n",
      "Prec 0.5711942632812296\n",
      "Recall 0.5400986493155286\n",
      "F1 0.5552114057383766\n",
      "468\n",
      "468\n",
      "71744\n",
      "50480\n",
      "Acc: 0.7036128456735058\n",
      "Prec 0.5833813127815041\n",
      "Recall 0.5504247774648775\n",
      "F1 0.5664240685021356\n",
      "Epoch: 452, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50419\n",
      "Acc: 0.6910498903508772\n",
      "Prec 0.5743450736253486\n",
      "Recall 0.5380401943409753\n",
      "F1 0.555600193442187\n",
      "468\n",
      "468\n",
      "71744\n",
      "50794\n",
      "Acc: 0.7079895182872435\n",
      "Prec 0.5860101304410735\n",
      "Recall 0.5607014885060843\n",
      "F1 0.5730765207029717\n",
      "Epoch: 453, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50584\n",
      "Acc: 0.693311403508772\n",
      "Prec 0.5773991914308064\n",
      "Recall 0.5461638632244252\n",
      "F1 0.5613473524390246\n",
      "468\n",
      "468\n",
      "71744\n",
      "50700\n",
      "Acc: 0.7066793041926851\n",
      "Prec 0.5850740909636326\n",
      "Recall 0.5555394706661873\n",
      "F1 0.5699244016176699\n",
      "Epoch: 454, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50784\n",
      "Acc: 0.6960526315789474\n",
      "Prec 0.5806615578972992\n",
      "Recall 0.5487476969769701\n",
      "F1 0.5642537304241846\n",
      "468\n",
      "468\n",
      "71744\n",
      "50606\n",
      "Acc: 0.7053690900981266\n",
      "Prec 0.5849252527343097\n",
      "Recall 0.553659530712312\n",
      "F1 0.5688631108354189\n",
      "Epoch: 455, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50590\n",
      "Acc: 0.6933936403508771\n",
      "Prec 0.5770103471235267\n",
      "Recall 0.5539510984678447\n",
      "F1 0.565245644513116\n",
      "468\n",
      "468\n",
      "71744\n",
      "50874\n",
      "Acc: 0.7091045941123997\n",
      "Prec 0.5897220429622717\n",
      "Recall 0.5557774717119441\n",
      "F1 0.5722468178322858\n",
      "Epoch: 456, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50530\n",
      "Acc: 0.6925712719298246\n",
      "Prec 0.5786851085079386\n",
      "Recall 0.5409011585233149\n",
      "F1 0.5591555645678465\n",
      "468\n",
      "468\n",
      "71744\n",
      "50514\n",
      "Acc: 0.7040867528991972\n",
      "Prec 0.5832008897253645\n",
      "Recall 0.5522603214645744\n",
      "F1 0.5673090505674325\n",
      "Epoch: 457, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.812s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50496\n",
      "Acc: 0.6921052631578948\n",
      "Prec 0.5761833012332566\n",
      "Recall 0.5451063374217336\n",
      "F1 0.5602141644607912\n",
      "468\n",
      "468\n",
      "71744\n",
      "50580\n",
      "Acc: 0.7050066904549509\n",
      "Prec 0.5857092592193767\n",
      "Recall 0.5506711945671106\n",
      "F1 0.5676500618585117\n",
      "Epoch: 458, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.797s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50521\n",
      "Acc: 0.6924479166666667\n",
      "Prec 0.5783474240189569\n",
      "Recall 0.5424709946532552\n",
      "F1 0.5598350225799869\n",
      "468\n",
      "468\n",
      "71744\n",
      "50767\n",
      "Acc: 0.7076131801962533\n",
      "Prec 0.5875667998168914\n",
      "Recall 0.5581282550305257\n",
      "F1 0.572469316871314\n",
      "Epoch: 459, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50100\n",
      "Acc: 0.6866776315789473\n",
      "Prec 0.5696269067725993\n",
      "Recall 0.5424322833197859\n",
      "F1 0.5556970823745069\n",
      "468\n",
      "468\n",
      "71744\n",
      "50251\n",
      "Acc: 0.7004209411239964\n",
      "Prec 0.582262342581035\n",
      "Recall 0.5401507414882403\n",
      "F1 0.5604165534948706\n",
      "Epoch: 460, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50343\n",
      "Acc: 0.6900082236842106\n",
      "Prec 0.5742232504042315\n",
      "Recall 0.5361901645150162\n",
      "F1 0.5545553664352714\n",
      "468\n",
      "468\n",
      "71744\n",
      "50624\n",
      "Acc: 0.7056199821587869\n",
      "Prec 0.5856088772174227\n",
      "Recall 0.5549467310468098\n",
      "F1 0.5698656509670379\n",
      "Epoch: 461, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50675\n",
      "Acc: 0.6945586622807017\n",
      "Prec 0.579699916766724\n",
      "Recall 0.5489347950342317\n",
      "F1 0.5638980471970866\n",
      "468\n",
      "468\n",
      "71744\n",
      "50604\n",
      "Acc: 0.7053412132024978\n",
      "Prec 0.5864313073017805\n",
      "Recall 0.5526108578586065\n",
      "F1 0.5690189840470908\n",
      "Epoch: 462, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50528\n",
      "Acc: 0.6925438596491228\n",
      "Prec 0.5762107420771397\n",
      "Recall 0.5426994990881562\n",
      "F1 0.5589532914969221\n",
      "468\n",
      "468\n",
      "71744\n",
      "50814\n",
      "Acc: 0.7082682872435325\n",
      "Prec 0.5882871916165556\n",
      "Recall 0.5590612230404002\n",
      "F1 0.5733019763529944\n",
      "Epoch: 463, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.903s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50683\n",
      "Acc: 0.6946683114035088\n",
      "Prec 0.5792633937913131\n",
      "Recall 0.5487573117093658\n",
      "F1 0.563597850994187\n",
      "468\n",
      "468\n",
      "71744\n",
      "50834\n",
      "Acc: 0.7085470561998216\n",
      "Prec 0.5880535153753744\n",
      "Recall 0.5598168445991868\n",
      "F1 0.5735878804993225\n",
      "Epoch: 464, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50714\n",
      "Acc: 0.6950932017543859\n",
      "Prec 0.5785755986208747\n",
      "Recall 0.5509507592379445\n",
      "F1 0.5644253684190026\n",
      "468\n",
      "468\n",
      "71744\n",
      "50621\n",
      "Acc: 0.7055781668153435\n",
      "Prec 0.5848697584989783\n",
      "Recall 0.5503935269294965\n",
      "F1 0.5671081471698607\n",
      "Epoch: 465, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.906s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50886\n",
      "Acc: 0.6974506578947368\n",
      "Prec 0.5826573933653331\n",
      "Recall 0.5507344896093312\n",
      "F1 0.5662463742195922\n",
      "468\n",
      "468\n",
      "71744\n",
      "50768\n",
      "Acc: 0.7076271186440678\n",
      "Prec 0.5874812087798369\n",
      "Recall 0.5582999623620516\n",
      "F1 0.5725189853195424\n",
      "Epoch: 466, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.821s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50657\n",
      "Acc: 0.694311951754386\n",
      "Prec 0.5778013404149535\n",
      "Recall 0.5489151403870242\n",
      "F1 0.5629879553442461\n",
      "468\n",
      "468\n",
      "71744\n",
      "50636\n",
      "Acc: 0.7057872435325602\n",
      "Prec 0.5859016332300345\n",
      "Recall 0.5539424309715713\n",
      "F1 0.5694739924780704\n",
      "Epoch: 467, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50655\n",
      "Acc: 0.6942845394736842\n",
      "Prec 0.578847685621727\n",
      "Recall 0.5494422548622081\n",
      "F1 0.5637617888773522\n",
      "468\n",
      "468\n",
      "71744\n",
      "50639\n",
      "Acc: 0.7058290588760036\n",
      "Prec 0.5870604032585284\n",
      "Recall 0.5511241958234582\n",
      "F1 0.5685249877860029\n",
      "Epoch: 468, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.839s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50435\n",
      "Acc: 0.6912691885964912\n",
      "Prec 0.5751626294265696\n",
      "Recall 0.5422173756518829\n",
      "F1 0.5582043173912257\n",
      "468\n",
      "468\n",
      "71744\n",
      "50669\n",
      "Acc: 0.7062472123104371\n",
      "Prec 0.5881664366805249\n",
      "Recall 0.5523502026294812\n",
      "F1 0.5696959417915923\n",
      "Epoch: 469, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50708\n",
      "Acc: 0.6950109649122806\n",
      "Prec 0.5811145411815842\n",
      "Recall 0.5445974830900858\n",
      "F1 0.5622637223215192\n",
      "468\n",
      "468\n",
      "71744\n",
      "50722\n",
      "Acc: 0.7069859500446031\n",
      "Prec 0.5856858257954461\n",
      "Recall 0.559427448173937\n",
      "F1 0.5722555740195738\n",
      "Epoch: 470, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.815s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50763\n",
      "Acc: 0.6957648026315789\n",
      "Prec 0.5799571034291972\n",
      "Recall 0.5526487960888767\n",
      "F1 0.5659737338993497\n",
      "468\n",
      "468\n",
      "71744\n",
      "50856\n",
      "Acc: 0.7088537020517395\n",
      "Prec 0.5891446871741214\n",
      "Recall 0.5581660277737277\n",
      "F1 0.5732371284250094\n",
      "Epoch: 471, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50774\n",
      "Acc: 0.6959155701754386\n",
      "Prec 0.5812596649110346\n",
      "Recall 0.5515546639033356\n",
      "F1 0.5660176976329651\n",
      "468\n",
      "468\n",
      "71744\n",
      "50897\n",
      "Acc: 0.709425178412132\n",
      "Prec 0.5898264553925413\n",
      "Recall 0.5580495978306521\n",
      "F1 0.573498184403166\n",
      "Epoch: 472, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.814s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50644\n",
      "Acc: 0.6941337719298246\n",
      "Prec 0.5778928549456889\n",
      "Recall 0.5439359000392602\n",
      "F1 0.5604004511104873\n",
      "468\n",
      "468\n",
      "71744\n",
      "50857\n",
      "Acc: 0.708867640499554\n",
      "Prec 0.5878049355911449\n",
      "Recall 0.5635282232500461\n",
      "F1 0.5754106331909717\n",
      "Epoch: 473, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50791\n",
      "Acc: 0.6961485745614036\n",
      "Prec 0.5805513042966769\n",
      "Recall 0.5528260083735669\n",
      "F1 0.5663495406560667\n",
      "468\n",
      "468\n",
      "71744\n",
      "50871\n",
      "Acc: 0.7090627787689563\n",
      "Prec 0.5891337224097547\n",
      "Recall 0.559049885269543\n",
      "F1 0.5736976868835166\n",
      "Epoch: 474, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50721\n",
      "Acc: 0.6951891447368421\n",
      "Prec 0.5811463887586517\n",
      "Recall 0.5465141781664352\n",
      "F1 0.5632984789259291\n",
      "468\n",
      "468\n",
      "71744\n",
      "50844\n",
      "Acc: 0.7086864406779662\n",
      "Prec 0.588836907098255\n",
      "Recall 0.5581129243535119\n",
      "F1 0.5730634055229897\n",
      "Epoch: 475, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50107\n",
      "Acc: 0.6867735745614035\n",
      "Prec 0.5692685031423915\n",
      "Recall 0.5491155567965055\n",
      "F1 0.5590104549358942\n",
      "468\n",
      "468\n",
      "71744\n",
      "50407\n",
      "Acc: 0.7025953389830508\n",
      "Prec 0.5858140894685321\n",
      "Recall 0.5402062869950722\n",
      "F1 0.5620865496858503\n",
      "Epoch: 476, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50574\n",
      "Acc: 0.6931743421052632\n",
      "Prec 0.5798045998031436\n",
      "Recall 0.541786655995558\n",
      "F1 0.56015129154068\n",
      "468\n",
      "468\n",
      "71744\n",
      "50611\n",
      "Acc: 0.7054387823371989\n",
      "Prec 0.585168634707891\n",
      "Recall 0.550926009435353\n",
      "F1 0.5675312746667689\n",
      "Epoch: 477, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50543\n",
      "Acc: 0.692749451754386\n",
      "Prec 0.576303847800114\n",
      "Recall 0.5454465485673617\n",
      "F1 0.5604507842860371\n",
      "468\n",
      "468\n",
      "71744\n",
      "50925\n",
      "Acc: 0.7098154549509367\n",
      "Prec 0.5898641509390248\n",
      "Recall 0.5610285556794182\n",
      "F1 0.5750851156590069\n",
      "Epoch: 478, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50923\n",
      "Acc: 0.6979577850877193\n",
      "Prec 0.5830152199781585\n",
      "Recall 0.5519589529893192\n",
      "F1 0.5670621905952445\n",
      "468\n",
      "468\n",
      "71744\n",
      "50790\n",
      "Acc: 0.7079337644959858\n",
      "Prec 0.5885035017428877\n",
      "Recall 0.5609610716325196\n",
      "F1 0.5744023132922832\n",
      "Epoch: 479, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.888s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50587\n",
      "Acc: 0.6933525219298246\n",
      "Prec 0.5782917977291491\n",
      "Recall 0.5460192889690222\n",
      "F1 0.5616923642370076\n",
      "468\n",
      "468\n",
      "71744\n",
      "50858\n",
      "Acc: 0.7088815789473685\n",
      "Prec 0.5889507869302119\n",
      "Recall 0.5579481693228017\n",
      "F1 0.5730304515447531\n",
      "Epoch: 480, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50642\n",
      "Acc: 0.6941063596491228\n",
      "Prec 0.5788241066572822\n",
      "Recall 0.5460234962710638\n",
      "F1 0.5619455677732679\n",
      "468\n",
      "468\n",
      "71744\n",
      "50513\n",
      "Acc: 0.7040728144513827\n",
      "Prec 0.584988098408399\n",
      "Recall 0.5453869290336755\n",
      "F1 0.5644938268570439\n",
      "Epoch: 481, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.789s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50615\n",
      "Acc: 0.6937362938596491\n",
      "Prec 0.5784953272335603\n",
      "Recall 0.5476209784384447\n",
      "F1 0.5626349170615441\n",
      "468\n",
      "468\n",
      "71744\n",
      "50474\n",
      "Acc: 0.7035292149866191\n",
      "Prec 0.5839419748060907\n",
      "Recall 0.5475323486757688\n",
      "F1 0.5651513504470109\n",
      "Epoch: 482, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50620\n",
      "Acc: 0.6938048245614035\n",
      "Prec 0.5773700751678783\n",
      "Recall 0.5485209111528054\n",
      "F1 0.5625758862114985\n",
      "468\n",
      "468\n",
      "71744\n",
      "50547\n",
      "Acc: 0.704546721677074\n",
      "Prec 0.5844895962815935\n",
      "Recall 0.5501487797824524\n",
      "F1 0.5667995107045564\n",
      "Epoch: 483, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50611\n",
      "Acc: 0.6936814692982456\n",
      "Prec 0.5781550558329352\n",
      "Recall 0.5465750627911766\n",
      "F1 0.5619217103059239\n",
      "468\n",
      "468\n",
      "71744\n",
      "50590\n",
      "Acc: 0.7051460749330954\n",
      "Prec 0.5850844651922377\n",
      "Recall 0.5528353168736073\n",
      "F1 0.5685029134921203\n",
      "Epoch: 484, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.822s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50664\n",
      "Acc: 0.6944078947368421\n",
      "Prec 0.5791491338342735\n",
      "Recall 0.5490756067961436\n",
      "F1 0.5637115560997679\n",
      "468\n",
      "468\n",
      "71744\n",
      "50770\n",
      "Acc: 0.7076549955396967\n",
      "Prec 0.5883814655755765\n",
      "Recall 0.5555585896727403\n",
      "F1 0.5714991370483847\n",
      "Epoch: 485, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.761s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50595\n",
      "Acc: 0.6934621710526315\n",
      "Prec 0.5774425626379119\n",
      "Recall 0.5503378862193021\n",
      "F1 0.5635645123254659\n",
      "468\n",
      "468\n",
      "71744\n",
      "50827\n",
      "Acc: 0.7084494870651205\n",
      "Prec 0.5898479788803136\n",
      "Recall 0.5537978710609158\n",
      "F1 0.5712547375925654\n",
      "Epoch: 486, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.890s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50706\n",
      "Acc: 0.694983552631579\n",
      "Prec 0.5793276165382798\n",
      "Recall 0.5481042206895236\n",
      "F1 0.5632835641175423\n",
      "468\n",
      "468\n",
      "71744\n",
      "50964\n",
      "Acc: 0.7103590544157002\n",
      "Prec 0.5900906843636667\n",
      "Recall 0.5601752458472745\n",
      "F1 0.5747439535568699\n",
      "Epoch: 487, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50531\n",
      "Acc: 0.6925849780701754\n",
      "Prec 0.5749090152489734\n",
      "Recall 0.5495194455134783\n",
      "F1 0.5619275824201291\n",
      "468\n",
      "468\n",
      "71744\n",
      "50422\n",
      "Acc: 0.7028044157002676\n",
      "Prec 0.5858308695781947\n",
      "Recall 0.5425894703537777\n",
      "F1 0.5633816583995436\n",
      "Epoch: 488, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.821s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50602\n",
      "Acc: 0.6935581140350877\n",
      "Prec 0.5801731734430585\n",
      "Recall 0.5429689827081868\n",
      "F1 0.5609548818974915\n",
      "468\n",
      "468\n",
      "71744\n",
      "50897\n",
      "Acc: 0.709425178412132\n",
      "Prec 0.5903590903304644\n",
      "Recall 0.5578379678325908\n",
      "F1 0.573637970764903\n",
      "Epoch: 489, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50643\n",
      "Acc: 0.6941200657894737\n",
      "Prec 0.578533110305809\n",
      "Recall 0.5477667596166539\n",
      "F1 0.5627297234527309\n",
      "468\n",
      "468\n",
      "71744\n",
      "50708\n",
      "Acc: 0.7067908117752008\n",
      "Prec 0.5873938623448752\n",
      "Recall 0.5557721990273636\n",
      "F1 0.5711456797076598\n",
      "Epoch: 490, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50609\n",
      "Acc: 0.6936540570175439\n",
      "Prec 0.5761580882632936\n",
      "Recall 0.5472853667809185\n",
      "F1 0.5613507101637978\n",
      "468\n",
      "468\n",
      "71744\n",
      "50880\n",
      "Acc: 0.7091882247992863\n",
      "Prec 0.5898356785240563\n",
      "Recall 0.5598249725761545\n",
      "F1 0.574438626281878\n",
      "Epoch: 491, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50784\n",
      "Acc: 0.6960526315789474\n",
      "Prec 0.5813360376491294\n",
      "Recall 0.5507535925174646\n",
      "F1 0.5656317356215173\n",
      "468\n",
      "468\n",
      "71744\n",
      "50802\n",
      "Acc: 0.7081010258697591\n",
      "Prec 0.5892274221505767\n",
      "Recall 0.5570123928695355\n",
      "F1 0.5726672063833026\n",
      "Epoch: 492, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50729\n",
      "Acc: 0.6952987938596491\n",
      "Prec 0.5790880561238231\n",
      "Recall 0.550511031706809\n",
      "F1 0.564438067736144\n",
      "468\n",
      "468\n",
      "71744\n",
      "50675\n",
      "Acc: 0.7063308429973238\n",
      "Prec 0.5882426611319943\n",
      "Recall 0.5532416870059291\n",
      "F1 0.5702055621601905\n",
      "Epoch: 493, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50746\n",
      "Acc: 0.6955317982456141\n",
      "Prec 0.580842734065468\n",
      "Recall 0.5492401163056005\n",
      "F1 0.5645995436681976\n",
      "468\n",
      "468\n",
      "71744\n",
      "50829\n",
      "Acc: 0.7084773639607493\n",
      "Prec 0.5894577735609233\n",
      "Recall 0.5589099080221762\n",
      "F1 0.5737775370858903\n",
      "Epoch: 494, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.774s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50893\n",
      "Acc: 0.697546600877193\n",
      "Prec 0.582982901878963\n",
      "Recall 0.5527097766038284\n",
      "F1 0.5674428576784307\n",
      "468\n",
      "468\n",
      "71744\n",
      "50836\n",
      "Acc: 0.7085749330954505\n",
      "Prec 0.5889164364833682\n",
      "Recall 0.5585656343522475\n",
      "F1 0.5733396473641663\n",
      "Epoch: 495, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50878\n",
      "Acc: 0.6973410087719298\n",
      "Prec 0.582186935377055\n",
      "Recall 0.554894695310513\n",
      "F1 0.5682132810895373\n",
      "468\n",
      "468\n",
      "71744\n",
      "50775\n",
      "Acc: 0.707724687778769\n",
      "Prec 0.5891030615608683\n",
      "Recall 0.55518109467257\n",
      "F1 0.5716392747565124\n",
      "Epoch: 496, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.766s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50819\n",
      "Acc: 0.6965323464912281\n",
      "Prec 0.5814151730471727\n",
      "Recall 0.5562191599840974\n",
      "F1 0.5685381493236243\n",
      "468\n",
      "468\n",
      "71744\n",
      "50629\n",
      "Acc: 0.705689674397859\n",
      "Prec 0.5880231956313068\n",
      "Recall 0.5496615498132692\n",
      "F1 0.5681956136461199\n",
      "Epoch: 497, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.893s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50740\n",
      "Acc: 0.6954495614035088\n",
      "Prec 0.5827420104219581\n",
      "Recall 0.546335279772442\n",
      "F1 0.5639516834923136\n",
      "468\n",
      "468\n",
      "71744\n",
      "50773\n",
      "Acc: 0.7076968108831401\n",
      "Prec 0.5876993465178835\n",
      "Recall 0.556749708298474\n",
      "F1 0.5718060377856476\n",
      "Epoch: 498, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50719\n",
      "Acc: 0.6951617324561403\n",
      "Prec 0.579433049018104\n",
      "Recall 0.5525323283269401\n",
      "F1 0.5656630460455534\n",
      "468\n",
      "468\n",
      "71744\n",
      "50543\n",
      "Acc: 0.7044909678858162\n",
      "Prec 0.5863527424943721\n",
      "Recall 0.5454848936414926\n",
      "F1 0.565180999755244\n",
      "Epoch: 499, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50738\n",
      "Acc: 0.695422149122807\n",
      "Prec 0.5825902995988775\n",
      "Recall 0.546055683636628\n",
      "F1 0.5637316732666775\n",
      "468\n",
      "468\n",
      "71744\n",
      "50642\n",
      "Acc: 0.7058708742194469\n",
      "Prec 0.5863868183528991\n",
      "Recall 0.5531858133149287\n",
      "F1 0.5693026666548712\n",
      "Epoch: 500, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.907s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50762\n",
      "Acc: 0.695751096491228\n",
      "Prec 0.5814991259691037\n",
      "Recall 0.5471390223720568\n",
      "F1 0.5637960470511554\n",
      "468\n",
      "468\n",
      "71744\n",
      "50916\n",
      "Acc: 0.7096900089206066\n",
      "Prec 0.5902677905159973\n",
      "Recall 0.5614144551846899\n",
      "F1 0.575479688538558\n",
      "Epoch: 501, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50949\n",
      "Acc: 0.6983141447368421\n",
      "Prec 0.5845241840023354\n",
      "Recall 0.5533501140677983\n",
      "F1 0.5685101147669005\n",
      "468\n",
      "468\n",
      "71744\n",
      "50848\n",
      "Acc: 0.7087421944692239\n",
      "Prec 0.5890727348883974\n",
      "Recall 0.5592158192334956\n",
      "F1 0.5737561187843426\n",
      "Epoch: 502, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51061\n",
      "Acc: 0.6998492324561404\n",
      "Prec 0.5856950080872454\n",
      "Recall 0.5582744717904363\n",
      "F1 0.5716561097506976\n",
      "468\n",
      "468\n",
      "71744\n",
      "51137\n",
      "Acc: 0.7127704058876003\n",
      "Prec 0.5937634521975214\n",
      "Recall 0.5662004024291388\n",
      "F1 0.5796544508538248\n",
      "Epoch: 503, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50621\n",
      "Acc: 0.6938185307017544\n",
      "Prec 0.5784305130430364\n",
      "Recall 0.550438515246758\n",
      "F1 0.5640874623962041\n",
      "468\n",
      "468\n",
      "71744\n",
      "50790\n",
      "Acc: 0.7079337644959858\n",
      "Prec 0.5895391229773985\n",
      "Recall 0.5545645104641943\n",
      "F1 0.571517239482907\n",
      "Epoch: 504, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.815s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50808\n",
      "Acc: 0.6963815789473684\n",
      "Prec 0.5818350248100992\n",
      "Recall 0.5478245070272715\n",
      "F1 0.5643177907229489\n",
      "468\n",
      "468\n",
      "71744\n",
      "50867\n",
      "Acc: 0.7090070249776985\n",
      "Prec 0.5893171479902656\n",
      "Recall 0.557702366357738\n",
      "F1 0.5730740651891795\n",
      "Epoch: 505, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50751\n",
      "Acc: 0.6956003289473685\n",
      "Prec 0.5796246105475639\n",
      "Recall 0.5497150423962169\n",
      "F1 0.5642737621591445\n",
      "468\n",
      "468\n",
      "71744\n",
      "50655\n",
      "Acc: 0.7060520740410348\n",
      "Prec 0.5882660051345477\n",
      "Recall 0.5506904513454018\n",
      "F1 0.568858396711505\n",
      "Epoch: 506, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50710\n",
      "Acc: 0.6950383771929824\n",
      "Prec 0.5802751852452778\n",
      "Recall 0.5477106099401782\n",
      "F1 0.5635228333555152\n",
      "468\n",
      "468\n",
      "71744\n",
      "50728\n",
      "Acc: 0.7070695807314897\n",
      "Prec 0.5892060030193087\n",
      "Recall 0.5562392183820243\n",
      "F1 0.5722482061333354\n",
      "Epoch: 507, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.871s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50876\n",
      "Acc: 0.697313596491228\n",
      "Prec 0.5833287421378057\n",
      "Recall 0.5489807572730404\n",
      "F1 0.5656337861062992\n",
      "468\n",
      "468\n",
      "71744\n",
      "50907\n",
      "Acc: 0.7095645628902766\n",
      "Prec 0.5900875462642272\n",
      "Recall 0.5636988472314058\n",
      "F1 0.5765914236290787\n",
      "Epoch: 508, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50897\n",
      "Acc: 0.6976014254385965\n",
      "Prec 0.5820223919359245\n",
      "Recall 0.5544807691353505\n",
      "F1 0.5679178634759445\n",
      "468\n",
      "468\n",
      "71744\n",
      "50747\n",
      "Acc: 0.7073344112399643\n",
      "Prec 0.5879998250976183\n",
      "Recall 0.5540324018131703\n",
      "F1 0.5705109675333279\n",
      "Epoch: 509, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50898\n",
      "Acc: 0.6976151315789474\n",
      "Prec 0.5813631790999525\n",
      "Recall 0.5541037343382795\n",
      "F1 0.567406244486016\n",
      "468\n",
      "468\n",
      "71744\n",
      "50993\n",
      "Acc: 0.7107632694023194\n",
      "Prec 0.5916164103890078\n",
      "Recall 0.5607574666397362\n",
      "F1 0.5757737590644109\n",
      "Epoch: 510, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50893\n",
      "Acc: 0.697546600877193\n",
      "Prec 0.5833157456110157\n",
      "Recall 0.5544437566113742\n",
      "F1 0.5685134207280309\n",
      "468\n",
      "468\n",
      "71744\n",
      "50876\n",
      "Acc: 0.7091324710080286\n",
      "Prec 0.5903632058904457\n",
      "Recall 0.5580387799806502\n",
      "F1 0.5737460701283545\n",
      "Epoch: 511, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.813s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50788\n",
      "Acc: 0.6961074561403509\n",
      "Prec 0.5808688304085002\n",
      "Recall 0.5502359372508455\n",
      "F1 0.5651375795736754\n",
      "468\n",
      "468\n",
      "71744\n",
      "50809\n",
      "Acc: 0.7081985950044603\n",
      "Prec 0.5893108387437851\n",
      "Recall 0.5584231520730291\n",
      "F1 0.5734513724524328\n",
      "Epoch: 512, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50703\n",
      "Acc: 0.6949424342105263\n",
      "Prec 0.5783886339954648\n",
      "Recall 0.5501922248469151\n",
      "F1 0.5639382005655244\n",
      "468\n",
      "468\n",
      "71744\n",
      "50857\n",
      "Acc: 0.708867640499554\n",
      "Prec 0.5897283855983736\n",
      "Recall 0.5593616191582945\n",
      "F1 0.5741437542166543\n",
      "Epoch: 513, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50804\n",
      "Acc: 0.6963267543859649\n",
      "Prec 0.5822565062375467\n",
      "Recall 0.5518513161587706\n",
      "F1 0.5666463328509018\n",
      "468\n",
      "468\n",
      "71744\n",
      "50754\n",
      "Acc: 0.7074319803746655\n",
      "Prec 0.5892250351896968\n",
      "Recall 0.5532452381947541\n",
      "F1 0.5706685811231417\n",
      "Epoch: 514, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50593\n",
      "Acc: 0.6934347587719298\n",
      "Prec 0.5776308647983269\n",
      "Recall 0.5478971504031932\n",
      "F1 0.5623712613697508\n",
      "468\n",
      "468\n",
      "71744\n",
      "50550\n",
      "Acc: 0.7045885370205174\n",
      "Prec 0.5863687947568658\n",
      "Recall 0.5467107900194935\n",
      "F1 0.5658457734680259\n",
      "Epoch: 515, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.864s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50804\n",
      "Acc: 0.6963267543859649\n",
      "Prec 0.5817581497787488\n",
      "Recall 0.5490698824124315\n",
      "F1 0.5649415645852834\n",
      "468\n",
      "468\n",
      "71744\n",
      "50971\n",
      "Acc: 0.7104566235504014\n",
      "Prec 0.5921926354669338\n",
      "Recall 0.5595365124584768\n",
      "F1 0.5754016081812694\n",
      "Epoch: 516, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50728\n",
      "Acc: 0.6952850877192982\n",
      "Prec 0.5807859780876009\n",
      "Recall 0.5494933354307555\n",
      "F1 0.5647064764502328\n",
      "468\n",
      "468\n",
      "71744\n",
      "50874\n",
      "Acc: 0.7091045941123997\n",
      "Prec 0.5904340612313335\n",
      "Recall 0.5590003216022458\n",
      "F1 0.5742873800235401\n",
      "Epoch: 517, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50873\n",
      "Acc: 0.6972724780701754\n",
      "Prec 0.5824092564705674\n",
      "Recall 0.5514288191856624\n",
      "F1 0.5664957906665622\n",
      "468\n",
      "468\n",
      "71744\n",
      "50883\n",
      "Acc: 0.7092300401427297\n",
      "Prec 0.5903264985957526\n",
      "Recall 0.5602969201153191\n",
      "F1 0.5749198454454815\n",
      "Epoch: 518, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.826s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50746\n",
      "Acc: 0.6955317982456141\n",
      "Prec 0.5807437930297172\n",
      "Recall 0.5486347999717621\n",
      "F1 0.5642328563656137\n",
      "468\n",
      "468\n",
      "71744\n",
      "50783\n",
      "Acc: 0.7078361953612846\n",
      "Prec 0.5889252148815545\n",
      "Recall 0.5557141064511861\n",
      "F1 0.5718378592366022\n",
      "Epoch: 519, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50899\n",
      "Acc: 0.6976288377192983\n",
      "Prec 0.5842174249029443\n",
      "Recall 0.5525109676266103\n",
      "F1 0.5679220064507361\n",
      "468\n",
      "468\n",
      "71744\n",
      "50815\n",
      "Acc: 0.708282225691347\n",
      "Prec 0.5897057447483657\n",
      "Recall 0.5559242491774958\n",
      "F1 0.5723169350018021\n",
      "Epoch: 520, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50692\n",
      "Acc: 0.6947916666666667\n",
      "Prec 0.5780677755529645\n",
      "Recall 0.5453281626341886\n",
      "F1 0.5612208967553051\n",
      "468\n",
      "468\n",
      "71744\n",
      "50985\n",
      "Acc: 0.7106517618198037\n",
      "Prec 0.5912212215315416\n",
      "Recall 0.5639194640613624\n",
      "F1 0.5772477041904981\n",
      "Epoch: 521, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50813\n",
      "Acc: 0.6964501096491228\n",
      "Prec 0.5797044256040227\n",
      "Recall 0.5529417711935104\n",
      "F1 0.5660069186097373\n",
      "468\n",
      "468\n",
      "71744\n",
      "51200\n",
      "Acc: 0.7136485280999108\n",
      "Prec 0.5942783363179512\n",
      "Recall 0.5669349877320943\n",
      "F1 0.5802847320676227\n",
      "Epoch: 522, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50701\n",
      "Acc: 0.6949150219298246\n",
      "Prec 0.5782628357084505\n",
      "Recall 0.5522478504384308\n",
      "F1 0.5649560184111919\n",
      "468\n",
      "468\n",
      "71744\n",
      "50666\n",
      "Acc: 0.7062053969669938\n",
      "Prec 0.5890043278750917\n",
      "Recall 0.5505140630079934\n",
      "F1 0.5691091398999241\n",
      "Epoch: 523, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.752s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50849\n",
      "Acc: 0.6969435307017544\n",
      "Prec 0.5831042687687655\n",
      "Recall 0.5510801992495952\n",
      "F1 0.5666401289691773\n",
      "468\n",
      "468\n",
      "71744\n",
      "51016\n",
      "Acc: 0.7110838537020517\n",
      "Prec 0.5919366306848162\n",
      "Recall 0.5616181816220355\n",
      "F1 0.5763789819330222\n",
      "Epoch: 524, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.780s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50978\n",
      "Acc: 0.6987116228070176\n",
      "Prec 0.5857858125369426\n",
      "Recall 0.552914933593245\n",
      "F1 0.5688759311688347\n",
      "468\n",
      "468\n",
      "71744\n",
      "51148\n",
      "Acc: 0.7129237288135594\n",
      "Prec 0.5932383050412349\n",
      "Recall 0.5660254082412693\n",
      "F1 0.5793124548762522\n",
      "Epoch: 525, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50968\n",
      "Acc: 0.6985745614035088\n",
      "Prec 0.5847672647722738\n",
      "Recall 0.5528074134855232\n",
      "F1 0.5683383874627822\n",
      "468\n",
      "468\n",
      "71744\n",
      "51052\n",
      "Acc: 0.711585637823372\n",
      "Prec 0.5922199628821465\n",
      "Recall 0.5640306319178122\n",
      "F1 0.5777816701690873\n",
      "Epoch: 526, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50963\n",
      "Acc: 0.6985060307017544\n",
      "Prec 0.5832409268440294\n",
      "Recall 0.5526451729858142\n",
      "F1 0.5675309926874001\n",
      "468\n",
      "468\n",
      "71744\n",
      "50868\n",
      "Acc: 0.7090209634255129\n",
      "Prec 0.5890034820316924\n",
      "Recall 0.5597108360461036\n",
      "F1 0.5739836723088496\n",
      "Epoch: 527, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50867\n",
      "Acc: 0.6971902412280702\n",
      "Prec 0.5824627035059317\n",
      "Recall 0.5538399287028518\n",
      "F1 0.5677908209272243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "71744\n",
      "50907\n",
      "Acc: 0.7095645628902766\n",
      "Prec 0.5905633448952505\n",
      "Recall 0.5574440810752815\n",
      "F1 0.5735259784292159\n",
      "Epoch: 528, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.886s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50946\n",
      "Acc: 0.6982730263157895\n",
      "Prec 0.5840782719088048\n",
      "Recall 0.5548780210066699\n",
      "F1 0.5691038324221368\n",
      "468\n",
      "468\n",
      "71744\n",
      "50968\n",
      "Acc: 0.7104148082069581\n",
      "Prec 0.5909688164381661\n",
      "Recall 0.5618569681732036\n",
      "F1 0.5760453173777491\n",
      "Epoch: 529, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50900\n",
      "Acc: 0.6976425438596491\n",
      "Prec 0.581874579176406\n",
      "Recall 0.5525689779428474\n",
      "F1 0.5668432589504884\n",
      "468\n",
      "468\n",
      "71744\n",
      "50980\n",
      "Acc: 0.7105820695807314\n",
      "Prec 0.5925713883991343\n",
      "Recall 0.5595038897032181\n",
      "F1 0.5755630782777668\n",
      "Epoch: 530, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51099\n",
      "Acc: 0.7003700657894737\n",
      "Prec 0.5859372265327131\n",
      "Recall 0.5573805915039833\n",
      "F1 0.5713022796580343\n",
      "468\n",
      "468\n",
      "71744\n",
      "51249\n",
      "Acc: 0.7143315120428189\n",
      "Prec 0.5954280754848624\n",
      "Recall 0.5681284184381803\n",
      "F1 0.5814579912288781\n",
      "Epoch: 531, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.890s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51038\n",
      "Acc: 0.6995339912280701\n",
      "Prec 0.584537192540514\n",
      "Recall 0.5577208175350036\n",
      "F1 0.5708142259063835\n",
      "468\n",
      "468\n",
      "71744\n",
      "50988\n",
      "Acc: 0.7106935771632471\n",
      "Prec 0.5914285353667581\n",
      "Recall 0.5608934302296168\n",
      "F1 0.5757564115613396\n",
      "Epoch: 532, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51037\n",
      "Acc: 0.6995202850877194\n",
      "Prec 0.5851575546622797\n",
      "Recall 0.5554594218384432\n",
      "F1 0.5699218645583627\n",
      "468\n",
      "468\n",
      "71744\n",
      "51007\n",
      "Acc: 0.7109584076717217\n",
      "Prec 0.591142032078284\n",
      "Recall 0.5613159845163062\n",
      "F1 0.5758430536246043\n",
      "Epoch: 533, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50987\n",
      "Acc: 0.6988349780701755\n",
      "Prec 0.5840086759365382\n",
      "Recall 0.5547785372146478\n",
      "F1 0.5690184702025138\n",
      "468\n",
      "468\n",
      "71744\n",
      "51082\n",
      "Acc: 0.7120037912578056\n",
      "Prec 0.5930229433345652\n",
      "Recall 0.5632245626135678\n",
      "F1 0.5777397765810254\n",
      "Epoch: 534, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.876s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51190\n",
      "Acc: 0.7016173245614035\n",
      "Prec 0.5871777980323887\n",
      "Recall 0.5614896590130906\n",
      "F1 0.5740464911320451\n",
      "468\n",
      "468\n",
      "71744\n",
      "50977\n",
      "Acc: 0.7105402542372882\n",
      "Prec 0.5919955326854196\n",
      "Recall 0.5583892594930232\n",
      "F1 0.5747015248583252\n",
      "Epoch: 535, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50947\n",
      "Acc: 0.6982867324561404\n",
      "Prec 0.5829132444805777\n",
      "Recall 0.5548112600501738\n",
      "F1 0.5685151904214136\n",
      "468\n",
      "468\n",
      "71744\n",
      "50999\n",
      "Acc: 0.710846900089206\n",
      "Prec 0.5927350419224713\n",
      "Recall 0.5587843822536641\n",
      "F1 0.5752592223578262\n",
      "Epoch: 536, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51056\n",
      "Acc: 0.699780701754386\n",
      "Prec 0.5859505162018643\n",
      "Recall 0.5532565831456333\n",
      "F1 0.5691344105421118\n",
      "468\n",
      "468\n",
      "71744\n",
      "51012\n",
      "Acc: 0.711028099910794\n",
      "Prec 0.5911341841671656\n",
      "Recall 0.5634226189954091\n",
      "F1 0.5769458363743765\n",
      "Epoch: 537, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50814\n",
      "Acc: 0.6964638157894737\n",
      "Prec 0.5807242112482366\n",
      "Recall 0.5532911680945635\n",
      "F1 0.566675872365224\n",
      "468\n",
      "468\n",
      "71744\n",
      "50887\n",
      "Acc: 0.7092857939339875\n",
      "Prec 0.5911056820693954\n",
      "Recall 0.5563032057338563\n",
      "F1 0.5731766406172165\n",
      "Epoch: 538, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.812s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50648\n",
      "Acc: 0.6941885964912281\n",
      "Prec 0.5791157431362354\n",
      "Recall 0.5482682269196334\n",
      "F1 0.5632699596656764\n",
      "468\n",
      "468\n",
      "71744\n",
      "50956\n",
      "Acc: 0.7102475468331847\n",
      "Prec 0.592089202450093\n",
      "Recall 0.5577254302900888\n",
      "F1 0.5743938123654277\n",
      "Epoch: 539, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50880\n",
      "Acc: 0.6973684210526315\n",
      "Prec 0.5830562506866522\n",
      "Recall 0.5492571036761952\n",
      "F1 0.5656522309809825\n",
      "468\n",
      "468\n",
      "71744\n",
      "50926\n",
      "Acc: 0.7098293933987511\n",
      "Prec 0.5903837748327583\n",
      "Recall 0.5622780923736987\n",
      "F1 0.5759882791748298\n",
      "Epoch: 540, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50878\n",
      "Acc: 0.6973410087719298\n",
      "Prec 0.5825120723874904\n",
      "Recall 0.5512011843388577\n",
      "F1 0.5664242563746763\n",
      "468\n",
      "468\n",
      "71744\n",
      "50914\n",
      "Acc: 0.7096621320249777\n",
      "Prec 0.5900777461067737\n",
      "Recall 0.5606573288963931\n",
      "F1 0.5749914470496474\n",
      "Epoch: 541, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50771\n",
      "Acc: 0.695874451754386\n",
      "Prec 0.5804952114353665\n",
      "Recall 0.5559983241655607\n",
      "F1 0.5679827550863075\n",
      "468\n",
      "468\n",
      "71744\n",
      "50710\n",
      "Acc: 0.7068186886708296\n",
      "Prec 0.5886872112407198\n",
      "Recall 0.552039418712074\n",
      "F1 0.5697746284927306\n",
      "Epoch: 542, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50776\n",
      "Acc: 0.6959429824561404\n",
      "Prec 0.5810986987820486\n",
      "Recall 0.5463366937271394\n",
      "F1 0.5631817910473128\n",
      "468\n",
      "468\n",
      "71744\n",
      "50823\n",
      "Acc: 0.7083937332738626\n",
      "Prec 0.5890502539185438\n",
      "Recall 0.5591394690820237\n",
      "F1 0.5737052677634584\n",
      "Epoch: 543, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50910\n",
      "Acc: 0.6977796052631579\n",
      "Prec 0.5829856521165541\n",
      "Recall 0.5520020697095582\n",
      "F1 0.5670709566118419\n",
      "468\n",
      "468\n",
      "71744\n",
      "51030\n",
      "Acc: 0.711278991971454\n",
      "Prec 0.5919727879124499\n",
      "Recall 0.5630323907133247\n",
      "F1 0.5771400166571352\n",
      "Epoch: 544, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.879s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50907\n",
      "Acc: 0.6977384868421053\n",
      "Prec 0.5816181137460331\n",
      "Recall 0.5539623785274508\n",
      "F1 0.567453484588052\n",
      "468\n",
      "468\n",
      "71744\n",
      "51043\n",
      "Acc: 0.7114601917930419\n",
      "Prec 0.5915177015089177\n",
      "Recall 0.5659383015516329\n",
      "F1 0.578445353334385\n",
      "Epoch: 545, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51018\n",
      "Acc: 0.6992598684210526\n",
      "Prec 0.584858892370632\n",
      "Recall 0.556130120723847\n",
      "F1 0.5701328280775693\n",
      "468\n",
      "468\n",
      "71744\n",
      "51059\n",
      "Acc: 0.7116832069580732\n",
      "Prec 0.5924027518719998\n",
      "Recall 0.5615719128014677\n",
      "F1 0.5765754772644813\n",
      "Epoch: 546, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.907s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50922\n",
      "Acc: 0.6979440789473684\n",
      "Prec 0.5833947294396601\n",
      "Recall 0.5557725388261517\n",
      "F1 0.5692487467833727\n",
      "468\n",
      "468\n",
      "71744\n",
      "50906\n",
      "Acc: 0.7095506244424621\n",
      "Prec 0.5913755589571333\n",
      "Recall 0.5563331557334593\n",
      "F1 0.573319391457187\n",
      "Epoch: 547, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.879s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50665\n",
      "Acc: 0.694421600877193\n",
      "Prec 0.5786779455472365\n",
      "Recall 0.5463985258112757\n",
      "F1 0.5620751734052614\n",
      "468\n",
      "468\n",
      "71744\n",
      "50800\n",
      "Acc: 0.7080731489741302\n",
      "Prec 0.5898902029133756\n",
      "Recall 0.553211520841853\n",
      "F1 0.5709624078098152\n",
      "Epoch: 548, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50820\n",
      "Acc: 0.696546052631579\n",
      "Prec 0.5826812004500899\n",
      "Recall 0.5520808570220685\n",
      "F1 0.5669684395894176\n",
      "468\n",
      "468\n",
      "71744\n",
      "50832\n",
      "Acc: 0.7085191793041927\n",
      "Prec 0.591570686684903\n",
      "Recall 0.5534422298937567\n",
      "F1 0.5718716273646194\n",
      "Epoch: 549, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50784\n",
      "Acc: 0.6960526315789474\n",
      "Prec 0.5819547881655147\n",
      "Recall 0.5493080971591199\n",
      "F1 0.5651603733611438\n",
      "468\n",
      "468\n",
      "71744\n",
      "50945\n",
      "Acc: 0.7100942239072257\n",
      "Prec 0.5906621971675042\n",
      "Recall 0.5581916511170015\n",
      "F1 0.5739680596999254\n",
      "Epoch: 550, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50879\n",
      "Acc: 0.6973547149122807\n",
      "Prec 0.5820756114343222\n",
      "Recall 0.5563825901082561\n",
      "F1 0.5689391773713931\n",
      "468\n",
      "468\n",
      "71744\n",
      "51068\n",
      "Acc: 0.7118086529884032\n",
      "Prec 0.5934302217728383\n",
      "Recall 0.559168711020774\n",
      "F1 0.5757902471507981\n",
      "Epoch: 551, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50950\n",
      "Acc: 0.698327850877193\n",
      "Prec 0.5833259571713837\n",
      "Recall 0.5517875615218685\n",
      "F1 0.5671186223745238\n",
      "468\n",
      "468\n",
      "71744\n",
      "51032\n",
      "Acc: 0.7113068688670829\n",
      "Prec 0.5922237960917027\n",
      "Recall 0.5634738433024723\n",
      "F1 0.577491217605845\n",
      "Epoch: 552, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.791s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50828\n",
      "Acc: 0.696655701754386\n",
      "Prec 0.5811952839965491\n",
      "Recall 0.5541641476002618\n",
      "F1 0.567357931209957\n",
      "468\n",
      "468\n",
      "71744\n",
      "50968\n",
      "Acc: 0.7104148082069581\n",
      "Prec 0.5916091851099612\n",
      "Recall 0.5587463734273675\n",
      "F1 0.574708374664292\n",
      "Epoch: 553, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.809s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50467\n",
      "Acc: 0.6917077850877194\n",
      "Prec 0.5776604235485805\n",
      "Recall 0.5472439459691522\n",
      "F1 0.5620409666440604\n",
      "468\n",
      "468\n",
      "71744\n",
      "50856\n",
      "Acc: 0.7088537020517395\n",
      "Prec 0.5907371846404187\n",
      "Recall 0.5563278374511772\n",
      "F1 0.5730164098871074\n",
      "Epoch: 554, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50715\n",
      "Acc: 0.6951069078947368\n",
      "Prec 0.5838932222231719\n",
      "Recall 0.5442991936294735\n",
      "F1 0.5634014296782817\n",
      "468\n",
      "468\n",
      "71744\n",
      "50813\n",
      "Acc: 0.7082543487957181\n",
      "Prec 0.588753916806401\n",
      "Recall 0.5569531157941119\n",
      "F1 0.5724121770589637\n",
      "Epoch: 555, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50780\n",
      "Acc: 0.6959978070175439\n",
      "Prec 0.5808990035099515\n",
      "Recall 0.5482375125160142\n",
      "F1 0.5640958735940901\n",
      "468\n",
      "468\n",
      "71744\n",
      "50992\n",
      "Acc: 0.7107493309545049\n",
      "Prec 0.5917666736410764\n",
      "Recall 0.5641382191994434\n",
      "F1 0.5776222585736813\n",
      "Epoch: 556, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.819s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50994\n",
      "Acc: 0.6989309210526315\n",
      "Prec 0.5844173167335296\n",
      "Recall 0.5563997354156457\n",
      "F1 0.5700644810493903\n",
      "468\n",
      "468\n",
      "71744\n",
      "51147\n",
      "Acc: 0.7129097903657449\n",
      "Prec 0.5943355850823714\n",
      "Recall 0.5635399387293548\n",
      "F1 0.5785282309093109\n",
      "Epoch: 557, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50887\n",
      "Acc: 0.6974643640350877\n",
      "Prec 0.58302054345732\n",
      "Recall 0.5529462664817376\n",
      "F1 0.5675853026096312\n",
      "468\n",
      "468\n",
      "71744\n",
      "51144\n",
      "Acc: 0.7128679750223015\n",
      "Prec 0.593572147961922\n",
      "Recall 0.5663970410298821\n",
      "F1 0.5796662729215981\n",
      "Epoch: 558, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50667\n",
      "Acc: 0.6944490131578948\n",
      "Prec 0.5786872395620546\n",
      "Recall 0.5539187263856443\n",
      "F1 0.5660321565507974\n",
      "468\n",
      "468\n",
      "71744\n",
      "50954\n",
      "Acc: 0.7102196699375558\n",
      "Prec 0.5918509530051814\n",
      "Recall 0.557722274236236\n",
      "F1 0.5742800053042864\n",
      "Epoch: 559, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.775s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50851\n",
      "Acc: 0.6969709429824561\n",
      "Prec 0.5832731282843571\n",
      "Recall 0.5498911288044472\n",
      "F1 0.5660904267093392\n",
      "468\n",
      "468\n",
      "71744\n",
      "50875\n",
      "Acc: 0.7091185325602141\n",
      "Prec 0.5902244625209838\n",
      "Recall 0.5610144511250218\n",
      "F1 0.5752488887525359\n",
      "Epoch: 560, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50933\n",
      "Acc: 0.6980948464912281\n",
      "Prec 0.5841425971031048\n",
      "Recall 0.5510705103989274\n",
      "F1 0.5671248103181133\n",
      "468\n",
      "468\n",
      "71744\n",
      "51042\n",
      "Acc: 0.7114462533452275\n",
      "Prec 0.5919949131259444\n",
      "Recall 0.5653781411738148\n",
      "F1 0.5783804665644359\n",
      "Epoch: 561, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50971\n",
      "Acc: 0.6986156798245614\n",
      "Prec 0.5828616164359853\n",
      "Recall 0.5539539550772518\n",
      "F1 0.5680402446592887\n",
      "468\n",
      "468\n",
      "71744\n",
      "51125\n",
      "Acc: 0.7126031445138269\n",
      "Prec 0.5936605040459771\n",
      "Recall 0.5630912972274872\n",
      "F1 0.5779719780301354\n",
      "Epoch: 562, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50875\n",
      "Acc: 0.6972998903508771\n",
      "Prec 0.5828564985762501\n",
      "Recall 0.5509390332990156\n",
      "F1 0.5664485118344532\n",
      "468\n",
      "468\n",
      "71744\n",
      "50973\n",
      "Acc: 0.7104845004460303\n",
      "Prec 0.5916323302198119\n",
      "Recall 0.5610784441583259\n",
      "F1 0.5759504547575307\n",
      "Epoch: 563, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50884\n",
      "Acc: 0.6974232456140351\n",
      "Prec 0.583040002008843\n",
      "Recall 0.5508624612661991\n",
      "F1 0.5664946693838092\n",
      "468\n",
      "468\n",
      "71744\n",
      "50854\n",
      "Acc: 0.7088258251561106\n",
      "Prec 0.589232085058812\n",
      "Recall 0.5589996456609103\n",
      "F1 0.5737178619048552\n",
      "Epoch: 564, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51078\n",
      "Acc: 0.7000822368421052\n",
      "Prec 0.5856130614790366\n",
      "Recall 0.5588994711675422\n",
      "F1 0.571944510930939\n",
      "468\n",
      "468\n",
      "71744\n",
      "50967\n",
      "Acc: 0.7104008697591436\n",
      "Prec 0.5916874471004223\n",
      "Recall 0.559106833712527\n",
      "F1 0.5749359387884142\n",
      "Epoch: 565, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51115\n",
      "Acc: 0.7005893640350878\n",
      "Prec 0.5873711823873563\n",
      "Recall 0.5574478231532076\n",
      "F1 0.5720184333420482\n",
      "468\n",
      "468\n",
      "71744\n",
      "51052\n",
      "Acc: 0.711585637823372\n",
      "Prec 0.5924772363031137\n",
      "Recall 0.5622611529378655\n",
      "F1 0.5769738619189693\n",
      "Epoch: 566, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50859\n",
      "Acc: 0.6970805921052632\n",
      "Prec 0.5820222871510062\n",
      "Recall 0.5518409644342136\n",
      "F1 0.5665299405630808\n",
      "468\n",
      "468\n",
      "71744\n",
      "50853\n",
      "Acc: 0.7088118867082962\n",
      "Prec 0.590041144294923\n",
      "Recall 0.5571673591680446\n",
      "F1 0.5731332450464278\n",
      "Epoch: 567, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.826s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50941\n",
      "Acc: 0.6982044956140351\n",
      "Prec 0.5836361160616487\n",
      "Recall 0.5544238543883382\n",
      "F1 0.5686550681493439\n",
      "468\n",
      "468\n",
      "71744\n",
      "50959\n",
      "Acc: 0.710289362176628\n",
      "Prec 0.5902805113855881\n",
      "Recall 0.5630732925122864\n",
      "F1 0.5763559974891271\n",
      "Epoch: 568, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50854\n",
      "Acc: 0.6970120614035088\n",
      "Prec 0.5829277159607434\n",
      "Recall 0.5546785227349343\n",
      "F1 0.5684523754389341\n",
      "468\n",
      "468\n",
      "71744\n",
      "50972\n",
      "Acc: 0.7104705619982159\n",
      "Prec 0.5921882476356224\n",
      "Recall 0.5592644350864134\n",
      "F1 0.5752556414143154\n",
      "Epoch: 569, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50687\n",
      "Acc: 0.6947231359649123\n",
      "Prec 0.5780213297328795\n",
      "Recall 0.5508579333913529\n",
      "F1 0.5641128250891349\n",
      "468\n",
      "468\n",
      "71744\n",
      "50812\n",
      "Acc: 0.7082404103479036\n",
      "Prec 0.5904207881498166\n",
      "Recall 0.5530658407387052\n",
      "F1 0.5711331664718953\n",
      "Epoch: 570, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50809\n",
      "Acc: 0.6963952850877193\n",
      "Prec 0.5817772728269938\n",
      "Recall 0.5507884857924037\n",
      "F1 0.5658589282434728\n",
      "468\n",
      "468\n",
      "71744\n",
      "51032\n",
      "Acc: 0.7113068688670829\n",
      "Prec 0.592057151249307\n",
      "Recall 0.5622210116095129\n",
      "F1 0.5767534745379131\n",
      "Epoch: 571, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50988\n",
      "Acc: 0.6988486842105263\n",
      "Prec 0.584869184954859\n",
      "Recall 0.5533114778839746\n",
      "F1 0.5686528398558683\n",
      "468\n",
      "468\n",
      "71744\n",
      "51025\n",
      "Acc: 0.7112092997323818\n",
      "Prec 0.5917807479360255\n",
      "Recall 0.5632997061894264\n",
      "F1 0.5771890957904089\n",
      "Epoch: 572, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.771s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50796\n",
      "Acc: 0.6962171052631579\n",
      "Prec 0.5807274705711599\n",
      "Recall 0.5491817394618485\n",
      "F1 0.5645142452325567\n",
      "468\n",
      "468\n",
      "71744\n",
      "51067\n",
      "Acc: 0.7117947145405887\n",
      "Prec 0.5927195960047466\n",
      "Recall 0.5627750558945412\n",
      "F1 0.5773593209160689\n",
      "Epoch: 573, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51050\n",
      "Acc: 0.6996984649122807\n",
      "Prec 0.5852285386783135\n",
      "Recall 0.5557614294035308\n",
      "F1 0.5701144765196896\n",
      "468\n",
      "468\n",
      "71744\n",
      "51256\n",
      "Acc: 0.71442908117752\n",
      "Prec 0.595286142860655\n",
      "Recall 0.5665721986260647\n",
      "F1 0.5805743552877802\n",
      "Epoch: 574, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50809\n",
      "Acc: 0.6963952850877193\n",
      "Prec 0.5816691934354181\n",
      "Recall 0.5533413015560626\n",
      "F1 0.5671517399899201\n",
      "468\n",
      "468\n",
      "71744\n",
      "50940\n",
      "Acc: 0.7100245316681534\n",
      "Prec 0.5928817145713149\n",
      "Recall 0.5578553071366921\n",
      "F1 0.5748354397897063\n",
      "Epoch: 575, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.890s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50714\n",
      "Acc: 0.6950932017543859\n",
      "Prec 0.5816364878337033\n",
      "Recall 0.5432055960182306\n",
      "F1 0.5617645349073661\n",
      "468\n",
      "468\n",
      "71744\n",
      "50991\n",
      "Acc: 0.7107353925066905\n",
      "Prec 0.5912583490727988\n",
      "Recall 0.5639462654686888\n",
      "F1 0.5772794424287029\n",
      "Epoch: 576, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50920\n",
      "Acc: 0.6979166666666666\n",
      "Prec 0.5818726929475054\n",
      "Recall 0.5570075279247041\n",
      "F1 0.5691686699367967\n",
      "468\n",
      "468\n",
      "71744\n",
      "50875\n",
      "Acc: 0.7091185325602141\n",
      "Prec 0.5908150758813678\n",
      "Recall 0.5554246402394704\n",
      "F1 0.5725735138196342\n",
      "Epoch: 577, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.888s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50701\n",
      "Acc: 0.6949150219298246\n",
      "Prec 0.5798500530231466\n",
      "Recall 0.5505220145727718\n",
      "F1 0.5648055688767161\n",
      "468\n",
      "468\n",
      "71744\n",
      "50857\n",
      "Acc: 0.708867640499554\n",
      "Prec 0.5905839625776445\n",
      "Recall 0.5545890094834524\n",
      "F1 0.5720207912927826\n",
      "Epoch: 578, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50776\n",
      "Acc: 0.6959429824561404\n",
      "Prec 0.5801199068757695\n",
      "Recall 0.5476661014884447\n",
      "F1 0.5634260496906048\n",
      "468\n",
      "468\n",
      "71744\n",
      "51119\n",
      "Acc: 0.7125195138269402\n",
      "Prec 0.5940635243927801\n",
      "Recall 0.564142455230904\n",
      "F1 0.5787164996729807\n",
      "Epoch: 579, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50985\n",
      "Acc: 0.6988075657894737\n",
      "Prec 0.5833343224651508\n",
      "Recall 0.5537674050475662\n",
      "F1 0.5681664642851297\n",
      "468\n",
      "468\n",
      "71744\n",
      "51098\n",
      "Acc: 0.7122268064228368\n",
      "Prec 0.5937670266538366\n",
      "Recall 0.5647025993240518\n",
      "F1 0.578870219512747\n",
      "Epoch: 580, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50989\n",
      "Acc: 0.6988623903508772\n",
      "Prec 0.5840327798459751\n",
      "Recall 0.5567863809664533\n",
      "F1 0.5700842149682016\n",
      "468\n",
      "468\n",
      "71744\n",
      "51115\n",
      "Acc: 0.7124637600356825\n",
      "Prec 0.5939474120594793\n",
      "Recall 0.5628067579907062\n",
      "F1 0.5779579206248516\n",
      "Epoch: 581, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51032\n",
      "Acc: 0.699451754385965\n",
      "Prec 0.5844989613560295\n",
      "Recall 0.5554487253077851\n",
      "F1 0.5696036876553217\n",
      "468\n",
      "468\n",
      "71744\n",
      "51168\n",
      "Acc: 0.7132024977698483\n",
      "Prec 0.5949939490108781\n",
      "Recall 0.5649506737724791\n",
      "F1 0.5795832417889918\n",
      "Epoch: 582, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51051\n",
      "Acc: 0.6997121710526316\n",
      "Prec 0.5862947864867096\n",
      "Recall 0.5570193956670256\n",
      "F1 0.5712822822443423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "71744\n",
      "51246\n",
      "Acc: 0.7142896966993756\n",
      "Prec 0.5954723004301666\n",
      "Recall 0.5663331149473819\n",
      "F1 0.5805372884372535\n",
      "Epoch: 583, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50919\n",
      "Acc: 0.6979029605263158\n",
      "Prec 0.5834836879308549\n",
      "Recall 0.5531489056790955\n",
      "F1 0.5679115050457757\n",
      "468\n",
      "468\n",
      "71744\n",
      "51148\n",
      "Acc: 0.7129237288135594\n",
      "Prec 0.5944136908837304\n",
      "Recall 0.5641028718023395\n",
      "F1 0.5788617631649717\n",
      "Epoch: 584, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.894s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50941\n",
      "Acc: 0.6982044956140351\n",
      "Prec 0.5820021135556009\n",
      "Recall 0.5500650174569724\n",
      "F1 0.5655830718565414\n",
      "468\n",
      "468\n",
      "71744\n",
      "51124\n",
      "Acc: 0.7125892060660125\n",
      "Prec 0.5917846023360802\n",
      "Recall 0.573007001221779\n",
      "F1 0.5822444449600227\n",
      "Epoch: 585, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51067\n",
      "Acc: 0.6999314692982456\n",
      "Prec 0.5846011234525987\n",
      "Recall 0.5584609018807195\n",
      "F1 0.5712321176072997\n",
      "468\n",
      "468\n",
      "71744\n",
      "51100\n",
      "Acc: 0.7122546833184656\n",
      "Prec 0.5942824689016185\n",
      "Recall 0.5616632893439802\n",
      "F1 0.5775126452115523\n",
      "Epoch: 586, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.889s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51160\n",
      "Acc: 0.7012061403508771\n",
      "Prec 0.586203755025439\n",
      "Recall 0.5575924342915735\n",
      "F1 0.5715402478315182\n",
      "468\n",
      "468\n",
      "71744\n",
      "51200\n",
      "Acc: 0.7136485280999108\n",
      "Prec 0.5947391331526616\n",
      "Recall 0.56537110956935\n",
      "F1 0.5796833977189636\n",
      "Epoch: 587, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.885s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51036\n",
      "Acc: 0.6995065789473685\n",
      "Prec 0.5841196130826788\n",
      "Recall 0.5581372738410725\n",
      "F1 0.5708329399021274\n",
      "468\n",
      "468\n",
      "71744\n",
      "51282\n",
      "Acc: 0.7147914808206958\n",
      "Prec 0.5955995174662206\n",
      "Recall 0.5695352605884021\n",
      "F1 0.5822758581677969\n",
      "Epoch: 588, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50857\n",
      "Acc: 0.6970531798245614\n",
      "Prec 0.5819595227448735\n",
      "Recall 0.5562087834897929\n",
      "F1 0.5687928514844592\n",
      "468\n",
      "468\n",
      "71744\n",
      "50827\n",
      "Acc: 0.7084494870651205\n",
      "Prec 0.5901440959554819\n",
      "Recall 0.5527592365788963\n",
      "F1 0.570840228855633\n",
      "Epoch: 589, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50957\n",
      "Acc: 0.6984237938596491\n",
      "Prec 0.5845431537542254\n",
      "Recall 0.5514135358165685\n",
      "F1 0.5674952402820421\n",
      "468\n",
      "468\n",
      "71744\n",
      "50971\n",
      "Acc: 0.7104566235504014\n",
      "Prec 0.5915411692774734\n",
      "Recall 0.5594019118885187\n",
      "F1 0.5750228077644857\n",
      "Epoch: 590, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.881s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50897\n",
      "Acc: 0.6976014254385965\n",
      "Prec 0.5838831873735226\n",
      "Recall 0.5528900238644668\n",
      "F1 0.5679641043782886\n",
      "468\n",
      "468\n",
      "71744\n",
      "51046\n",
      "Acc: 0.7115020071364853\n",
      "Prec 0.5928126638685525\n",
      "Recall 0.5630324221833207\n",
      "F1 0.5775389004402938\n",
      "Epoch: 591, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51066\n",
      "Acc: 0.6999177631578948\n",
      "Prec 0.5870351992491417\n",
      "Recall 0.5541537988251198\n",
      "F1 0.5701207885055408\n",
      "468\n",
      "468\n",
      "71744\n",
      "51012\n",
      "Acc: 0.711028099910794\n",
      "Prec 0.590891516306251\n",
      "Recall 0.5611190450386293\n",
      "F1 0.5756205619575586\n",
      "Epoch: 592, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50911\n",
      "Acc: 0.6977933114035088\n",
      "Prec 0.5829052860368329\n",
      "Recall 0.5551797329874667\n",
      "F1 0.5687047903263932\n",
      "468\n",
      "468\n",
      "71744\n",
      "50969\n",
      "Acc: 0.7104287466547725\n",
      "Prec 0.5929226749052038\n",
      "Recall 0.5566019880557369\n",
      "F1 0.5741885324417358\n",
      "Epoch: 593, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51024\n",
      "Acc: 0.6993421052631579\n",
      "Prec 0.5859551181234681\n",
      "Recall 0.5534528059341126\n",
      "F1 0.569240387800742\n",
      "468\n",
      "468\n",
      "71744\n",
      "51078\n",
      "Acc: 0.7119480374665478\n",
      "Prec 0.5932728720720174\n",
      "Recall 0.5624246744261072\n",
      "F1 0.5774370689494017\n",
      "Epoch: 594, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50977\n",
      "Acc: 0.6986979166666667\n",
      "Prec 0.5841174691792929\n",
      "Recall 0.5563132755496403\n",
      "F1 0.5698764332456431\n",
      "468\n",
      "468\n",
      "71744\n",
      "50913\n",
      "Acc: 0.7096481935771632\n",
      "Prec 0.5918975948499795\n",
      "Recall 0.5554269196767386\n",
      "F1 0.5730825999254607\n",
      "Epoch: 595, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51066\n",
      "Acc: 0.6999177631578948\n",
      "Prec 0.5867656297813821\n",
      "Recall 0.554222772959164\n",
      "F1 0.5700301135988253\n",
      "468\n",
      "468\n",
      "71744\n",
      "51150\n",
      "Acc: 0.7129516057091883\n",
      "Prec 0.5942315545868849\n",
      "Recall 0.5665021437688177\n",
      "F1 0.580035627543894\n",
      "Epoch: 596, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50995\n",
      "Acc: 0.6989446271929824\n",
      "Prec 0.5827675739994865\n",
      "Recall 0.5573936273244491\n",
      "F1 0.5697982558632148\n",
      "468\n",
      "468\n",
      "71744\n",
      "51225\n",
      "Acc: 0.7139969892952721\n",
      "Prec 0.5947980279444834\n",
      "Recall 0.5630694807708558\n",
      "F1 0.5784990324667056\n",
      "Epoch: 597, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51218\n",
      "Acc: 0.7020010964912281\n",
      "Prec 0.5881391924675904\n",
      "Recall 0.5586135934981683\n",
      "F1 0.572996293189283\n",
      "468\n",
      "468\n",
      "71744\n",
      "51282\n",
      "Acc: 0.7147914808206958\n",
      "Prec 0.5954912841624297\n",
      "Recall 0.5676946096950948\n",
      "F1 0.5812608181110371\n",
      "Epoch: 598, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50953\n",
      "Acc: 0.6983689692982457\n",
      "Prec 0.5840726109702582\n",
      "Recall 0.556716202230515\n",
      "F1 0.5700663997464992\n",
      "468\n",
      "468\n",
      "71744\n",
      "50834\n",
      "Acc: 0.7085470561998216\n",
      "Prec 0.5914789404699978\n",
      "Recall 0.5522690582741\n",
      "F1 0.5712019042673998\n",
      "Epoch: 599, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50895\n",
      "Acc: 0.6975740131578947\n",
      "Prec 0.5820812906666811\n",
      "Recall 0.5506621300636977\n",
      "F1 0.5659359701812563\n",
      "468\n",
      "468\n",
      "71744\n",
      "51218\n",
      "Acc: 0.713899420160571\n",
      "Prec 0.5949314788058514\n",
      "Recall 0.5679305010428898\n",
      "F1 0.5811175164370652\n",
      "Epoch: 600, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50981\n",
      "Acc: 0.6987527412280702\n",
      "Prec 0.5827523190675954\n",
      "Recall 0.5538548829638441\n",
      "F1 0.5679362525544932\n",
      "468\n",
      "468\n",
      "71744\n",
      "51145\n",
      "Acc: 0.712881913470116\n",
      "Prec 0.5950873330849892\n",
      "Recall 0.5627005081289039\n",
      "F1 0.5784409419206112\n",
      "Epoch: 601, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50749\n",
      "Acc: 0.6955729166666667\n",
      "Prec 0.579879815933042\n",
      "Recall 0.5521796399428088\n",
      "F1 0.5656908324205976\n",
      "468\n",
      "468\n",
      "71744\n",
      "50997\n",
      "Acc: 0.7108190231935771\n",
      "Prec 0.5936573708146339\n",
      "Recall 0.5580618418289989\n",
      "F1 0.575309540963065\n",
      "Epoch: 602, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50796\n",
      "Acc: 0.6962171052631579\n",
      "Prec 0.5816389439098003\n",
      "Recall 0.5477585013490087\n",
      "F1 0.5641905382019765\n",
      "468\n",
      "468\n",
      "71744\n",
      "51056\n",
      "Acc: 0.7116413916146298\n",
      "Prec 0.5928646155289576\n",
      "Recall 0.5611832371555088\n",
      "F1 0.5765890614736289\n",
      "Epoch: 603, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50881\n",
      "Acc: 0.6973821271929824\n",
      "Prec 0.5833826074778442\n",
      "Recall 0.5494763713562658\n",
      "F1 0.5659220860820365\n",
      "468\n",
      "468\n",
      "71744\n",
      "51074\n",
      "Acc: 0.7118922836752899\n",
      "Prec 0.5946226135247732\n",
      "Recall 0.5611630856585968\n",
      "F1 0.5774085297018393\n",
      "Epoch: 604, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.800s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50828\n",
      "Acc: 0.696655701754386\n",
      "Prec 0.5822313396293987\n",
      "Recall 0.5499961984023604\n",
      "F1 0.5656548929088148\n",
      "468\n",
      "468\n",
      "71744\n",
      "50985\n",
      "Acc: 0.7106517618198037\n",
      "Prec 0.5930270111012108\n",
      "Recall 0.5585105780447529\n",
      "F1 0.5752514931135372\n",
      "Epoch: 605, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50782\n",
      "Acc: 0.6960252192982456\n",
      "Prec 0.5822013656476969\n",
      "Recall 0.5484760798925414\n",
      "F1 0.56483575222633\n",
      "468\n",
      "468\n",
      "71744\n",
      "51108\n",
      "Acc: 0.7123661909009813\n",
      "Prec 0.5936842127212704\n",
      "Recall 0.5631649445565505\n",
      "F1 0.578022008552979\n",
      "Epoch: 606, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50958\n",
      "Acc: 0.6984375\n",
      "Prec 0.5837879358149731\n",
      "Recall 0.5573776878254356\n",
      "F1 0.5702772027199917\n",
      "468\n",
      "468\n",
      "71744\n",
      "50855\n",
      "Acc: 0.7088397636039251\n",
      "Prec 0.5921145112405375\n",
      "Recall 0.5529633377037829\n",
      "F1 0.5718696187167839\n",
      "Epoch: 607, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50935\n",
      "Acc: 0.6981222587719298\n",
      "Prec 0.5847218294762347\n",
      "Recall 0.5503391882355729\n",
      "F1 0.5670097588696752\n",
      "468\n",
      "468\n",
      "71744\n",
      "51048\n",
      "Acc: 0.7115298840321141\n",
      "Prec 0.5920722586384147\n",
      "Recall 0.5671206401155344\n",
      "F1 0.579327907675425\n",
      "Epoch: 608, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51099\n",
      "Acc: 0.7003700657894737\n",
      "Prec 0.5856412793415159\n",
      "Recall 0.5569170614821111\n",
      "F1 0.5709181032075604\n",
      "468\n",
      "468\n",
      "71744\n",
      "51326\n",
      "Acc: 0.7154047725245317\n",
      "Prec 0.5969499205434842\n",
      "Recall 0.5709167456598846\n",
      "F1 0.5836431774640022\n",
      "Epoch: 609, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51174\n",
      "Acc: 0.7013980263157895\n",
      "Prec 0.5867774107266026\n",
      "Recall 0.560256314273422\n",
      "F1 0.5732102592407756\n",
      "468\n",
      "468\n",
      "71744\n",
      "51214\n",
      "Acc: 0.7138436663693131\n",
      "Prec 0.5947185676023942\n",
      "Recall 0.5671160367009161\n",
      "F1 0.5805894156739478\n",
      "Epoch: 610, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.828s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "51023\n",
      "Acc: 0.699328399122807\n",
      "Prec 0.5843254715143311\n",
      "Recall 0.5587994676866141\n",
      "F1 0.5712774715004976\n",
      "468\n",
      "468\n",
      "71744\n",
      "51255\n",
      "Acc: 0.7144151427297056\n",
      "Prec 0.5970720323217815\n",
      "Recall 0.5653496918086797\n",
      "F1 0.5807780127529977\n",
      "Epoch: 611, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51069\n",
      "Acc: 0.6999588815789474\n",
      "Prec 0.5851789388650878\n",
      "Recall 0.5533178033206236\n",
      "F1 0.5688025498969892\n",
      "468\n",
      "468\n",
      "71744\n",
      "51183\n",
      "Acc: 0.7134115744870652\n",
      "Prec 0.5952383629309164\n",
      "Recall 0.5647365621484329\n",
      "F1 0.5795864366938313\n",
      "Epoch: 612, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50845\n",
      "Acc: 0.6968887061403509\n",
      "Prec 0.5819770797450331\n",
      "Recall 0.5560034747295718\n",
      "F1 0.5686938626127965\n",
      "468\n",
      "468\n",
      "71744\n",
      "50959\n",
      "Acc: 0.710289362176628\n",
      "Prec 0.59363864156366\n",
      "Recall 0.5557878250092824\n",
      "F1 0.5740900162493237\n",
      "Epoch: 613, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50848\n",
      "Acc: 0.6969298245614035\n",
      "Prec 0.5833261595573727\n",
      "Recall 0.5467141384183637\n",
      "F1 0.5644270550538358\n",
      "468\n",
      "468\n",
      "71744\n",
      "51210\n",
      "Acc: 0.7137879125780553\n",
      "Prec 0.5954844702195378\n",
      "Recall 0.5666815590594858\n",
      "F1 0.5807260915879024\n",
      "Epoch: 614, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51162\n",
      "Acc: 0.7012335526315789\n",
      "Prec 0.5872349762540182\n",
      "Recall 0.5567749629506628\n",
      "F1 0.5715994607082983\n",
      "468\n",
      "468\n",
      "71744\n",
      "51249\n",
      "Acc: 0.7143315120428189\n",
      "Prec 0.5964405693881617\n",
      "Recall 0.5689448237339538\n",
      "F1 0.5823683334647196\n",
      "Epoch: 615, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.816s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50902\n",
      "Acc: 0.6976699561403509\n",
      "Prec 0.5814683924632474\n",
      "Recall 0.553091795350242\n",
      "F1 0.56692522896773\n",
      "468\n",
      "468\n",
      "71744\n",
      "51127\n",
      "Acc: 0.7126310214094559\n",
      "Prec 0.5949859347202034\n",
      "Recall 0.5618407762533617\n",
      "F1 0.577938521391334\n",
      "Epoch: 616, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51180\n",
      "Acc: 0.7014802631578947\n",
      "Prec 0.5883011636999343\n",
      "Recall 0.5570919016647422\n",
      "F1 0.5722713432577492\n",
      "468\n",
      "468\n",
      "71744\n",
      "51285\n",
      "Acc: 0.7148332961641392\n",
      "Prec 0.5968466593475011\n",
      "Recall 0.566938893082042\n",
      "F1 0.5815084809805154\n",
      "Epoch: 617, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51238\n",
      "Acc: 0.7022752192982457\n",
      "Prec 0.5881988676531941\n",
      "Recall 0.5608449915354994\n",
      "F1 0.5741963395254044\n",
      "468\n",
      "468\n",
      "71744\n",
      "51286\n",
      "Acc: 0.7148472346119537\n",
      "Prec 0.5972159622685325\n",
      "Recall 0.5656995586236077\n",
      "F1 0.5810306943003075\n",
      "Epoch: 618, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.818s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51292\n",
      "Acc: 0.703015350877193\n",
      "Prec 0.5879178154962325\n",
      "Recall 0.5628460476101687\n",
      "F1 0.5751088114261765\n",
      "468\n",
      "468\n",
      "71744\n",
      "51280\n",
      "Acc: 0.7147636039250669\n",
      "Prec 0.5966955423701236\n",
      "Recall 0.564973470984448\n",
      "F1 0.5804013842467872\n",
      "Epoch: 619, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51023\n",
      "Acc: 0.699328399122807\n",
      "Prec 0.5839239620635437\n",
      "Recall 0.5573955627525137\n",
      "F1 0.5703514543686482\n",
      "468\n",
      "468\n",
      "71744\n",
      "51069\n",
      "Acc: 0.7118225914362176\n",
      "Prec 0.5946925150164264\n",
      "Recall 0.557554992474168\n",
      "F1 0.5755252731360483\n",
      "Epoch: 620, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51098\n",
      "Acc: 0.7003563596491228\n",
      "Prec 0.5853835623107048\n",
      "Recall 0.5542724861562277\n",
      "F1 0.5694033789815975\n",
      "468\n",
      "468\n",
      "71744\n",
      "51296\n",
      "Acc: 0.7149866190900981\n",
      "Prec 0.5970767579137354\n",
      "Recall 0.5670198686090312\n",
      "F1 0.5816602799254506\n",
      "Epoch: 621, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51120\n",
      "Acc: 0.7006578947368421\n",
      "Prec 0.5873886091839594\n",
      "Recall 0.5554565064495508\n",
      "F1 0.5709764522285645\n",
      "468\n",
      "468\n",
      "71744\n",
      "51302\n",
      "Acc: 0.7150702497769849\n",
      "Prec 0.5973171100266402\n",
      "Recall 0.5700128453150755\n",
      "F1 0.5833456494175103\n",
      "Epoch: 622, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51270\n",
      "Acc: 0.7027138157894737\n",
      "Prec 0.5883281596042749\n",
      "Recall 0.5600908960571801\n",
      "F1 0.5738623797018726\n",
      "468\n",
      "468\n",
      "71744\n",
      "51306\n",
      "Acc: 0.7151260035682426\n",
      "Prec 0.596765144055314\n",
      "Recall 0.5661741495689154\n",
      "F1 0.5810673003832008\n",
      "Epoch: 623, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.876s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51306\n",
      "Acc: 0.7032072368421053\n",
      "Prec 0.5888208990411791\n",
      "Recall 0.5640182770100909\n",
      "F1 0.5761527814873092\n",
      "468\n",
      "468\n",
      "71744\n",
      "51104\n",
      "Acc: 0.7123104371097234\n",
      "Prec 0.5957322834950898\n",
      "Recall 0.558150988731187\n",
      "F1 0.5763296358570786\n",
      "Epoch: 624, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50844\n",
      "Acc: 0.696875\n",
      "Prec 0.582150466465324\n",
      "Recall 0.5524093948927863\n",
      "F1 0.5668901181321773\n",
      "468\n",
      "468\n",
      "71744\n",
      "51398\n",
      "Acc: 0.7164083407671722\n",
      "Prec 0.5989480119858145\n",
      "Recall 0.5685748246182514\n",
      "F1 0.5833663380166877\n",
      "Epoch: 625, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.826s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50826\n",
      "Acc: 0.6966282894736842\n",
      "Prec 0.5822427511332652\n",
      "Recall 0.5507985762690882\n",
      "F1 0.5660843441649971\n",
      "468\n",
      "468\n",
      "71744\n",
      "51022\n",
      "Acc: 0.7111674843889384\n",
      "Prec 0.5946602746723487\n",
      "Recall 0.5578726816966896\n",
      "F1 0.5756793682934466\n",
      "Epoch: 626, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50899\n",
      "Acc: 0.6976288377192983\n",
      "Prec 0.5837923863477985\n",
      "Recall 0.548450141517576\n",
      "F1 0.5655696708601349\n",
      "468\n",
      "468\n",
      "71744\n",
      "51098\n",
      "Acc: 0.7122268064228368\n",
      "Prec 0.5943376858603407\n",
      "Recall 0.5645276464139302\n",
      "F1 0.5790492572858014\n",
      "Epoch: 627, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.785s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50933\n",
      "Acc: 0.6980948464912281\n",
      "Prec 0.5828822054881405\n",
      "Recall 0.5513817918274404\n",
      "F1 0.566694588996925\n",
      "468\n",
      "468\n",
      "71744\n",
      "51228\n",
      "Acc: 0.7140388046387154\n",
      "Prec 0.5962259795579051\n",
      "Recall 0.567918554360488\n",
      "F1 0.5817281042294149\n",
      "Epoch: 628, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.805s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51115\n",
      "Acc: 0.7005893640350878\n",
      "Prec 0.585523093505742\n",
      "Recall 0.5565784324646775\n",
      "F1 0.5706839858713844\n",
      "468\n",
      "468\n",
      "71744\n",
      "51194\n",
      "Acc: 0.7135648974130241\n",
      "Prec 0.5950679673070294\n",
      "Recall 0.5650694705935638\n",
      "F1 0.5796808727453261\n",
      "Epoch: 629, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51036\n",
      "Acc: 0.6995065789473685\n",
      "Prec 0.5864487748271454\n",
      "Recall 0.551564638596515\n",
      "F1 0.568472045632179\n",
      "468\n",
      "468\n",
      "71744\n",
      "51176\n",
      "Acc: 0.713314005352364\n",
      "Prec 0.5942857656082362\n",
      "Recall 0.5665193340537047\n",
      "F1 0.5800704636256735\n",
      "Epoch: 630, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.872s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51153\n",
      "Acc: 0.7011101973684211\n",
      "Prec 0.5869317647096727\n",
      "Recall 0.5593443632524174\n",
      "F1 0.5728060912998566\n",
      "468\n",
      "468\n",
      "71744\n",
      "51302\n",
      "Acc: 0.7150702497769849\n",
      "Prec 0.5982528127067578\n",
      "Recall 0.564940854779851\n",
      "F1 0.581119833836951\n",
      "Epoch: 631, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51077\n",
      "Acc: 0.7000685307017543\n",
      "Prec 0.5857413777638442\n",
      "Recall 0.5533103546461113\n",
      "F1 0.5690641789828189\n",
      "468\n",
      "468\n",
      "71744\n",
      "51286\n",
      "Acc: 0.7148472346119537\n",
      "Prec 0.5972679032369358\n",
      "Recall 0.5677776391064936\n",
      "F1 0.5821495343981832\n",
      "Epoch: 632, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51157\n",
      "Acc: 0.7011650219298246\n",
      "Prec 0.5867108903192179\n",
      "Recall 0.5577579109786118\n",
      "F1 0.5718681717872163\n",
      "468\n",
      "468\n",
      "71744\n",
      "51347\n",
      "Acc: 0.7156974799286352\n",
      "Prec 0.5979317784405862\n",
      "Recall 0.5686985662124088\n",
      "F1 0.5829489120534408\n",
      "Epoch: 633, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51237\n",
      "Acc: 0.7022615131578948\n",
      "Prec 0.5896094244317188\n",
      "Recall 0.5602537060455847\n",
      "F1 0.5745568431612474\n",
      "468\n",
      "468\n",
      "71744\n",
      "51331\n",
      "Acc: 0.7154744647636039\n",
      "Prec 0.5975223755234939\n",
      "Recall 0.5673479356296399\n",
      "F1 0.5820443409020962\n",
      "Epoch: 634, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51191\n",
      "Acc: 0.7016310307017544\n",
      "Prec 0.5883116389136188\n",
      "Recall 0.5577293156052635\n",
      "F1 0.5726124296694973\n",
      "468\n",
      "468\n",
      "71744\n",
      "51339\n",
      "Acc: 0.7155859723461195\n",
      "Prec 0.596880158754087\n",
      "Recall 0.5674296561380139\n",
      "F1 0.5817824412462272\n",
      "Epoch: 635, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51054\n",
      "Acc: 0.6997532894736842\n",
      "Prec 0.5854465999501703\n",
      "Recall 0.5560596364777345\n",
      "F1 0.570374848873597\n",
      "468\n",
      "468\n",
      "71744\n",
      "51352\n",
      "Acc: 0.7157671721677074\n",
      "Prec 0.5984124352813909\n",
      "Recall 0.5668949850811504\n",
      "F1 0.5822274923224606\n",
      "Epoch: 636, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.821s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51341\n",
      "Acc: 0.703686951754386\n",
      "Prec 0.5895086040766807\n",
      "Recall 0.5612654429265774\n",
      "F1 0.5750404410626924\n",
      "468\n",
      "468\n",
      "71744\n",
      "51420\n",
      "Acc: 0.71671498661909\n",
      "Prec 0.5990872557110286\n",
      "Recall 0.5690788055793717\n",
      "F1 0.5836975944006694\n",
      "Epoch: 637, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.804s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50980\n",
      "Acc: 0.6987390350877193\n",
      "Prec 0.5835224471814692\n",
      "Recall 0.5532307128565295\n",
      "F1 0.5679729791315463\n",
      "468\n",
      "468\n",
      "71744\n",
      "51167\n",
      "Acc: 0.7131885593220338\n",
      "Prec 0.5962716409716419\n",
      "Recall 0.5626165554455991\n",
      "F1 0.5789554122485482\n",
      "Epoch: 638, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "51210\n",
      "Acc: 0.701891447368421\n",
      "Prec 0.5888761669392126\n",
      "Recall 0.5612300516494846\n",
      "F1 0.5747208322932074\n",
      "468\n",
      "468\n",
      "71744\n",
      "51384\n",
      "Acc: 0.7162132024977699\n",
      "Prec 0.5988432448978319\n",
      "Recall 0.5683852520816419\n",
      "F1 0.5832168587203851\n",
      "Epoch: 639, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51150\n",
      "Acc: 0.7010690789473685\n",
      "Prec 0.586900624628349\n",
      "Recall 0.5578581489344375\n",
      "F1 0.5720109836671693\n",
      "468\n",
      "468\n",
      "71744\n",
      "51336\n",
      "Acc: 0.7155441570026762\n",
      "Prec 0.5985561194968755\n",
      "Recall 0.5684005713592302\n",
      "F1 0.5830887178220726\n",
      "Epoch: 640, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51110\n",
      "Acc: 0.7005208333333334\n",
      "Prec 0.5877225848943434\n",
      "Recall 0.557112690329832\n",
      "F1 0.5720084234371196\n",
      "468\n",
      "468\n",
      "71744\n",
      "51228\n",
      "Acc: 0.7140388046387154\n",
      "Prec 0.5962640139399399\n",
      "Recall 0.5675626687794689\n",
      "F1 0.5815594367679591\n",
      "Epoch: 641, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.823s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51098\n",
      "Acc: 0.7003563596491228\n",
      "Prec 0.5860971555601685\n",
      "Recall 0.5558179187009665\n",
      "F1 0.5705560921345949\n",
      "468\n",
      "468\n",
      "71744\n",
      "51321\n",
      "Acc: 0.7153350802854594\n",
      "Prec 0.5960077272956883\n",
      "Recall 0.5742332300196721\n",
      "F1 0.584917901261692\n",
      "Epoch: 642, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.810s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50915\n",
      "Acc: 0.6978481359649122\n",
      "Prec 0.5846586344620666\n",
      "Recall 0.5546571384782054\n",
      "F1 0.5692628731723972\n",
      "468\n",
      "468\n",
      "71744\n",
      "51204\n",
      "Acc: 0.7137042818911686\n",
      "Prec 0.5972180770479302\n",
      "Recall 0.5628276734767103\n",
      "F1 0.5795131109460178\n",
      "Epoch: 643, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51034\n",
      "Acc: 0.6994791666666667\n",
      "Prec 0.5853422119301976\n",
      "Recall 0.5528275952009757\n",
      "F1 0.5686204736121542\n",
      "468\n",
      "468\n",
      "71744\n",
      "51217\n",
      "Acc: 0.7138854817127565\n",
      "Prec 0.5966204642599034\n",
      "Recall 0.5645596521882713\n",
      "F1 0.5801474500291431\n",
      "Epoch: 644, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51043\n",
      "Acc: 0.6996025219298245\n",
      "Prec 0.5848955318129986\n",
      "Recall 0.5538227935906359\n",
      "F1 0.5689352145492776\n",
      "468\n",
      "468\n",
      "71744\n",
      "51112\n",
      "Acc: 0.7124219446922391\n",
      "Prec 0.5948125089647244\n",
      "Recall 0.5617016761513891\n",
      "F1 0.5777831133956297\n",
      "Epoch: 645, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51110\n",
      "Acc: 0.7005208333333334\n",
      "Prec 0.5863877128262432\n",
      "Recall 0.5555120001802113\n",
      "F1 0.570532433843189\n",
      "468\n",
      "468\n",
      "71744\n",
      "51256\n",
      "Acc: 0.71442908117752\n",
      "Prec 0.5965150871347134\n",
      "Recall 0.5676460250082745\n",
      "F1 0.5817226061540096\n",
      "Epoch: 646, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51295\n",
      "Acc: 0.7030564692982456\n",
      "Prec 0.5908297209752855\n",
      "Recall 0.5583391949539781\n",
      "F1 0.5741251546078717\n",
      "468\n",
      "468\n",
      "71744\n",
      "51154\n",
      "Acc: 0.713007359500446\n",
      "Prec 0.5954095894520667\n",
      "Recall 0.5629609093248478\n",
      "F1 0.5787307674920733\n",
      "Epoch: 647, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51116\n",
      "Acc: 0.7006030701754385\n",
      "Prec 0.5864749716290968\n",
      "Recall 0.5559107821005519\n",
      "F1 0.570784008985263\n",
      "468\n",
      "468\n",
      "71744\n",
      "51308\n",
      "Acc: 0.7151538804638715\n",
      "Prec 0.5975188971038632\n",
      "Recall 0.5669381009530067\n",
      "F1 0.5818269448728153\n",
      "Epoch: 648, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.811s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51182\n",
      "Acc: 0.7015076754385965\n",
      "Prec 0.5874265053936772\n",
      "Recall 0.5581118111183438\n",
      "F1 0.5723940720244679\n",
      "468\n",
      "468\n",
      "71744\n",
      "51234\n",
      "Acc: 0.7141224353256022\n",
      "Prec 0.596082302556562\n",
      "Recall 0.5660257402843004\n",
      "F1 0.5806653325454202\n",
      "Epoch: 649, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50953\n",
      "Acc: 0.6983689692982457\n",
      "Prec 0.5831604062365314\n",
      "Recall 0.5528337914838981\n",
      "F1 0.5675922976894869\n",
      "468\n",
      "468\n",
      "71744\n",
      "51218\n",
      "Acc: 0.713899420160571\n",
      "Prec 0.5965063715264304\n",
      "Recall 0.5650449081784663\n",
      "F1 0.5803495615151033\n",
      "Epoch: 650, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51085\n",
      "Acc: 0.7001781798245614\n",
      "Prec 0.5870643829067429\n",
      "Recall 0.5571513581194252\n",
      "F1 0.5717168651196763\n",
      "468\n",
      "468\n",
      "71744\n",
      "51283\n",
      "Acc: 0.7148054192685103\n",
      "Prec 0.5975058388848414\n",
      "Recall 0.5640848028533472\n",
      "F1 0.580314529439961\n",
      "Epoch: 651, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51281\n",
      "Acc: 0.7028645833333333\n",
      "Prec 0.5891839910200988\n",
      "Recall 0.5573033667003993\n",
      "F1 0.5728004231190628\n",
      "468\n",
      "468\n",
      "71744\n",
      "51231\n",
      "Acc: 0.7140806199821588\n",
      "Prec 0.5959386163736665\n",
      "Recall 0.5635032753497544\n",
      "F1 0.5792672571711225\n",
      "Epoch: 652, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50993\n",
      "Acc: 0.6989172149122806\n",
      "Prec 0.5839950497409033\n",
      "Recall 0.5589457017227442\n",
      "F1 0.5711958777601085\n",
      "468\n",
      "468\n",
      "71744\n",
      "51037\n",
      "Acc: 0.7113765611061552\n",
      "Prec 0.5959782588973797\n",
      "Recall 0.5551843583106965\n",
      "F1 0.5748584992023951\n",
      "Epoch: 653, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51065\n",
      "Acc: 0.6999040570175439\n",
      "Prec 0.5869963547354841\n",
      "Recall 0.5530137208955147\n",
      "F1 0.5694985425540158\n",
      "468\n",
      "468\n",
      "71744\n",
      "50929\n",
      "Acc: 0.7098712087421944\n",
      "Prec 0.5933934823472445\n",
      "Recall 0.554910928108567\n",
      "F1 0.5735073818834823\n",
      "Epoch: 654, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50989\n",
      "Acc: 0.6988623903508772\n",
      "Prec 0.585734739281404\n",
      "Recall 0.5521683374433629\n",
      "F1 0.5684564595830924\n",
      "468\n",
      "468\n",
      "71744\n",
      "51059\n",
      "Acc: 0.7116832069580732\n",
      "Prec 0.5935562362557969\n",
      "Recall 0.5608908701744159\n",
      "F1 0.5767614159134978\n",
      "Epoch: 655, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.894s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51048\n",
      "Acc: 0.6996710526315789\n",
      "Prec 0.5854206327413657\n",
      "Recall 0.5557862096262357\n",
      "F1 0.5702186534971889\n",
      "468\n",
      "468\n",
      "71744\n",
      "51217\n",
      "Acc: 0.7138854817127565\n",
      "Prec 0.5959646790827599\n",
      "Recall 0.5685966184697059\n",
      "F1 0.5819590638397877\n",
      "Epoch: 656, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50853\n",
      "Acc: 0.6969983552631579\n",
      "Prec 0.583043823326968\n",
      "Recall 0.5550735086795012\n",
      "F1 0.5687149674760805\n",
      "468\n",
      "468\n",
      "71744\n",
      "51161\n",
      "Acc: 0.7131049286351472\n",
      "Prec 0.5976259194802453\n",
      "Recall 0.5599624510011708\n",
      "F1 0.5781814731169311\n",
      "Epoch: 657, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50921\n",
      "Acc: 0.6979303728070175\n",
      "Prec 0.5846393175120018\n",
      "Recall 0.5473119298572721\n",
      "F1 0.5653601670241294\n",
      "468\n",
      "468\n",
      "71744\n",
      "51247\n",
      "Acc: 0.71430363514719\n",
      "Prec 0.597219133334367\n",
      "Recall 0.5689126116028915\n",
      "F1 0.5827223181592586\n",
      "Epoch: 658, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.872s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51285\n",
      "Acc: 0.7029194078947368\n",
      "Prec 0.5893157994580916\n",
      "Recall 0.5602967153840351\n",
      "F1 0.5744400004302839\n",
      "468\n",
      "468\n",
      "71744\n",
      "51488\n",
      "Acc: 0.7176628010704728\n",
      "Prec 0.6003972104086127\n",
      "Recall 0.5718542271722865\n",
      "F1 0.5857782242743795\n",
      "Epoch: 659, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51284\n",
      "Acc: 0.7029057017543859\n",
      "Prec 0.5888501478997707\n",
      "Recall 0.5584441980317245\n",
      "F1 0.5732442590183998\n",
      "468\n",
      "468\n",
      "71744\n",
      "51471\n",
      "Acc: 0.7174258474576272\n",
      "Prec 0.6015044288407112\n",
      "Recall 0.5710941931818465\n",
      "F1 0.5859049806686282\n",
      "Epoch: 660, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51297\n",
      "Acc: 0.7030838815789474\n",
      "Prec 0.5896307781548896\n",
      "Recall 0.5588945446666184\n",
      "F1 0.5738513879149617\n",
      "468\n",
      "468\n",
      "71744\n",
      "51217\n",
      "Acc: 0.7138854817127565\n",
      "Prec 0.59676049774807\n",
      "Recall 0.5632463700161688\n",
      "F1 0.579519300214965\n",
      "Epoch: 661, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51128\n",
      "Acc: 0.7007675438596491\n",
      "Prec 0.587363035336375\n",
      "Recall 0.5597103199218184\n",
      "F1 0.5732033629956894\n",
      "468\n",
      "468\n",
      "71744\n",
      "51243\n",
      "Acc: 0.7142478813559322\n",
      "Prec 0.5986776380507596\n",
      "Recall 0.5616965895167797\n",
      "F1 0.5795978220198792\n",
      "Epoch: 662, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51186\n",
      "Acc: 0.7015625\n",
      "Prec 0.588651071553142\n",
      "Recall 0.5598979686037243\n",
      "F1 0.5739146134047456\n",
      "468\n",
      "468\n",
      "71744\n",
      "51242\n",
      "Acc: 0.7142339429081177\n",
      "Prec 0.5983522437631176\n",
      "Recall 0.5627447120424974\n",
      "F1 0.5800024871873486\n",
      "Epoch: 663, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51255\n",
      "Acc: 0.7025082236842105\n",
      "Prec 0.5923815835833827\n",
      "Recall 0.5564858542791006\n",
      "F1 0.573872947801422\n",
      "468\n",
      "468\n",
      "71744\n",
      "51275\n",
      "Acc: 0.7146939116859946\n",
      "Prec 0.5974573528658319\n",
      "Recall 0.5657525438138459\n",
      "F1 0.5811728702944697\n",
      "Epoch: 664, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51179\n",
      "Acc: 0.7014665570175439\n",
      "Prec 0.5866653532744939\n",
      "Recall 0.5594867920569212\n",
      "F1 0.5727538317691274\n",
      "468\n",
      "468\n",
      "71744\n",
      "51430\n",
      "Acc: 0.7168543710972346\n",
      "Prec 0.6006576387659088\n",
      "Recall 0.5683686963083933\n",
      "F1 0.5840672512332388\n",
      "Epoch: 665, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51326\n",
      "Acc: 0.7034813596491228\n",
      "Prec 0.5898926997988249\n",
      "Recall 0.5607490195781444\n",
      "F1 0.5749517812505563\n",
      "468\n",
      "468\n",
      "71744\n",
      "51374\n",
      "Acc: 0.7160738180196253\n",
      "Prec 0.6005873126509583\n",
      "Recall 0.566453939937315\n",
      "F1 0.5830214635052359\n",
      "Epoch: 666, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "50944\n",
      "Acc: 0.6982456140350877\n",
      "Prec 0.5833431296035378\n",
      "Recall 0.5581427542752686\n",
      "F1 0.5704647698981828\n",
      "468\n",
      "468\n",
      "71744\n",
      "50985\n",
      "Acc: 0.7106517618198037\n",
      "Prec 0.5961694778958301\n",
      "Recall 0.5524783688031955\n",
      "F1 0.5734929841633948\n",
      "Epoch: 667, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51039\n",
      "Acc: 0.699547697368421\n",
      "Prec 0.585913540350815\n",
      "Recall 0.551155637674266\n",
      "F1 0.5680033496553315\n",
      "468\n",
      "468\n",
      "71744\n",
      "51251\n",
      "Acc: 0.7143593889384479\n",
      "Prec 0.5980910634543377\n",
      "Recall 0.5663099631184427\n",
      "F1 0.5817667974464389\n",
      "Epoch: 668, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51181\n",
      "Acc: 0.7014939692982456\n",
      "Prec 0.5886659579061736\n",
      "Recall 0.5576718602446764\n",
      "F1 0.5727499077676779\n",
      "468\n",
      "468\n",
      "71744\n",
      "51431\n",
      "Acc: 0.7168683095450491\n",
      "Prec 0.5995233866135737\n",
      "Recall 0.56985193011799\n",
      "F1 0.584311220058092\n",
      "Epoch: 669, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51276\n",
      "Acc: 0.702796052631579\n",
      "Prec 0.5914794251835849\n",
      "Recall 0.5593621818960307\n",
      "F1 0.5749726457264099\n",
      "468\n",
      "468\n",
      "71744\n",
      "51288\n",
      "Acc: 0.7148751115075825\n",
      "Prec 0.5984431030776632\n",
      "Recall 0.5653030642083804\n",
      "F1 0.5814012186405279\n",
      "Epoch: 670, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.897s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51124\n",
      "Acc: 0.7007127192982456\n",
      "Prec 0.5858327399711578\n",
      "Recall 0.556829385881846\n",
      "F1 0.5709629775015116\n",
      "468\n",
      "468\n",
      "71744\n",
      "51264\n",
      "Acc: 0.7145405887600357\n",
      "Prec 0.5974906952915019\n",
      "Recall 0.5638433867198431\n",
      "F1 0.5801796096146314\n",
      "Epoch: 671, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51247\n",
      "Acc: 0.7023985745614035\n",
      "Prec 0.5892749651324926\n",
      "Recall 0.5607028868380605\n",
      "F1 0.5746339784283891\n",
      "468\n",
      "468\n",
      "71744\n",
      "51545\n",
      "Acc: 0.7184572925958965\n",
      "Prec 0.601239220234474\n",
      "Recall 0.5727691282806898\n",
      "F1 0.5866589696698624\n",
      "Epoch: 672, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51451\n",
      "Acc: 0.7051946271929824\n",
      "Prec 0.5925666700169132\n",
      "Recall 0.5641363633387861\n",
      "F1 0.5780021260760686\n",
      "468\n",
      "468\n",
      "71744\n",
      "51354\n",
      "Acc: 0.7157950490633364\n",
      "Prec 0.5995278720279821\n",
      "Recall 0.5659982662656914\n",
      "F1 0.5822807828961738\n",
      "Epoch: 673, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.839s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51289\n",
      "Acc: 0.7029742324561403\n",
      "Prec 0.5902150262792213\n",
      "Recall 0.5591086791730864\n",
      "F1 0.5742409074234088\n",
      "468\n",
      "468\n",
      "71744\n",
      "51247\n",
      "Acc: 0.71430363514719\n",
      "Prec 0.5972647076842538\n",
      "Recall 0.562833552653697\n",
      "F1 0.5795381801584164\n",
      "Epoch: 674, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51223\n",
      "Acc: 0.7020696271929825\n",
      "Prec 0.589790679531644\n",
      "Recall 0.5580491435984255\n",
      "F1 0.5734810327758966\n",
      "468\n",
      "468\n",
      "71744\n",
      "51507\n",
      "Acc: 0.7179276315789473\n",
      "Prec 0.6007892514660609\n",
      "Recall 0.5725092066707861\n",
      "F1 0.586308411722216\n",
      "Epoch: 675, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51284\n",
      "Acc: 0.7029057017543859\n",
      "Prec 0.5912121507196659\n",
      "Recall 0.559365008281259\n",
      "F1 0.5748478265819997\n",
      "468\n",
      "468\n",
      "71744\n",
      "51500\n",
      "Acc: 0.7178300624442462\n",
      "Prec 0.6009980745796636\n",
      "Recall 0.5725615150087746\n",
      "F1 0.5864352712065791\n",
      "Epoch: 676, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51249\n",
      "Acc: 0.7024259868421052\n",
      "Prec 0.5890628890963868\n",
      "Recall 0.5580123860227507\n",
      "F1 0.5731173801614543\n",
      "468\n",
      "468\n",
      "71744\n",
      "51505\n",
      "Acc: 0.7178997546833185\n",
      "Prec 0.6012892141693874\n",
      "Recall 0.5720454320620126\n",
      "F1 0.5863028922200939\n",
      "Epoch: 677, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51380\n",
      "Acc: 0.7042214912280702\n",
      "Prec 0.5913316956317265\n",
      "Recall 0.5616853975219839\n",
      "F1 0.5761274147632722\n",
      "468\n",
      "468\n",
      "71744\n",
      "51477\n",
      "Acc: 0.7175094781445138\n",
      "Prec 0.600071774614725\n",
      "Recall 0.5720380804582201\n",
      "F1 0.5857196825060434\n",
      "Epoch: 678, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51436\n",
      "Acc: 0.7049890350877193\n",
      "Prec 0.591657619017273\n",
      "Recall 0.5635628816486206\n",
      "F1 0.5772686210650457\n",
      "468\n",
      "468\n",
      "71744\n",
      "51540\n",
      "Acc: 0.7183876003568243\n",
      "Prec 0.6011819890985161\n",
      "Recall 0.5741326415787102\n",
      "F1 0.587346050940915\n",
      "Epoch: 679, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51218\n",
      "Acc: 0.7020010964912281\n",
      "Prec 0.5890895772930288\n",
      "Recall 0.5589588113943212\n",
      "F1 0.5736288002720538\n",
      "468\n",
      "468\n",
      "71744\n",
      "51353\n",
      "Acc: 0.7157811106155219\n",
      "Prec 0.5982166952336757\n",
      "Recall 0.5640960381448434\n",
      "F1 0.5806555465542217\n",
      "Epoch: 680, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51107\n",
      "Acc: 0.7004797149122807\n",
      "Prec 0.5862796083651302\n",
      "Recall 0.5644945705137191\n",
      "F1 0.5751808857015854\n",
      "468\n",
      "468\n",
      "71744\n",
      "51153\n",
      "Acc: 0.7129934210526315\n",
      "Prec 0.5988230890463699\n",
      "Recall 0.5555468517236924\n",
      "F1 0.5763737777808824\n",
      "Epoch: 681, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.891s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51155\n",
      "Acc: 0.7011376096491229\n",
      "Prec 0.5894971921949546\n",
      "Recall 0.5539681312588287\n",
      "F1 0.5711806930116575\n",
      "468\n",
      "468\n",
      "71744\n",
      "51330\n",
      "Acc: 0.7154605263157895\n",
      "Prec 0.6000720024283198\n",
      "Recall 0.5649296506544523\n",
      "F1 0.58197079086078\n",
      "Epoch: 682, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51196\n",
      "Acc: 0.7016995614035088\n",
      "Prec 0.590184856474734\n",
      "Recall 0.5557403885207884\n",
      "F1 0.5724449528775954\n",
      "468\n",
      "468\n",
      "71744\n",
      "51372\n",
      "Acc: 0.7160459411239964\n",
      "Prec 0.6004399086384291\n",
      "Recall 0.5665051973797909\n",
      "F1 0.5829791430696585\n",
      "Epoch: 683, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51295\n",
      "Acc: 0.7030564692982456\n",
      "Prec 0.5899505984344298\n",
      "Recall 0.5608123649493963\n",
      "F1 0.5750125800685363\n",
      "468\n",
      "468\n",
      "71744\n",
      "51471\n",
      "Acc: 0.7174258474576272\n",
      "Prec 0.6006623977887983\n",
      "Recall 0.5680458202130964\n",
      "F1 0.5838989735289941\n",
      "Epoch: 684, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "50863\n",
      "Acc: 0.6971354166666667\n",
      "Prec 0.5828217436222908\n",
      "Recall 0.5571797384252443\n",
      "F1 0.5697123587537093\n",
      "468\n",
      "468\n",
      "71744\n",
      "50996\n",
      "Acc: 0.7108050847457628\n",
      "Prec 0.5965196867131826\n",
      "Recall 0.5527797762042712\n",
      "F1 0.5738174071459359\n",
      "Epoch: 685, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.823s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51070\n",
      "Acc: 0.6999725877192983\n",
      "Prec 0.5888144275891054\n",
      "Recall 0.5497857034521717\n",
      "F1 0.5686311558366198\n",
      "468\n",
      "468\n",
      "71744\n",
      "51367\n",
      "Acc: 0.7159762488849242\n",
      "Prec 0.597975833975761\n",
      "Recall 0.5709090100531279\n",
      "F1 0.584129040862742\n",
      "Epoch: 686, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51313\n",
      "Acc: 0.7033031798245614\n",
      "Prec 0.5901178261522922\n",
      "Recall 0.5626150788944969\n",
      "F1 0.5760383621637741\n",
      "468\n",
      "468\n",
      "71744\n",
      "51297\n",
      "Acc: 0.7150005575379126\n",
      "Prec 0.5993306389670249\n",
      "Recall 0.5626340660337122\n",
      "F1 0.5804028863344625\n",
      "Epoch: 687, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51183\n",
      "Acc: 0.7015213815789474\n",
      "Prec 0.5871377458964965\n",
      "Recall 0.5563517244702832\n",
      "F1 0.571330311115737\n",
      "468\n",
      "468\n",
      "71744\n",
      "51634\n",
      "Acc: 0.7196978144513827\n",
      "Prec 0.6026929087500011\n",
      "Recall 0.5741932590636359\n",
      "F1 0.5880980080386253\n",
      "Epoch: 688, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.773s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51309\n",
      "Acc: 0.7032483552631579\n",
      "Prec 0.5904673195848024\n",
      "Recall 0.560751076377726\n",
      "F1 0.5752256673178214\n",
      "468\n",
      "468\n",
      "71744\n",
      "51355\n",
      "Acc: 0.7158089875111507\n",
      "Prec 0.5981312959227264\n",
      "Recall 0.5670973621339505\n",
      "F1 0.582201060336504\n",
      "Epoch: 689, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51102\n",
      "Acc: 0.7004111842105263\n",
      "Prec 0.5883563235404942\n",
      "Recall 0.5544587959894239\n",
      "F1 0.5709048352409134\n",
      "468\n",
      "468\n",
      "71744\n",
      "51354\n",
      "Acc: 0.7157950490633364\n",
      "Prec 0.5989698676203254\n",
      "Recall 0.568237977195431\n",
      "F1 0.583199346182109\n",
      "Epoch: 690, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51125\n",
      "Acc: 0.7007264254385965\n",
      "Prec 0.5877376535585962\n",
      "Recall 0.5535464047670308\n",
      "F1 0.57012986854627\n",
      "468\n",
      "468\n",
      "71744\n",
      "51425\n",
      "Acc: 0.7167846788581623\n",
      "Prec 0.599952765016845\n",
      "Recall 0.5700339443954309\n",
      "F1 0.5846108136823062\n",
      "Epoch: 691, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51365\n",
      "Acc: 0.704015899122807\n",
      "Prec 0.5922357745362713\n",
      "Recall 0.5594702190540618\n",
      "F1 0.5753869135968361\n",
      "468\n",
      "468\n",
      "71744\n",
      "51518\n",
      "Acc: 0.7180809545049064\n",
      "Prec 0.6010965487340814\n",
      "Recall 0.5732588777445663\n",
      "F1 0.5868477722739875\n",
      "Epoch: 692, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.814s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51050\n",
      "Acc: 0.6996984649122807\n",
      "Prec 0.5861826802432679\n",
      "Recall 0.5626100275777182\n",
      "F1 0.5741545043801524\n",
      "468\n",
      "468\n",
      "71744\n",
      "51287\n",
      "Acc: 0.714861173059768\n",
      "Prec 0.6002464965800459\n",
      "Recall 0.5610589359909031\n",
      "F1 0.5799915358320568\n",
      "Epoch: 693, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.762s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51297\n",
      "Acc: 0.7030838815789474\n",
      "Prec 0.5915650515365787\n",
      "Recall 0.5551055183485554\n",
      "F1 0.5727556513515428\n",
      "468\n",
      "468\n",
      "71744\n",
      "51473\n",
      "Acc: 0.717453724353256\n",
      "Prec 0.6004223840001404\n",
      "Recall 0.5717180714315965\n",
      "F1 0.585718760638602\n",
      "Epoch: 694, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.866s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "51389\n",
      "Acc: 0.7043448464912281\n",
      "Prec 0.5919789108498675\n",
      "Recall 0.5626868678370052\n",
      "F1 0.5769613429619184\n",
      "468\n",
      "468\n",
      "71744\n",
      "51502\n",
      "Acc: 0.7178579393398751\n",
      "Prec 0.601621643845745\n",
      "Recall 0.5727217809222382\n",
      "F1 0.5868161085378839\n",
      "Epoch: 695, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51370\n",
      "Acc: 0.7040844298245614\n",
      "Prec 0.5917512957770752\n",
      "Recall 0.5640092697637834\n",
      "F1 0.5775473331828295\n",
      "468\n",
      "468\n",
      "71744\n",
      "51465\n",
      "Acc: 0.7173422167707404\n",
      "Prec 0.6013790904633853\n",
      "Recall 0.5680636940528437\n",
      "F1 0.584246843330759\n",
      "Epoch: 696, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51286\n",
      "Acc: 0.7029331140350877\n",
      "Prec 0.5899346547397801\n",
      "Recall 0.5572184542738235\n",
      "F1 0.5731100301324534\n",
      "468\n",
      "468\n",
      "71744\n",
      "51475\n",
      "Acc: 0.7174816012488849\n",
      "Prec 0.6001904866139486\n",
      "Recall 0.5738172654629231\n",
      "F1 0.5867076485251803\n",
      "Epoch: 697, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51429\n",
      "Acc: 0.7048930921052632\n",
      "Prec 0.5941141615334272\n",
      "Recall 0.561529925298909\n",
      "F1 0.577362675145658\n",
      "468\n",
      "468\n",
      "71744\n",
      "51587\n",
      "Acc: 0.7190427074041035\n",
      "Prec 0.6023643787635035\n",
      "Recall 0.5726198556692442\n",
      "F1 0.5871156284822369\n",
      "Epoch: 698, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51469\n",
      "Acc: 0.7054413377192983\n",
      "Prec 0.5916674054292047\n",
      "Recall 0.5647773639022778\n",
      "F1 0.5779097565348977\n",
      "468\n",
      "468\n",
      "71744\n",
      "51584\n",
      "Acc: 0.7190008920606601\n",
      "Prec 0.6026794436472073\n",
      "Recall 0.5718589859995883\n",
      "F1 0.5868648429503147\n",
      "Epoch: 699, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.816s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51455\n",
      "Acc: 0.7052494517543859\n",
      "Prec 0.5915429016724375\n",
      "Recall 0.5630509347658917\n",
      "F1 0.5769453694092784\n",
      "468\n",
      "468\n",
      "71744\n",
      "51519\n",
      "Acc: 0.7180948929527208\n",
      "Prec 0.6018045495807843\n",
      "Recall 0.570231714059282\n",
      "F1 0.5855928702586836\n",
      "Epoch: 700, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51596\n",
      "Acc: 0.7071820175438597\n",
      "Prec 0.5957846199203407\n",
      "Recall 0.5652119825782933\n",
      "F1 0.5800957651212884\n",
      "468\n",
      "468\n",
      "71744\n",
      "51510\n",
      "Acc: 0.7179694469223907\n",
      "Prec 0.6013507170068784\n",
      "Recall 0.570993958829045\n",
      "F1 0.5857793081264413\n",
      "Epoch: 701, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51363\n",
      "Acc: 0.7039884868421052\n",
      "Prec 0.5897234056846966\n",
      "Recall 0.562212513873681\n",
      "F1 0.5756394479429889\n",
      "468\n",
      "468\n",
      "71744\n",
      "51575\n",
      "Acc: 0.71887544603033\n",
      "Prec 0.6016537407313175\n",
      "Recall 0.5738205931411672\n",
      "F1 0.5874076471490162\n",
      "Epoch: 702, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51285\n",
      "Acc: 0.7029194078947368\n",
      "Prec 0.5886557583361735\n",
      "Recall 0.5603641202651835\n",
      "F1 0.5741616351504863\n",
      "468\n",
      "468\n",
      "71744\n",
      "51419\n",
      "Acc: 0.7167010481712757\n",
      "Prec 0.599920288405955\n",
      "Recall 0.5660468367883248\n",
      "F1 0.5824915201116793\n",
      "Epoch: 703, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.806s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51268\n",
      "Acc: 0.702686403508772\n",
      "Prec 0.589164551983044\n",
      "Recall 0.5561532674528731\n",
      "F1 0.5721831706314626\n",
      "468\n",
      "468\n",
      "71744\n",
      "51437\n",
      "Acc: 0.7169519402319358\n",
      "Prec 0.5994662341325809\n",
      "Recall 0.5691829072614634\n",
      "F1 0.5839322031959906\n",
      "Epoch: 704, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51364\n",
      "Acc: 0.7040021929824561\n",
      "Prec 0.59143860331213\n",
      "Recall 0.564188348987806\n",
      "F1 0.5774921889217399\n",
      "468\n",
      "468\n",
      "71744\n",
      "51498\n",
      "Acc: 0.7178021855486173\n",
      "Prec 0.6024021423144552\n",
      "Recall 0.5668495172491936\n",
      "F1 0.5840853177634353\n",
      "Epoch: 705, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51307\n",
      "Acc: 0.7032209429824562\n",
      "Prec 0.5906093820890885\n",
      "Recall 0.5596323751987968\n",
      "F1 0.574703759829658\n",
      "468\n",
      "468\n",
      "71744\n",
      "51609\n",
      "Acc: 0.7193493532560215\n",
      "Prec 0.6034572102078727\n",
      "Recall 0.5727368193517388\n",
      "F1 0.587695829945231\n",
      "Epoch: 706, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.817s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51489\n",
      "Acc: 0.7057154605263158\n",
      "Prec 0.5943169071864384\n",
      "Recall 0.5635986806325352\n",
      "F1 0.5785503335330381\n",
      "468\n",
      "468\n",
      "71744\n",
      "51342\n",
      "Acc: 0.7156277876895629\n",
      "Prec 0.600185303534723\n",
      "Recall 0.563798797588473\n",
      "F1 0.581423323800769\n",
      "Epoch: 707, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51262\n",
      "Acc: 0.7026041666666667\n",
      "Prec 0.5897206758527775\n",
      "Recall 0.5627026021875067\n",
      "F1 0.5758949253965578\n",
      "468\n",
      "468\n",
      "71744\n",
      "51533\n",
      "Acc: 0.7182900312221231\n",
      "Prec 0.6035540547738062\n",
      "Recall 0.5662394326807241\n",
      "F1 0.5843016040565103\n",
      "Epoch: 708, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51427\n",
      "Acc: 0.7048656798245614\n",
      "Prec 0.5943787069079879\n",
      "Recall 0.5633748397929388\n",
      "F1 0.5784616419182051\n",
      "468\n",
      "468\n",
      "71744\n",
      "51480\n",
      "Acc: 0.7175512934879572\n",
      "Prec 0.6014960089008669\n",
      "Recall 0.5676374686402103\n",
      "F1 0.5840764608122879\n",
      "Epoch: 709, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51256\n",
      "Acc: 0.7025219298245614\n",
      "Prec 0.5911041664192097\n",
      "Recall 0.5565561990932564\n",
      "F1 0.5733101848185931\n",
      "468\n",
      "468\n",
      "71744\n",
      "51620\n",
      "Acc: 0.7195026761819804\n",
      "Prec 0.6026261029221117\n",
      "Recall 0.5757193190374256\n",
      "F1 0.5888655111529923\n",
      "Epoch: 710, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51263\n",
      "Acc: 0.7026178728070176\n",
      "Prec 0.5885488746717491\n",
      "Recall 0.5586485097930558\n",
      "F1 0.5732090331240459\n",
      "468\n",
      "468\n",
      "71744\n",
      "51434\n",
      "Acc: 0.7169101248884924\n",
      "Prec 0.6016335572143245\n",
      "Recall 0.5672188283016516\n",
      "F1 0.5839195532623558\n",
      "Epoch: 711, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51334\n",
      "Acc: 0.7035910087719298\n",
      "Prec 0.5928708668423758\n",
      "Recall 0.5592841869703491\n",
      "F1 0.5755879812236468\n",
      "468\n",
      "468\n",
      "71744\n",
      "51350\n",
      "Acc: 0.7157392952720785\n",
      "Prec 0.5995757277094725\n",
      "Recall 0.5668947083645861\n",
      "F1 0.5827774057374672\n",
      "Epoch: 712, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51212\n",
      "Acc: 0.7019188596491228\n",
      "Prec 0.5900723457339437\n",
      "Recall 0.5557456668479398\n",
      "F1 0.5723948230304222\n",
      "468\n",
      "468\n",
      "71744\n",
      "51552\n",
      "Acc: 0.7185548617305977\n",
      "Prec 0.6029936407092381\n",
      "Recall 0.5715169087563653\n",
      "F1 0.5868334885449791\n",
      "Epoch: 713, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51297\n",
      "Acc: 0.7030838815789474\n",
      "Prec 0.5891633557637622\n",
      "Recall 0.5590125980910098\n",
      "F1 0.5736921019810465\n",
      "468\n",
      "468\n",
      "71744\n",
      "51554\n",
      "Acc: 0.7185827386262266\n",
      "Prec 0.6020379276372988\n",
      "Recall 0.5687514921695684\n",
      "F1 0.5849215305394068\n",
      "Epoch: 714, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.826s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51356\n",
      "Acc: 0.7038925438596492\n",
      "Prec 0.5915509290548266\n",
      "Recall 0.560326398820555\n",
      "F1 0.575515454250011\n",
      "468\n",
      "468\n",
      "71744\n",
      "51545\n",
      "Acc: 0.7184572925958965\n",
      "Prec 0.6013461382900697\n",
      "Recall 0.5733616813525239\n",
      "F1 0.5870205801979664\n",
      "Epoch: 715, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.780s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51486\n",
      "Acc: 0.7056743421052631\n",
      "Prec 0.5928953303685348\n",
      "Recall 0.5621131215903394\n",
      "F1 0.5770940366099752\n",
      "468\n",
      "468\n",
      "71744\n",
      "51726\n",
      "Acc: 0.7209801516503123\n",
      "Prec 0.6042835501685008\n",
      "Recall 0.5768856367405854\n",
      "F1 0.5902668381030985\n",
      "Epoch: 716, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51287\n",
      "Acc: 0.7029468201754386\n",
      "Prec 0.5900394622674916\n",
      "Recall 0.5624547210736481\n",
      "F1 0.5759169737585969\n",
      "468\n",
      "468\n",
      "71744\n",
      "51399\n",
      "Acc: 0.7164222792149866\n",
      "Prec 0.6010549407094096\n",
      "Recall 0.5622462964268126\n",
      "F1 0.5810032751187219\n",
      "Epoch: 717, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51309\n",
      "Acc: 0.7032483552631579\n",
      "Prec 0.5904118272804572\n",
      "Recall 0.560731181534029\n",
      "F1 0.5751888670089443\n",
      "468\n",
      "468\n",
      "71744\n",
      "51491\n",
      "Acc: 0.7177046164139161\n",
      "Prec 0.601346310709814\n",
      "Recall 0.5734325763608895\n",
      "F1 0.5870578166335247\n",
      "Epoch: 718, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.864s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51083\n",
      "Acc: 0.7001507675438596\n",
      "Prec 0.5860712880061034\n",
      "Recall 0.5576738141844456\n",
      "F1 0.5715200177738609\n",
      "468\n",
      "468\n",
      "71744\n",
      "51753\n",
      "Acc: 0.7213564897413024\n",
      "Prec 0.6067492708135935\n",
      "Recall 0.5766469020338821\n",
      "F1 0.5913152253722401\n",
      "Epoch: 719, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51345\n",
      "Acc: 0.7037417763157895\n",
      "Prec 0.5909387575810713\n",
      "Recall 0.5593457549423837\n",
      "F1 0.5747083993311763\n",
      "468\n",
      "468\n",
      "71744\n",
      "51517\n",
      "Acc: 0.7180670160570919\n",
      "Prec 0.6016447028930888\n",
      "Recall 0.5684128041465818\n",
      "F1 0.58455682838468\n",
      "Epoch: 720, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51133\n",
      "Acc: 0.7008360745614035\n",
      "Prec 0.5873774581206215\n",
      "Recall 0.5576759865003721\n",
      "F1 0.5721415099780276\n",
      "468\n",
      "468\n",
      "71744\n",
      "51511\n",
      "Acc: 0.7179833853702052\n",
      "Prec 0.6042696649521152\n",
      "Recall 0.568169532227586\n",
      "F1 0.5856638258103907\n",
      "Epoch: 721, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51233\n",
      "Acc: 0.7022066885964913\n",
      "Prec 0.5896794979730536\n",
      "Recall 0.5581579027780399\n",
      "F1 0.5734858816840718\n",
      "468\n",
      "468\n",
      "71744\n",
      "51617\n",
      "Acc: 0.719460860838537\n",
      "Prec 0.6037671581516967\n",
      "Recall 0.5709151417810664\n",
      "F1 0.5868817683192427\n",
      "Epoch: 722, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.866s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "51421\n",
      "Acc: 0.7047834429824561\n",
      "Prec 0.5928837990897605\n",
      "Recall 0.560165274589107\n",
      "F1 0.5760603320323979\n",
      "468\n",
      "468\n",
      "71744\n",
      "51607\n",
      "Acc: 0.7193214763603925\n",
      "Prec 0.6037877519327223\n",
      "Recall 0.57347160339789\n",
      "F1 0.5882393351049245\n",
      "Epoch: 723, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51491\n",
      "Acc: 0.7057428728070175\n",
      "Prec 0.5930677770881445\n",
      "Recall 0.5654967087126623\n",
      "F1 0.5789541801034327\n",
      "468\n",
      "468\n",
      "71744\n",
      "51570\n",
      "Acc: 0.7188057537912578\n",
      "Prec 0.6030677101092422\n",
      "Recall 0.5693257992904451\n",
      "F1 0.585711202478437\n",
      "Epoch: 724, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51388\n",
      "Acc: 0.7043311403508772\n",
      "Prec 0.5916323080247491\n",
      "Recall 0.5598530182928553\n",
      "F1 0.575304132492027\n",
      "468\n",
      "468\n",
      "71744\n",
      "51569\n",
      "Acc: 0.7187918153434434\n",
      "Prec 0.602416721151361\n",
      "Recall 0.5722686818833445\n",
      "F1 0.58695583016041\n",
      "Epoch: 725, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51488\n",
      "Acc: 0.7057017543859649\n",
      "Prec 0.5933983794911817\n",
      "Recall 0.5627864311165448\n",
      "F1 0.5776871537494864\n",
      "468\n",
      "468\n",
      "71744\n",
      "51505\n",
      "Acc: 0.7178997546833185\n",
      "Prec 0.6021975415247153\n",
      "Recall 0.5696876995112753\n",
      "F1 0.5854916847988951\n",
      "Epoch: 726, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51277\n",
      "Acc: 0.7028097587719299\n",
      "Prec 0.5883133080543693\n",
      "Recall 0.5613468164278265\n",
      "F1 0.5745137984796789\n",
      "468\n",
      "468\n",
      "71744\n",
      "51232\n",
      "Acc: 0.7140945584299733\n",
      "Prec 0.59868855735482\n",
      "Recall 0.5596923388579639\n",
      "F1 0.5785340556097501\n",
      "Epoch: 727, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.798s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51182\n",
      "Acc: 0.7015076754385965\n",
      "Prec 0.5879608827149555\n",
      "Recall 0.555759993057388\n",
      "F1 0.5714071379085707\n",
      "468\n",
      "468\n",
      "71744\n",
      "51537\n",
      "Acc: 0.7183457850133809\n",
      "Prec 0.6014045538160743\n",
      "Recall 0.574077555508361\n",
      "F1 0.5874234127216955\n",
      "Epoch: 728, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51414\n",
      "Acc: 0.7046875\n",
      "Prec 0.5917918368097009\n",
      "Recall 0.5629462602182679\n",
      "F1 0.57700876452793\n",
      "468\n",
      "468\n",
      "71744\n",
      "51633\n",
      "Acc: 0.7196838760035682\n",
      "Prec 0.6052164445904129\n",
      "Recall 0.5711170910140855\n",
      "F1 0.5876725347131084\n",
      "Epoch: 729, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51454\n",
      "Acc: 0.7052357456140351\n",
      "Prec 0.5923547006155424\n",
      "Recall 0.5602610159166432\n",
      "F1 0.5758610464697679\n",
      "468\n",
      "468\n",
      "71744\n",
      "51623\n",
      "Acc: 0.7195444915254238\n",
      "Prec 0.6036980981877358\n",
      "Recall 0.5741765653302187\n",
      "F1 0.5885673769033161\n",
      "Epoch: 730, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.790s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51561\n",
      "Acc: 0.706702302631579\n",
      "Prec 0.5939652062175566\n",
      "Recall 0.5673228048840643\n",
      "F1 0.5803383890534259\n",
      "468\n",
      "468\n",
      "71744\n",
      "51688\n",
      "Acc: 0.7204504906333631\n",
      "Prec 0.6040043458240655\n",
      "Recall 0.572994428499186\n",
      "F1 0.5880908841990595\n",
      "Epoch: 731, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.803s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51478\n",
      "Acc: 0.7055646929824562\n",
      "Prec 0.5927806366921976\n",
      "Recall 0.5656366513308769\n",
      "F1 0.5788906256476397\n",
      "468\n",
      "468\n",
      "71744\n",
      "51477\n",
      "Acc: 0.7175094781445138\n",
      "Prec 0.6025898511411235\n",
      "Recall 0.5648983615278788\n",
      "F1 0.5831356854640164\n",
      "Epoch: 732, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.864s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51398\n",
      "Acc: 0.704468201754386\n",
      "Prec 0.5934216057823853\n",
      "Recall 0.5603785684746517\n",
      "F1 0.5764269366043286\n",
      "468\n",
      "468\n",
      "71744\n",
      "51660\n",
      "Acc: 0.7200602140945584\n",
      "Prec 0.6044973947512159\n",
      "Recall 0.5754562920815274\n",
      "F1 0.5896194625913092\n",
      "Epoch: 733, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51472\n",
      "Acc: 0.7054824561403509\n",
      "Prec 0.5934309805820529\n",
      "Recall 0.5641404717528083\n",
      "F1 0.5784151512427702\n",
      "468\n",
      "468\n",
      "71744\n",
      "51613\n",
      "Acc: 0.7194051070472792\n",
      "Prec 0.6037434943638094\n",
      "Recall 0.5720184722045807\n",
      "F1 0.5874529727431069\n",
      "Epoch: 734, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.883s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51523\n",
      "Acc: 0.7061814692982457\n",
      "Prec 0.5933844485737623\n",
      "Recall 0.5634037729107338\n",
      "F1 0.5780056036255096\n",
      "468\n",
      "468\n",
      "71744\n",
      "51673\n",
      "Acc: 0.7202414139161463\n",
      "Prec 0.6053764021023483\n",
      "Recall 0.5727474871978687\n",
      "F1 0.5886101050356534\n",
      "Epoch: 735, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51110\n",
      "Acc: 0.7005208333333334\n",
      "Prec 0.5866438850934724\n",
      "Recall 0.5592975850288525\n",
      "F1 0.5726444443444365\n",
      "468\n",
      "468\n",
      "71744\n",
      "51580\n",
      "Acc: 0.7189451382694023\n",
      "Prec 0.6055887855896632\n",
      "Recall 0.5669641182164402\n",
      "F1 0.5856402908714899\n",
      "Epoch: 736, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51346\n",
      "Acc: 0.7037554824561404\n",
      "Prec 0.5920799454046393\n",
      "Recall 0.5602016764519476\n",
      "F1 0.5756998492692057\n",
      "468\n",
      "468\n",
      "71744\n",
      "51510\n",
      "Acc: 0.7179694469223907\n",
      "Prec 0.6032114446216548\n",
      "Recall 0.5678108214261762\n",
      "F1 0.5849760432314481\n",
      "Epoch: 737, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.864s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51356\n",
      "Acc: 0.7038925438596492\n",
      "Prec 0.5913366416650966\n",
      "Recall 0.561766112438821\n",
      "F1 0.5761722190820338\n",
      "468\n",
      "468\n",
      "71744\n",
      "51498\n",
      "Acc: 0.7178021855486173\n",
      "Prec 0.6032904719570387\n",
      "Recall 0.5670179727918419\n",
      "F1 0.5845921080867101\n",
      "Epoch: 738, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51527\n",
      "Acc: 0.7062362938596491\n",
      "Prec 0.5952926315759465\n",
      "Recall 0.5635296986747532\n",
      "F1 0.5789758594360526\n",
      "468\n",
      "468\n",
      "71744\n",
      "51785\n",
      "Acc: 0.7218025200713648\n",
      "Prec 0.6057761364071003\n",
      "Recall 0.5781711878712241\n",
      "F1 0.5916518432676457\n",
      "Epoch: 739, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.867s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51675\n",
      "Acc: 0.708264802631579\n",
      "Prec 0.5955303018691415\n",
      "Recall 0.5684442370529342\n",
      "F1 0.5816721187070071\n",
      "468\n",
      "468\n",
      "71744\n",
      "51571\n",
      "Acc: 0.7188196922390723\n",
      "Prec 0.6045603824824052\n",
      "Recall 0.5680659401245441\n",
      "F1 0.5857452718158627\n",
      "Epoch: 740, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51497\n",
      "Acc: 0.7058251096491228\n",
      "Prec 0.592925323186381\n",
      "Recall 0.5641296335959954\n",
      "F1 0.5781691584453096\n",
      "468\n",
      "468\n",
      "71744\n",
      "51392\n",
      "Acc: 0.7163247100802854\n",
      "Prec 0.6018788417110914\n",
      "Recall 0.5633176821204059\n",
      "F1 0.5819601879949269\n",
      "Epoch: 741, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51274\n",
      "Acc: 0.7027686403508772\n",
      "Prec 0.5898256743901006\n",
      "Recall 0.5615194296688135\n",
      "F1 0.5753245922876749\n",
      "468\n",
      "468\n",
      "71744\n",
      "51615\n",
      "Acc: 0.7194329839429081\n",
      "Prec 0.6048038832356285\n",
      "Recall 0.5700062299372924\n",
      "F1 0.5868897066326705\n",
      "Epoch: 742, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51301\n",
      "Acc: 0.7031387061403509\n",
      "Prec 0.590930325043251\n",
      "Recall 0.5596964680245445\n",
      "F1 0.5748894737510535\n",
      "468\n",
      "468\n",
      "71744\n",
      "51546\n",
      "Acc: 0.718471231043711\n",
      "Prec 0.6032980833513412\n",
      "Recall 0.5706463106318768\n",
      "F1 0.5865181131920748\n",
      "Epoch: 743, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.895s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51445\n",
      "Acc: 0.7051123903508771\n",
      "Prec 0.5930870241385526\n",
      "Recall 0.5618582357563836\n",
      "F1 0.5770504293213072\n",
      "468\n",
      "468\n",
      "71744\n",
      "51738\n",
      "Acc: 0.7211474130240857\n",
      "Prec 0.6060965477806715\n",
      "Recall 0.5750495332859081\n",
      "F1 0.5901649973943041\n",
      "Epoch: 744, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.893s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51439\n",
      "Acc: 0.705030153508772\n",
      "Prec 0.5929536699100332\n",
      "Recall 0.5618856280520045\n",
      "F1 0.5770017452836838\n",
      "468\n",
      "468\n",
      "71744\n",
      "51682\n",
      "Acc: 0.7203668599464763\n",
      "Prec 0.6046789047322636\n",
      "Recall 0.5738805851259794\n",
      "F1 0.5888773314325042\n",
      "Epoch: 745, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.878s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51339\n",
      "Acc: 0.7036595394736842\n",
      "Prec 0.5916759006400286\n",
      "Recall 0.5587034930491344\n",
      "F1 0.5747171659263887\n",
      "468\n",
      "468\n",
      "71744\n",
      "51654\n",
      "Acc: 0.7199765834076717\n",
      "Prec 0.6036632278874785\n",
      "Recall 0.5746109681399028\n",
      "F1 0.5887789327414279\n",
      "Epoch: 746, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51600\n",
      "Acc: 0.7072368421052632\n",
      "Prec 0.596216755445257\n",
      "Recall 0.564082529699671\n",
      "F1 0.5797046675227124\n",
      "468\n",
      "468\n",
      "71744\n",
      "51680\n",
      "Acc: 0.7203389830508474\n",
      "Prec 0.6059816234716501\n",
      "Recall 0.5735621663375535\n",
      "F1 0.589326374691639\n",
      "Epoch: 747, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.872s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51297\n",
      "Acc: 0.7030838815789474\n",
      "Prec 0.590870172898363\n",
      "Recall 0.5617665766478738\n",
      "F1 0.5759509479515091\n",
      "468\n",
      "468\n",
      "71744\n",
      "51475\n",
      "Acc: 0.7174816012488849\n",
      "Prec 0.6030078471224032\n",
      "Recall 0.565623498362986\n",
      "F1 0.5837177127711582\n",
      "Epoch: 748, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51423\n",
      "Acc: 0.7048108552631579\n",
      "Prec 0.59249409384282\n",
      "Recall 0.5610047807217884\n",
      "F1 0.5763196246215816\n",
      "468\n",
      "468\n",
      "71744\n",
      "51671\n",
      "Acc: 0.7202135370205174\n",
      "Prec 0.6041247221620017\n",
      "Recall 0.5759467213508455\n",
      "F1 0.5896993015616641\n",
      "Epoch: 749, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.810s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51239\n",
      "Acc: 0.7022889254385964\n",
      "Prec 0.5894390035953353\n",
      "Recall 0.5566293115962114\n",
      "F1 0.572564518973534\n",
      "468\n",
      "468\n",
      "71744\n",
      "51557\n",
      "Acc: 0.71862455396967\n",
      "Prec 0.6038271435761906\n",
      "Recall 0.5709037398606481\n",
      "F1 0.5869040805132703\n",
      "Epoch: 750, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.845s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "51304\n",
      "Acc: 0.7031798245614035\n",
      "Prec 0.591161670430008\n",
      "Recall 0.5586351087851372\n",
      "F1 0.5744383182142784\n",
      "468\n",
      "468\n",
      "71744\n",
      "51531\n",
      "Acc: 0.7182621543264942\n",
      "Prec 0.603185825960709\n",
      "Recall 0.5718429369676654\n",
      "F1 0.5870963590627687\n",
      "Epoch: 751, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51090\n",
      "Acc: 0.7002467105263158\n",
      "Prec 0.5882696312646855\n",
      "Recall 0.5537363131176464\n",
      "F1 0.570480842657554\n",
      "468\n",
      "468\n",
      "71744\n",
      "51473\n",
      "Acc: 0.717453724353256\n",
      "Prec 0.6013530517914515\n",
      "Recall 0.5710105737563854\n",
      "F1 0.5857891590130692\n",
      "Epoch: 752, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51484\n",
      "Acc: 0.7056469298245615\n",
      "Prec 0.5938703529767023\n",
      "Recall 0.5662391235367322\n",
      "F1 0.579725681018663\n",
      "468\n",
      "468\n",
      "71744\n",
      "51554\n",
      "Acc: 0.7185827386262266\n",
      "Prec 0.603647719833424\n",
      "Recall 0.5683288720261763\n",
      "F1 0.585456109101541\n",
      "Epoch: 753, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51723\n",
      "Acc: 0.7089226973684211\n",
      "Prec 0.5979331371776848\n",
      "Recall 0.5675319380092528\n",
      "F1 0.5823360293966313\n",
      "468\n",
      "468\n",
      "71744\n",
      "51788\n",
      "Acc: 0.7218443354148082\n",
      "Prec 0.605654821506696\n",
      "Recall 0.5778389289346266\n",
      "F1 0.5914199939509915\n",
      "Epoch: 754, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51480\n",
      "Acc: 0.7055921052631579\n",
      "Prec 0.5939049326533404\n",
      "Recall 0.5618530589558485\n",
      "F1 0.5774345590734715\n",
      "468\n",
      "468\n",
      "71744\n",
      "51724\n",
      "Acc: 0.7209522747546833\n",
      "Prec 0.6065705604042203\n",
      "Recall 0.5768745969716759\n",
      "F1 0.5913500011169932\n",
      "Epoch: 755, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51542\n",
      "Acc: 0.7064418859649123\n",
      "Prec 0.5937142126198405\n",
      "Recall 0.565883574297374\n",
      "F1 0.5794649223014636\n",
      "468\n",
      "468\n",
      "71744\n",
      "51779\n",
      "Acc: 0.7217188893844781\n",
      "Prec 0.6060060468173983\n",
      "Recall 0.5766600477200967\n",
      "F1 0.5909689598619147\n",
      "Epoch: 756, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51517\n",
      "Acc: 0.7060992324561404\n",
      "Prec 0.5930307731459533\n",
      "Recall 0.5667291620507685\n",
      "F1 0.5795817271068557\n",
      "468\n",
      "468\n",
      "71744\n",
      "51672\n",
      "Acc: 0.7202274754683319\n",
      "Prec 0.6061519021249977\n",
      "Recall 0.5713431529544845\n",
      "F1 0.5882330247341501\n",
      "Epoch: 757, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51599\n",
      "Acc: 0.7072231359649123\n",
      "Prec 0.5946719609482908\n",
      "Recall 0.5681807400106761\n",
      "F1 0.5811245991114096\n",
      "468\n",
      "468\n",
      "71744\n",
      "51689\n",
      "Acc: 0.7204644290811775\n",
      "Prec 0.6061684633331449\n",
      "Recall 0.5724921237817425\n",
      "F1 0.5888491983812839\n",
      "Epoch: 758, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51548\n",
      "Acc: 0.7065241228070176\n",
      "Prec 0.5963855791387881\n",
      "Recall 0.5625291164526663\n",
      "F1 0.5789628074857384\n",
      "468\n",
      "468\n",
      "71744\n",
      "51630\n",
      "Acc: 0.7196420606601249\n",
      "Prec 0.6037656730486238\n",
      "Recall 0.5731652035472812\n",
      "F1 0.5880676287271769\n",
      "Epoch: 759, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51657\n",
      "Acc: 0.7080180921052631\n",
      "Prec 0.5965321241718526\n",
      "Recall 0.5691155356006884\n",
      "F1 0.5825014042705287\n",
      "468\n",
      "468\n",
      "71744\n",
      "51746\n",
      "Acc: 0.7212589206066012\n",
      "Prec 0.6060927147825957\n",
      "Recall 0.573192926519372\n",
      "F1 0.5891839004242567\n",
      "Epoch: 760, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.794s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51445\n",
      "Acc: 0.7051123903508771\n",
      "Prec 0.5922612962079303\n",
      "Recall 0.5635125921268395\n",
      "F1 0.5775293967289613\n",
      "468\n",
      "468\n",
      "71744\n",
      "51583\n",
      "Acc: 0.7189869536128457\n",
      "Prec 0.6043967706973993\n",
      "Recall 0.5704228307857834\n",
      "F1 0.5869185642182728\n",
      "Epoch: 761, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51432\n",
      "Acc: 0.7049342105263158\n",
      "Prec 0.593252516074109\n",
      "Recall 0.5631152343058461\n",
      "F1 0.5777911559395137\n",
      "468\n",
      "468\n",
      "71744\n",
      "51721\n",
      "Acc: 0.72091045941124\n",
      "Prec 0.605010645392334\n",
      "Recall 0.5745742129631267\n",
      "F1 0.5893997586494272\n",
      "Epoch: 762, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51379\n",
      "Acc: 0.7042077850877193\n",
      "Prec 0.5913655370412825\n",
      "Recall 0.5623448322645473\n",
      "F1 0.5764901878009558\n",
      "468\n",
      "468\n",
      "71744\n",
      "51564\n",
      "Acc: 0.7187221231043711\n",
      "Prec 0.6058108058472775\n",
      "Recall 0.5688484036876461\n",
      "F1 0.586748066240236\n",
      "Epoch: 763, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51533\n",
      "Acc: 0.7063185307017544\n",
      "Prec 0.593988652622473\n",
      "Recall 0.5640448490246122\n",
      "F1 0.5786296154891019\n",
      "468\n",
      "468\n",
      "71744\n",
      "51648\n",
      "Acc: 0.719892952720785\n",
      "Prec 0.6047793031262105\n",
      "Recall 0.5748853110889459\n",
      "F1 0.5894535338744257\n",
      "Epoch: 764, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51542\n",
      "Acc: 0.7064418859649123\n",
      "Prec 0.594779373743214\n",
      "Recall 0.5632337454140868\n",
      "F1 0.5785768897198996\n",
      "468\n",
      "468\n",
      "71744\n",
      "51762\n",
      "Acc: 0.7214819357716324\n",
      "Prec 0.6058293067706864\n",
      "Recall 0.5780159365618665\n",
      "F1 0.5915958967135304\n",
      "Epoch: 765, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51491\n",
      "Acc: 0.7057428728070175\n",
      "Prec 0.5944116690441948\n",
      "Recall 0.56282684711255\n",
      "F1 0.5781882315602754\n",
      "468\n",
      "468\n",
      "71744\n",
      "51756\n",
      "Acc: 0.7213983050847458\n",
      "Prec 0.6055149238528155\n",
      "Recall 0.5787478704682928\n",
      "F1 0.5918288987833672\n",
      "Epoch: 766, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51542\n",
      "Acc: 0.7064418859649123\n",
      "Prec 0.5946275637180215\n",
      "Recall 0.5652500811048234\n",
      "F1 0.5795667846846239\n",
      "468\n",
      "468\n",
      "71744\n",
      "51715\n",
      "Acc: 0.7208268287243532\n",
      "Prec 0.6058294819682646\n",
      "Recall 0.5732727832518684\n",
      "F1 0.58910166411926\n",
      "Epoch: 767, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51584\n",
      "Acc: 0.7070175438596491\n",
      "Prec 0.594960241523986\n",
      "Recall 0.5649508766793834\n",
      "F1 0.5795673560901593\n",
      "468\n",
      "468\n",
      "71744\n",
      "51800\n",
      "Acc: 0.7220115967885816\n",
      "Prec 0.6068636017551442\n",
      "Recall 0.5767404872717155\n",
      "F1 0.5914187229134986\n",
      "Epoch: 768, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51697\n",
      "Acc: 0.7085663377192982\n",
      "Prec 0.596495597977552\n",
      "Recall 0.5672233125982732\n",
      "F1 0.5814912964982174\n",
      "468\n",
      "468\n",
      "71744\n",
      "51730\n",
      "Acc: 0.72103590544157\n",
      "Prec 0.6063377901696844\n",
      "Recall 0.5735180260811925\n",
      "F1 0.589471438402618\n",
      "Epoch: 769, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51527\n",
      "Acc: 0.7062362938596491\n",
      "Prec 0.5937653391882375\n",
      "Recall 0.564063348291736\n",
      "F1 0.5785333684399464\n",
      "468\n",
      "468\n",
      "71744\n",
      "51842\n",
      "Acc: 0.7225970115967886\n",
      "Prec 0.6064116903369032\n",
      "Recall 0.5807987849306996\n",
      "F1 0.5933289509361123\n",
      "Epoch: 770, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.882s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51639\n",
      "Acc: 0.7077713815789474\n",
      "Prec 0.5973803750126153\n",
      "Recall 0.5678761016422015\n",
      "F1 0.5822547144875688\n",
      "468\n",
      "468\n",
      "71744\n",
      "51607\n",
      "Acc: 0.7193214763603925\n",
      "Prec 0.6052476382312726\n",
      "Recall 0.569423333051546\n",
      "F1 0.5867892131646968\n",
      "Epoch: 771, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51532\n",
      "Acc: 0.7063048245614035\n",
      "Prec 0.5950195517502571\n",
      "Recall 0.5655111594686751\n",
      "F1 0.5798902060306458\n",
      "468\n",
      "468\n",
      "71744\n",
      "51821\n",
      "Acc: 0.7223043041926851\n",
      "Prec 0.6080921299605965\n",
      "Recall 0.5741488991190753\n",
      "F1 0.5906332438007812\n",
      "Epoch: 772, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51639\n",
      "Acc: 0.7077713815789474\n",
      "Prec 0.5960130000436883\n",
      "Recall 0.5659806055694939\n",
      "F1 0.5806087005341274\n",
      "468\n",
      "468\n",
      "71744\n",
      "51769\n",
      "Acc: 0.7215795049063336\n",
      "Prec 0.6081527618495554\n",
      "Recall 0.5760397132393204\n",
      "F1 0.5916608151309632\n",
      "Epoch: 773, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51796\n",
      "Acc: 0.7099232456140351\n",
      "Prec 0.5983602954866917\n",
      "Recall 0.5696988234007994\n",
      "F1 0.5836779162910801\n",
      "468\n",
      "468\n",
      "71744\n",
      "51788\n",
      "Acc: 0.7218443354148082\n",
      "Prec 0.6079091573019523\n",
      "Recall 0.5748424750752764\n",
      "F1 0.59091358665388\n",
      "Epoch: 774, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51573\n",
      "Acc: 0.7068667763157894\n",
      "Prec 0.5948736180780096\n",
      "Recall 0.5659045552356772\n",
      "F1 0.5800276021711525\n",
      "468\n",
      "468\n",
      "71744\n",
      "51840\n",
      "Acc: 0.7225691347011597\n",
      "Prec 0.6083438432524427\n",
      "Recall 0.5768918768177872\n",
      "F1 0.5922005480287961\n",
      "Epoch: 775, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.823s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51533\n",
      "Acc: 0.7063185307017544\n",
      "Prec 0.5953843230205914\n",
      "Recall 0.5626439396369529\n",
      "F1 0.5785513046695817\n",
      "468\n",
      "468\n",
      "71744\n",
      "51774\n",
      "Acc: 0.7216491971454059\n",
      "Prec 0.6070037425463061\n",
      "Recall 0.5765839469414731\n",
      "F1 0.5914029299122896\n",
      "Epoch: 776, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51585\n",
      "Acc: 0.70703125\n",
      "Prec 0.5948656268790489\n",
      "Recall 0.5656780731303593\n",
      "F1 0.5799048180291628\n",
      "468\n",
      "468\n",
      "71744\n",
      "51722\n",
      "Acc: 0.7209243978590544\n",
      "Prec 0.6073587364627555\n",
      "Recall 0.572196762526955\n",
      "F1 0.5892536688508665\n",
      "Epoch: 777, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51594\n",
      "Acc: 0.7071546052631579\n",
      "Prec 0.5953093103457601\n",
      "Recall 0.5670807457018748\n",
      "F1 0.5808522636231295\n",
      "468\n",
      "468\n",
      "71744\n",
      "51687\n",
      "Acc: 0.7204365521855486\n",
      "Prec 0.607032993927862\n",
      "Recall 0.5712129452744191\n",
      "F1 0.5885784840048636\n",
      "Epoch: 778, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.847s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "51495\n",
      "Acc: 0.705797697368421\n",
      "Prec 0.5949683646746943\n",
      "Recall 0.5599906328456801\n",
      "F1 0.5769498515058131\n",
      "468\n",
      "468\n",
      "71744\n",
      "51653\n",
      "Acc: 0.7199626449598573\n",
      "Prec 0.605672378448317\n",
      "Recall 0.5723930012959114\n",
      "F1 0.5885626323682206\n",
      "Epoch: 779, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51556\n",
      "Acc: 0.7066337719298246\n",
      "Prec 0.5949367205163497\n",
      "Recall 0.5656445035079193\n",
      "F1 0.5799209549991192\n",
      "468\n",
      "468\n",
      "71744\n",
      "51702\n",
      "Acc: 0.7206456289027654\n",
      "Prec 0.6045087375712928\n",
      "Recall 0.5805223552292511\n",
      "F1 0.5922727905175976\n",
      "Epoch: 780, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.876s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51541\n",
      "Acc: 0.7064281798245614\n",
      "Prec 0.5953741752518821\n",
      "Recall 0.5653598809102601\n",
      "F1 0.5799789728413531\n",
      "468\n",
      "468\n",
      "71744\n",
      "51880\n",
      "Acc: 0.7231266726137378\n",
      "Prec 0.608906170185567\n",
      "Recall 0.5776536780901148\n",
      "F1 0.592868348496041\n",
      "Epoch: 781, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.896s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51547\n",
      "Acc: 0.7065104166666667\n",
      "Prec 0.5955884812975099\n",
      "Recall 0.5642356747530197\n",
      "F1 0.5794883075454519\n",
      "468\n",
      "468\n",
      "71744\n",
      "51717\n",
      "Acc: 0.7208547056199821\n",
      "Prec 0.607036981561489\n",
      "Recall 0.5729798721530698\n",
      "F1 0.5895169564610703\n",
      "Epoch: 782, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51605\n",
      "Acc: 0.7073053728070176\n",
      "Prec 0.594948162993119\n",
      "Recall 0.5661948686011856\n",
      "F1 0.5802155080031539\n",
      "468\n",
      "468\n",
      "71744\n",
      "51821\n",
      "Acc: 0.7223043041926851\n",
      "Prec 0.6069225181949633\n",
      "Recall 0.5766434717243282\n",
      "F1 0.5913956821004644\n",
      "Epoch: 783, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51670\n",
      "Acc: 0.7081962719298246\n",
      "Prec 0.5957092212535674\n",
      "Recall 0.5661199207646676\n",
      "F1 0.58053778294633\n",
      "468\n",
      "468\n",
      "71744\n",
      "51998\n",
      "Acc: 0.724771409455843\n",
      "Prec 0.6099188743917945\n",
      "Recall 0.5818037860915194\n",
      "F1 0.5955296850458647\n",
      "Epoch: 784, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51718\n",
      "Acc: 0.7088541666666667\n",
      "Prec 0.5963504267000531\n",
      "Recall 0.5677497658504486\n",
      "F1 0.5816987528916362\n",
      "468\n",
      "468\n",
      "71744\n",
      "51794\n",
      "Acc: 0.721927966101695\n",
      "Prec 0.6072716213778945\n",
      "Recall 0.5742865032781509\n",
      "F1 0.5903186456996106\n",
      "Epoch: 785, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.884s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51694\n",
      "Acc: 0.7085252192982456\n",
      "Prec 0.5977211658586512\n",
      "Recall 0.5682531692515239\n",
      "F1 0.5826147910807994\n",
      "468\n",
      "468\n",
      "71744\n",
      "51936\n",
      "Acc: 0.723907225691347\n",
      "Prec 0.6103252576377651\n",
      "Recall 0.578263059410014\n",
      "F1 0.5938617192425794\n",
      "Epoch: 786, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51543\n",
      "Acc: 0.7064555921052632\n",
      "Prec 0.5944365764674694\n",
      "Recall 0.5657889394457957\n",
      "F1 0.5797590822721775\n",
      "468\n",
      "468\n",
      "71744\n",
      "51736\n",
      "Acc: 0.7211195361284567\n",
      "Prec 0.6081726369212875\n",
      "Recall 0.5712685305090502\n",
      "F1 0.58914322847792\n",
      "Epoch: 787, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.879s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51511\n",
      "Acc: 0.7060169956140351\n",
      "Prec 0.5944087140234833\n",
      "Recall 0.5610937768846909\n",
      "F1 0.5772709846821309\n",
      "468\n",
      "468\n",
      "71744\n",
      "51745\n",
      "Acc: 0.7212449821587869\n",
      "Prec 0.6068770379283112\n",
      "Recall 0.5747504602717065\n",
      "F1 0.5903770137525758\n",
      "Epoch: 788, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51503\n",
      "Acc: 0.7059073464912281\n",
      "Prec 0.5929059523713117\n",
      "Recall 0.5673443695264239\n",
      "F1 0.5798435861433261\n",
      "468\n",
      "468\n",
      "71744\n",
      "51707\n",
      "Acc: 0.7207153211418377\n",
      "Prec 0.6074515480209427\n",
      "Recall 0.5702320896889749\n",
      "F1 0.588253677849103\n",
      "Epoch: 789, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51448\n",
      "Acc: 0.7051535087719298\n",
      "Prec 0.5949436533563238\n",
      "Recall 0.56078800561963\n",
      "F1 0.5773611239781588\n",
      "468\n",
      "468\n",
      "71744\n",
      "51859\n",
      "Acc: 0.7228339652096343\n",
      "Prec 0.6085740385066274\n",
      "Recall 0.5759618135933452\n",
      "F1 0.5918189918907081\n",
      "Epoch: 790, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51575\n",
      "Acc: 0.7068941885964912\n",
      "Prec 0.5945753614344517\n",
      "Recall 0.5647237718917669\n",
      "F1 0.5792652321231239\n",
      "468\n",
      "468\n",
      "71744\n",
      "51951\n",
      "Acc: 0.7241163024085637\n",
      "Prec 0.6100760422030372\n",
      "Recall 0.5801154042775788\n",
      "F1 0.5947186243174605\n",
      "Epoch: 791, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51575\n",
      "Acc: 0.7068941885964912\n",
      "Prec 0.5977231269011193\n",
      "Recall 0.5646375733656861\n",
      "F1 0.5807094748480912\n",
      "468\n",
      "468\n",
      "71744\n",
      "51774\n",
      "Acc: 0.7216491971454059\n",
      "Prec 0.6084963500013979\n",
      "Recall 0.572835541246037\n",
      "F1 0.5901277000677867\n",
      "Epoch: 792, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51373\n",
      "Acc: 0.704125548245614\n",
      "Prec 0.5933026131333752\n",
      "Recall 0.5590881314665694\n",
      "F1 0.5756874583128053\n",
      "468\n",
      "468\n",
      "71744\n",
      "51794\n",
      "Acc: 0.721927966101695\n",
      "Prec 0.6062749814166687\n",
      "Recall 0.5780657363487395\n",
      "F1 0.5918344076250271\n",
      "Epoch: 793, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.888s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51493\n",
      "Acc: 0.7057702850877193\n",
      "Prec 0.5938859788672443\n",
      "Recall 0.5637818076976376\n",
      "F1 0.5784424765339029\n",
      "468\n",
      "468\n",
      "71744\n",
      "51773\n",
      "Acc: 0.7216352586975915\n",
      "Prec 0.60767012109175\n",
      "Recall 0.5736024692941153\n",
      "F1 0.5901450432547894\n",
      "Epoch: 794, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51554\n",
      "Acc: 0.7066063596491228\n",
      "Prec 0.5959712418334571\n",
      "Recall 0.5645101914521513\n",
      "F1 0.5798142567001007\n",
      "468\n",
      "468\n",
      "71744\n",
      "51859\n",
      "Acc: 0.7228339652096343\n",
      "Prec 0.6078206812155561\n",
      "Recall 0.5788921155210146\n",
      "F1 0.5930038017183441\n",
      "Epoch: 795, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51536\n",
      "Acc: 0.706359649122807\n",
      "Prec 0.5937101947920226\n",
      "Recall 0.5678872317638588\n",
      "F1 0.5805116837940983\n",
      "468\n",
      "468\n",
      "71744\n",
      "51691\n",
      "Acc: 0.7204923059768065\n",
      "Prec 0.6076380947772347\n",
      "Recall 0.5699431282865319\n",
      "F1 0.5881872941254465\n",
      "Epoch: 796, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51558\n",
      "Acc: 0.7066611842105263\n",
      "Prec 0.5967718204236555\n",
      "Recall 0.5634401644032921\n",
      "F1 0.5796272009048576\n",
      "468\n",
      "468\n",
      "71744\n",
      "51815\n",
      "Acc: 0.7222206735057984\n",
      "Prec 0.6070694633344796\n",
      "Recall 0.5771800918773268\n",
      "F1 0.5917475874595477\n",
      "Epoch: 797, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51605\n",
      "Acc: 0.7073053728070176\n",
      "Prec 0.5970112718942922\n",
      "Recall 0.5663642479757551\n",
      "F1 0.5812840897275019\n",
      "468\n",
      "468\n",
      "71744\n",
      "51979\n",
      "Acc: 0.7245065789473685\n",
      "Prec 0.6104568803717558\n",
      "Recall 0.5806243094071477\n",
      "F1 0.5951669921921732\n",
      "Epoch: 798, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51665\n",
      "Acc: 0.7081277412280702\n",
      "Prec 0.5958440364183971\n",
      "Recall 0.5655678763981201\n",
      "F1 0.5803113307567314\n",
      "468\n",
      "468\n",
      "71744\n",
      "51865\n",
      "Acc: 0.7229175958965209\n",
      "Prec 0.6078474512643947\n",
      "Recall 0.5790803757090787\n",
      "F1 0.5931153056703223\n",
      "Epoch: 799, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51567\n",
      "Acc: 0.7067845394736842\n",
      "Prec 0.5949266408852475\n",
      "Recall 0.5675421417228983\n",
      "F1 0.5809118403652467\n",
      "468\n",
      "468\n",
      "71744\n",
      "51766\n",
      "Acc: 0.7215376895628903\n",
      "Prec 0.6070499332146796\n",
      "Recall 0.5724948650433942\n",
      "F1 0.5892662493252798\n",
      "Epoch: 800, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.892s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51649\n",
      "Acc: 0.7079084429824561\n",
      "Prec 0.5957695733095946\n",
      "Recall 0.5664237016582612\n",
      "F1 0.5807261396495635\n",
      "468\n",
      "468\n",
      "71744\n",
      "52009\n",
      "Acc: 0.724924732381802\n",
      "Prec 0.6109653695881071\n",
      "Recall 0.5807477614820722\n",
      "F1 0.5954734599806388\n",
      "Epoch: 801, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51763\n",
      "Acc: 0.7094709429824562\n",
      "Prec 0.5983194568021346\n",
      "Recall 0.5683591954311038\n",
      "F1 0.5829546369566255\n",
      "468\n",
      "468\n",
      "71744\n",
      "51951\n",
      "Acc: 0.7241163024085637\n",
      "Prec 0.6103490389448784\n",
      "Recall 0.579797902058448\n",
      "F1 0.5946813458265929\n",
      "Epoch: 802, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51529\n",
      "Acc: 0.7062637061403508\n",
      "Prec 0.5949545162268736\n",
      "Recall 0.5663219957920513\n",
      "F1 0.5802852732280295\n",
      "468\n",
      "468\n",
      "71744\n",
      "51846\n",
      "Acc: 0.7226527653880463\n",
      "Prec 0.6088790300160855\n",
      "Recall 0.5753065406012822\n",
      "F1 0.5916168835271245\n",
      "Epoch: 803, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51656\n",
      "Acc: 0.7080043859649123\n",
      "Prec 0.5977208298880586\n",
      "Recall 0.566755138825997\n",
      "F1 0.581826265245293\n",
      "468\n",
      "468\n",
      "71744\n",
      "51980\n",
      "Acc: 0.7245205173951829\n",
      "Prec 0.6107716338886685\n",
      "Recall 0.5794126368763841\n",
      "F1 0.5946790116680849\n",
      "Epoch: 804, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51719\n",
      "Acc: 0.7088678728070176\n",
      "Prec 0.5978303881946933\n",
      "Recall 0.5681100709558752\n",
      "F1 0.582591437824023\n",
      "468\n",
      "468\n",
      "71744\n",
      "51917\n",
      "Acc: 0.7236423951828724\n",
      "Prec 0.609513023180489\n",
      "Recall 0.5775205995554759\n",
      "F1 0.5930856882937079\n",
      "Epoch: 805, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.879s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51672\n",
      "Acc: 0.7082236842105263\n",
      "Prec 0.5966704507147425\n",
      "Recall 0.5657611559449641\n",
      "F1 0.5808048610870187\n",
      "468\n",
      "468\n",
      "71744\n",
      "51900\n",
      "Acc: 0.7234054415700267\n",
      "Prec 0.6104037720595822\n",
      "Recall 0.5777132699027604\n",
      "F1 0.5936087888026395\n",
      "Epoch: 806, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.849s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "51709\n",
      "Acc: 0.7087308114035088\n",
      "Prec 0.5971743653621558\n",
      "Recall 0.5674278724718839\n",
      "F1 0.581921223614347\n",
      "468\n",
      "468\n",
      "71744\n",
      "51995\n",
      "Acc: 0.7247295941123997\n",
      "Prec 0.6111909688505398\n",
      "Recall 0.5804312093862348\n",
      "F1 0.5954140829113939\n",
      "Epoch: 807, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.846s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51672\n",
      "Acc: 0.7082236842105263\n",
      "Prec 0.5971975114951953\n",
      "Recall 0.5667092784246229\n",
      "F1 0.581554079325781\n",
      "468\n",
      "468\n",
      "71744\n",
      "51887\n",
      "Acc: 0.7232242417484389\n",
      "Prec 0.6098070915508594\n",
      "Recall 0.5763781767670684\n",
      "F1 0.5926215895534249\n",
      "Epoch: 808, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51699\n",
      "Acc: 0.70859375\n",
      "Prec 0.5968448810115176\n",
      "Recall 0.5703696985090705\n",
      "F1 0.5833070299362496\n",
      "468\n",
      "468\n",
      "71744\n",
      "51722\n",
      "Acc: 0.7209243978590544\n",
      "Prec 0.6092132562543803\n",
      "Recall 0.5699709566911755\n",
      "F1 0.5889391304330286\n",
      "Epoch: 809, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.839s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51472\n",
      "Acc: 0.7054824561403509\n",
      "Prec 0.5948380705364531\n",
      "Recall 0.5614769042092081\n",
      "F1 0.5776762312086272\n",
      "468\n",
      "468\n",
      "71744\n",
      "51797\n",
      "Acc: 0.7219697814451382\n",
      "Prec 0.6076910963906325\n",
      "Recall 0.5792244851895325\n",
      "F1 0.593116423650814\n",
      "Epoch: 810, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51117\n",
      "Acc: 0.7006167763157894\n",
      "Prec 0.589664934459552\n",
      "Recall 0.5566020983876868\n",
      "F1 0.572656685502992\n",
      "468\n",
      "468\n",
      "71744\n",
      "51846\n",
      "Acc: 0.7226527653880463\n",
      "Prec 0.6085468010741198\n",
      "Recall 0.5762194830314908\n",
      "F1 0.5919421033830485\n",
      "Epoch: 811, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51498\n",
      "Acc: 0.7058388157894737\n",
      "Prec 0.5946443254973457\n",
      "Recall 0.5624641483172306\n",
      "F1 0.5781067577699477\n",
      "468\n",
      "468\n",
      "71744\n",
      "51811\n",
      "Acc: 0.7221649197145406\n",
      "Prec 0.607339548261217\n",
      "Recall 0.575003256171056\n",
      "F1 0.5907292141374252\n",
      "Epoch: 812, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51514\n",
      "Acc: 0.7060581140350877\n",
      "Prec 0.5963476819387697\n",
      "Recall 0.5610150382575401\n",
      "F1 0.5781420323283383\n",
      "468\n",
      "468\n",
      "71744\n",
      "51894\n",
      "Acc: 0.7233218108831401\n",
      "Prec 0.6083004252024344\n",
      "Recall 0.5800018381096049\n",
      "F1 0.5938141761287203\n",
      "Epoch: 813, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51674\n",
      "Acc: 0.7082510964912281\n",
      "Prec 0.5972362704910852\n",
      "Recall 0.5684742974793038\n",
      "F1 0.5825004570177378\n",
      "468\n",
      "468\n",
      "71744\n",
      "52026\n",
      "Acc: 0.7251616859946476\n",
      "Prec 0.6107871544582932\n",
      "Recall 0.5820719557257342\n",
      "F1 0.5960839306040877\n",
      "Epoch: 814, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.839s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51564\n",
      "Acc: 0.7067434210526315\n",
      "Prec 0.5958179448849655\n",
      "Recall 0.5653024149606244\n",
      "F1 0.5801591889494357\n",
      "468\n",
      "468\n",
      "71744\n",
      "51616\n",
      "Acc: 0.7194469223907226\n",
      "Prec 0.6067264237359011\n",
      "Recall 0.5667336463052508\n",
      "F1 0.5860485366520113\n",
      "Epoch: 815, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51499\n",
      "Acc: 0.7058525219298246\n",
      "Prec 0.5963009869944728\n",
      "Recall 0.5617728586763565\n",
      "F1 0.5785221924278464\n",
      "468\n",
      "468\n",
      "71744\n",
      "51822\n",
      "Acc: 0.7223182426404996\n",
      "Prec 0.6084460980324986\n",
      "Recall 0.5778385220963305\n",
      "F1 0.5927474538516675\n",
      "Epoch: 816, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51619\n",
      "Acc: 0.7074972587719298\n",
      "Prec 0.5961706454078625\n",
      "Recall 0.5665761854886014\n",
      "F1 0.5809967934551032\n",
      "468\n",
      "468\n",
      "71744\n",
      "51905\n",
      "Acc: 0.723475133809099\n",
      "Prec 0.6083975505980578\n",
      "Recall 0.576131457573089\n",
      "F1 0.5918250463973639\n",
      "Epoch: 817, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51597\n",
      "Acc: 0.7071957236842106\n",
      "Prec 0.5961419114526948\n",
      "Recall 0.5665308009650963\n",
      "F1 0.5809592862669661\n",
      "468\n",
      "468\n",
      "71744\n",
      "51986\n",
      "Acc: 0.7246041480820696\n",
      "Prec 0.6111928824319188\n",
      "Recall 0.5816595192610855\n",
      "F1 0.5960605983885021\n",
      "Epoch: 818, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51511\n",
      "Acc: 0.7060169956140351\n",
      "Prec 0.5939768459932995\n",
      "Recall 0.5663213934911043\n",
      "F1 0.5798195389382867\n",
      "468\n",
      "468\n",
      "71744\n",
      "51739\n",
      "Acc: 0.7211613514719001\n",
      "Prec 0.6085428850129354\n",
      "Recall 0.5693379141881988\n",
      "F1 0.5882879440471652\n",
      "Epoch: 819, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51565\n",
      "Acc: 0.7067571271929824\n",
      "Prec 0.5960578265091114\n",
      "Recall 0.5653944332241767\n",
      "F1 0.5803213591669157\n",
      "468\n",
      "468\n",
      "71744\n",
      "51959\n",
      "Acc: 0.7242278099910794\n",
      "Prec 0.6105318716986353\n",
      "Recall 0.5786013528268382\n",
      "F1 0.5941379142773495\n",
      "Epoch: 820, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51517\n",
      "Acc: 0.7060992324561404\n",
      "Prec 0.5942624190474278\n",
      "Recall 0.5657763590297953\n",
      "F1 0.5796696353792239\n",
      "468\n",
      "468\n",
      "71744\n",
      "51810\n",
      "Acc: 0.7221509812667262\n",
      "Prec 0.6089550963185907\n",
      "Recall 0.5725558006745813\n",
      "F1 0.5901947644069379\n",
      "Epoch: 821, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51561\n",
      "Acc: 0.706702302631579\n",
      "Prec 0.5954176620195625\n",
      "Recall 0.5653300148592497\n",
      "F1 0.5799838886985297\n",
      "468\n",
      "468\n",
      "71744\n",
      "52001\n",
      "Acc: 0.7248132247992863\n",
      "Prec 0.6100156975779435\n",
      "Recall 0.5811545165282725\n",
      "F1 0.5952354644236512\n",
      "Epoch: 822, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.892s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51621\n",
      "Acc: 0.7075246710526316\n",
      "Prec 0.5972932158807125\n",
      "Recall 0.5670018961655415\n",
      "F1 0.58175351329264\n",
      "468\n",
      "468\n",
      "71744\n",
      "52002\n",
      "Acc: 0.7248271632471008\n",
      "Prec 0.61247213822791\n",
      "Recall 0.5796512480120172\n",
      "F1 0.595609889704731\n",
      "Epoch: 823, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51760\n",
      "Acc: 0.7094298245614035\n",
      "Prec 0.5972920865084294\n",
      "Recall 0.5691152643348804\n",
      "F1 0.5828633426437339\n",
      "468\n",
      "468\n",
      "71744\n",
      "51920\n",
      "Acc: 0.7236842105263158\n",
      "Prec 0.6095448405622451\n",
      "Recall 0.5778629587044065\n",
      "F1 0.5932812387586567\n",
      "Epoch: 824, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51725\n",
      "Acc: 0.7089501096491229\n",
      "Prec 0.5978751872836635\n",
      "Recall 0.5667053370696679\n",
      "F1 0.5818731336303582\n",
      "468\n",
      "468\n",
      "71744\n",
      "51878\n",
      "Acc: 0.7230987957181089\n",
      "Prec 0.6098948020556069\n",
      "Recall 0.5772769494669373\n",
      "F1 0.5931377837703147\n",
      "Epoch: 825, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51783\n",
      "Acc: 0.7097450657894737\n",
      "Prec 0.5991452888014178\n",
      "Recall 0.5696445304269543\n",
      "F1 0.5840226036912772\n",
      "468\n",
      "468\n",
      "71744\n",
      "51980\n",
      "Acc: 0.7245205173951829\n",
      "Prec 0.6104452587713632\n",
      "Recall 0.5796049230322743\n",
      "F1 0.5946254748507299\n",
      "Epoch: 826, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51826\n",
      "Acc: 0.7103344298245614\n",
      "Prec 0.5998807918746655\n",
      "Recall 0.5703337663512421\n",
      "F1 0.5847342591777868\n",
      "468\n",
      "468\n",
      "71744\n",
      "51934\n",
      "Acc: 0.7238793487957181\n",
      "Prec 0.6098234363943494\n",
      "Recall 0.577840482476423\n",
      "F1 0.5934013202094809\n",
      "Epoch: 827, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51771\n",
      "Acc: 0.7095805921052631\n",
      "Prec 0.5979690346704846\n",
      "Recall 0.5709759705357783\n",
      "F1 0.5841608431545966\n",
      "468\n",
      "468\n",
      "71744\n",
      "51897\n",
      "Acc: 0.7233636262265835\n",
      "Prec 0.6118717701291012\n",
      "Recall 0.5755156576917931\n",
      "F1 0.5931371277109537\n",
      "Epoch: 828, Train loss: 0.001, Val loss: 0.001, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51907\n",
      "Acc: 0.7114446271929824\n",
      "Prec 0.6000741228977464\n",
      "Recall 0.5707181006906175\n",
      "F1 0.5850280806343985\n",
      "468\n",
      "468\n",
      "71744\n",
      "51949\n",
      "Acc: 0.7240884255129348\n",
      "Prec 0.6101271887922388\n",
      "Recall 0.5794618457017995\n",
      "F1 0.5943992701324329\n",
      "Epoch: 829, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51770\n",
      "Acc: 0.7095668859649122\n",
      "Prec 0.5990198228545444\n",
      "Recall 0.5709395621892623\n",
      "F1 0.584642714568177\n",
      "468\n",
      "468\n",
      "71744\n",
      "51935\n",
      "Acc: 0.7238932872435325\n",
      "Prec 0.6104856017054122\n",
      "Recall 0.5792481148236271\n",
      "F1 0.594456774657939\n",
      "Epoch: 830, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.808s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51799\n",
      "Acc: 0.7099643640350877\n",
      "Prec 0.5984154972004491\n",
      "Recall 0.570336477982209\n",
      "F1 0.5840386913398574\n",
      "468\n",
      "468\n",
      "71744\n",
      "52017\n",
      "Acc: 0.7250362399643175\n",
      "Prec 0.6120175492484463\n",
      "Recall 0.5792922981743213\n",
      "F1 0.5952054428058993\n",
      "Epoch: 831, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51775\n",
      "Acc: 0.7096354166666666\n",
      "Prec 0.5985034199339432\n",
      "Recall 0.5680653305757886\n",
      "F1 0.5828872802343751\n",
      "468\n",
      "468\n",
      "71744\n",
      "52079\n",
      "Acc: 0.7259004237288136\n",
      "Prec 0.6120484702786607\n",
      "Recall 0.5858325791386642\n",
      "F1 0.5986536544269268\n",
      "Epoch: 832, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51847\n",
      "Acc: 0.7106222587719299\n",
      "Prec 0.5998820293814263\n",
      "Recall 0.5725338155417865\n",
      "F1 0.5858889550903204\n",
      "468\n",
      "468\n",
      "71744\n",
      "51948\n",
      "Acc: 0.7240744870651205\n",
      "Prec 0.6100905936222699\n",
      "Recall 0.5793400312793594\n",
      "F1 0.5943178125611159\n",
      "Epoch: 833, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51784\n",
      "Acc: 0.7097587719298246\n",
      "Prec 0.5991242417253998\n",
      "Recall 0.568182058026769\n",
      "F1 0.5832430524011358\n",
      "468\n",
      "468\n",
      "71744\n",
      "52023\n",
      "Acc: 0.7251198706512043\n",
      "Prec 0.6115597865952015\n",
      "Recall 0.5803722295902749\n",
      "F1 0.5955579882985185\n",
      "Epoch: 834, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.818s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "51930\n",
      "Acc: 0.7117598684210527\n",
      "Prec 0.6016951599252844\n",
      "Recall 0.5739219804037933\n",
      "F1 0.5874805086408199\n",
      "468\n",
      "468\n",
      "71744\n",
      "51966\n",
      "Acc: 0.7243253791257805\n",
      "Prec 0.6110640186140835\n",
      "Recall 0.5770396942665114\n",
      "F1 0.5935646705849053\n",
      "Epoch: 835, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.844s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51933\n",
      "Acc: 0.7118009868421052\n",
      "Prec 0.6004556715139074\n",
      "Recall 0.573174523696035\n",
      "F1 0.5864980211402985\n",
      "468\n",
      "468\n",
      "71744\n",
      "52000\n",
      "Acc: 0.724799286351472\n",
      "Prec 0.6105272932724207\n",
      "Recall 0.5784384997446126\n",
      "F1 0.5940498770406236\n",
      "Epoch: 836, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.726s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51713\n",
      "Acc: 0.7087856359649123\n",
      "Prec 0.5979661254138314\n",
      "Recall 0.5717771922603391\n",
      "F1 0.5845784918621793\n",
      "468\n",
      "468\n",
      "71744\n",
      "51854\n",
      "Acc: 0.722764272970562\n",
      "Prec 0.6099616801488723\n",
      "Recall 0.5726980886407822\n",
      "F1 0.5907428282994369\n",
      "Epoch: 837, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51574\n",
      "Acc: 0.7068804824561403\n",
      "Prec 0.5959753330703185\n",
      "Recall 0.5646719398900647\n",
      "F1 0.5799015002948809\n",
      "468\n",
      "468\n",
      "71744\n",
      "51967\n",
      "Acc: 0.724339317573595\n",
      "Prec 0.6112576471359095\n",
      "Recall 0.577414458608228\n",
      "F1 0.5938542709726765\n",
      "Epoch: 838, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51942\n",
      "Acc: 0.7119243421052631\n",
      "Prec 0.6028012148675416\n",
      "Recall 0.5727352506737012\n",
      "F1 0.5873837435482947\n",
      "468\n",
      "468\n",
      "71744\n",
      "52067\n",
      "Acc: 0.7257331623550402\n",
      "Prec 0.6118900038455591\n",
      "Recall 0.5815719782739687\n",
      "F1 0.5963459001694251\n",
      "Epoch: 839, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51548\n",
      "Acc: 0.7065241228070176\n",
      "Prec 0.595133855593726\n",
      "Recall 0.5680292323881371\n",
      "F1 0.5812657410709852\n",
      "468\n",
      "468\n",
      "71744\n",
      "51767\n",
      "Acc: 0.7215516280107047\n",
      "Prec 0.6088947524434536\n",
      "Recall 0.5700097866921215\n",
      "F1 0.5888109790683079\n",
      "Epoch: 840, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.896s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51782\n",
      "Acc: 0.7097313596491228\n",
      "Prec 0.600462887353224\n",
      "Recall 0.5685888724177306\n",
      "F1 0.5840913598483546\n",
      "468\n",
      "468\n",
      "71744\n",
      "52040\n",
      "Acc: 0.7253568242640499\n",
      "Prec 0.6126984486797947\n",
      "Recall 0.579005783178448\n",
      "F1 0.5953758250516376\n",
      "Epoch: 841, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51643\n",
      "Acc: 0.7078262061403509\n",
      "Prec 0.5964300788039126\n",
      "Recall 0.5681275696967152\n",
      "F1 0.5819349030958764\n",
      "468\n",
      "468\n",
      "71744\n",
      "51946\n",
      "Acc: 0.7240466101694916\n",
      "Prec 0.6116121513265959\n",
      "Recall 0.5753202775893339\n",
      "F1 0.5929113808097831\n",
      "Epoch: 842, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51648\n",
      "Acc: 0.7078947368421052\n",
      "Prec 0.5982971629846061\n",
      "Recall 0.5669095445390722\n",
      "F1 0.5821806036243222\n",
      "468\n",
      "468\n",
      "71744\n",
      "52053\n",
      "Acc: 0.7255380240856378\n",
      "Prec 0.6126741819649361\n",
      "Recall 0.5800596246144619\n",
      "F1 0.5959209909891925\n",
      "Epoch: 843, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.867s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51590\n",
      "Acc: 0.7070997807017544\n",
      "Prec 0.5977626468812618\n",
      "Recall 0.5639065971228627\n",
      "F1 0.5803412663799007\n",
      "468\n",
      "468\n",
      "71744\n",
      "51966\n",
      "Acc: 0.7243253791257805\n",
      "Prec 0.611422507349726\n",
      "Recall 0.5782087364595673\n",
      "F1 0.5943519679015744\n",
      "Epoch: 844, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51533\n",
      "Acc: 0.7063185307017544\n",
      "Prec 0.5948040426189274\n",
      "Recall 0.56531892770136\n",
      "F1 0.5796867955694953\n",
      "468\n",
      "468\n",
      "71744\n",
      "51944\n",
      "Acc: 0.7240187332738626\n",
      "Prec 0.6100081008925035\n",
      "Recall 0.5798557063666865\n",
      "F1 0.594549857007917\n",
      "Epoch: 845, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.885s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51789\n",
      "Acc: 0.7098273026315789\n",
      "Prec 0.6000818184825811\n",
      "Recall 0.5684147925648938\n",
      "F1 0.5838192069191755\n",
      "468\n",
      "468\n",
      "71744\n",
      "52100\n",
      "Acc: 0.7261931311329171\n",
      "Prec 0.6133548082841286\n",
      "Recall 0.5831730261382727\n",
      "F1 0.5978832574608407\n",
      "Epoch: 846, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.860s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51789\n",
      "Acc: 0.7098273026315789\n",
      "Prec 0.5978915145300655\n",
      "Recall 0.5693263574737768\n",
      "F1 0.5832594004879346\n",
      "468\n",
      "468\n",
      "71744\n",
      "52150\n",
      "Acc: 0.7268900535236396\n",
      "Prec 0.6147429832595386\n",
      "Recall 0.5841352650230681\n",
      "F1 0.5990484120665013\n",
      "Epoch: 847, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.814s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52010\n",
      "Acc: 0.7128563596491229\n",
      "Prec 0.6037098896016532\n",
      "Recall 0.5737018522578986\n",
      "F1 0.5883234718618839\n",
      "468\n",
      "468\n",
      "71744\n",
      "52120\n",
      "Acc: 0.726471900089206\n",
      "Prec 0.6127018571163919\n",
      "Recall 0.5844849164332692\n",
      "F1 0.5982608589858899\n",
      "Epoch: 848, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51931\n",
      "Acc: 0.7117735745614036\n",
      "Prec 0.6007103848596701\n",
      "Recall 0.5738472625270629\n",
      "F1 0.5869716325805837\n",
      "468\n",
      "468\n",
      "71744\n",
      "52098\n",
      "Acc: 0.7261652542372882\n",
      "Prec 0.6130292969676949\n",
      "Recall 0.5808403404739181\n",
      "F1 0.5965008815103843\n",
      "Epoch: 849, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51829\n",
      "Acc: 0.710375548245614\n",
      "Prec 0.5989070554558292\n",
      "Recall 0.5679312486487195\n",
      "F1 0.5830079979943487\n",
      "468\n",
      "468\n",
      "71744\n",
      "52084\n",
      "Acc: 0.7259701159678859\n",
      "Prec 0.6124977333353709\n",
      "Recall 0.5836456715849152\n",
      "F1 0.5977237335360877\n",
      "Epoch: 850, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52019\n",
      "Acc: 0.7129797149122807\n",
      "Prec 0.6030401250340739\n",
      "Recall 0.5753664240039502\n",
      "F1 0.5888783299023473\n",
      "468\n",
      "468\n",
      "71744\n",
      "52109\n",
      "Acc: 0.7263185771632471\n",
      "Prec 0.6127842504508357\n",
      "Recall 0.5826167021120776\n",
      "F1 0.5973198169843312\n",
      "Epoch: 851, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.801s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51899\n",
      "Acc: 0.7113349780701754\n",
      "Prec 0.6010214420560748\n",
      "Recall 0.5724354220417958\n",
      "F1 0.5863802468853994\n",
      "468\n",
      "468\n",
      "71744\n",
      "52028\n",
      "Acc: 0.7251895628902766\n",
      "Prec 0.6117366966235208\n",
      "Recall 0.5791235880696816\n",
      "F1 0.5949835681920947\n",
      "Epoch: 852, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51930\n",
      "Acc: 0.7117598684210527\n",
      "Prec 0.6030203393202024\n",
      "Recall 0.5709065485953739\n",
      "F1 0.5865241936240005\n",
      "468\n",
      "468\n",
      "71744\n",
      "52059\n",
      "Acc: 0.7256216547725245\n",
      "Prec 0.6118893262830101\n",
      "Recall 0.581846585519012\n",
      "F1 0.5964899132101238\n",
      "Epoch: 853, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51666\n",
      "Acc: 0.7081414473684211\n",
      "Prec 0.5965587926438478\n",
      "Recall 0.5682872297292775\n",
      "F1 0.5820799266696904\n",
      "468\n",
      "468\n",
      "71744\n",
      "52165\n",
      "Acc: 0.7270991302408564\n",
      "Prec 0.613911295376295\n",
      "Recall 0.5853865748691388\n",
      "F1 0.5993097117737065\n",
      "Epoch: 854, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51796\n",
      "Acc: 0.7099232456140351\n",
      "Prec 0.6000587154423466\n",
      "Recall 0.5700679614061795\n",
      "F1 0.5846790016915598\n",
      "468\n",
      "468\n",
      "71744\n",
      "52174\n",
      "Acc: 0.7272245762711864\n",
      "Prec 0.6144742176275814\n",
      "Recall 0.585273551756007\n",
      "F1 0.5995185271286868\n",
      "Epoch: 855, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51870\n",
      "Acc: 0.7109375\n",
      "Prec 0.6007713204500673\n",
      "Recall 0.5700266316518285\n",
      "F1 0.5849953043979511\n",
      "468\n",
      "468\n",
      "71744\n",
      "52169\n",
      "Acc: 0.7271548840321141\n",
      "Prec 0.6155573576189143\n",
      "Recall 0.58500299036093\n",
      "F1 0.5998913683125954\n",
      "Epoch: 856, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52122\n",
      "Acc: 0.7143914473684211\n",
      "Prec 0.6055425848584355\n",
      "Recall 0.5751494948100756\n",
      "F1 0.5899548540464475\n",
      "468\n",
      "468\n",
      "71744\n",
      "52149\n",
      "Acc: 0.7268761150758252\n",
      "Prec 0.6131651524689588\n",
      "Recall 0.5844542493248072\n",
      "F1 0.5984655531826266\n",
      "Epoch: 857, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51747\n",
      "Acc: 0.7092516447368421\n",
      "Prec 0.5979928044894722\n",
      "Recall 0.568451420408863\n",
      "F1 0.5828480296791688\n",
      "468\n",
      "468\n",
      "71744\n",
      "51996\n",
      "Acc: 0.7247435325602141\n",
      "Prec 0.6108632228961102\n",
      "Recall 0.5804493988741186\n",
      "F1 0.5952680833641694\n",
      "Epoch: 858, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.867s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51702\n",
      "Acc: 0.7086348684210526\n",
      "Prec 0.5973989292681753\n",
      "Recall 0.5671841316034493\n",
      "F1 0.5818995729925892\n",
      "468\n",
      "468\n",
      "71744\n",
      "52061\n",
      "Acc: 0.7256495316681534\n",
      "Prec 0.6123449243697654\n",
      "Recall 0.5853967054938479\n",
      "F1 0.5985676583567667\n",
      "Epoch: 859, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51900\n",
      "Acc: 0.7113486842105263\n",
      "Prec 0.6009737291704974\n",
      "Recall 0.5766883193427536\n",
      "F1 0.5885806208699976\n",
      "468\n",
      "468\n",
      "71744\n",
      "51985\n",
      "Acc: 0.7245902096342551\n",
      "Prec 0.6120773053024666\n",
      "Recall 0.5750680600007229\n",
      "F1 0.5929958012191111\n",
      "Epoch: 860, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.871s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52052\n",
      "Acc: 0.7134320175438597\n",
      "Prec 0.6051880476057955\n",
      "Recall 0.5740402377702147\n",
      "F1 0.5892027778701895\n",
      "468\n",
      "468\n",
      "71744\n",
      "52109\n",
      "Acc: 0.7263185771632471\n",
      "Prec 0.6124812066957434\n",
      "Recall 0.5841180541752817\n",
      "F1 0.5979634826343208\n",
      "Epoch: 861, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.806s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51919\n",
      "Acc: 0.711609100877193\n",
      "Prec 0.6007691652557089\n",
      "Recall 0.5730540983952169\n",
      "F1 0.5865844424798146\n",
      "468\n",
      "468\n",
      "71744\n",
      "52209\n",
      "Acc: 0.7277124219446922\n",
      "Prec 0.6147524799166212\n",
      "Recall 0.5861645487444593\n",
      "F1 0.6001182452739778\n",
      "Epoch: 862, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.868s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "52100\n",
      "Acc: 0.7140899122807017\n",
      "Prec 0.6044392961084483\n",
      "Recall 0.5759477307804987\n",
      "F1 0.5898496561856487\n",
      "468\n",
      "468\n",
      "71744\n",
      "52162\n",
      "Acc: 0.727057314897413\n",
      "Prec 0.6147682385096319\n",
      "Recall 0.5819229645641487\n",
      "F1 0.5978948536673553\n",
      "Epoch: 863, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51852\n",
      "Acc: 0.7106907894736842\n",
      "Prec 0.5992395200888063\n",
      "Recall 0.5691953986306565\n",
      "F1 0.5838311951272395\n",
      "468\n",
      "468\n",
      "71744\n",
      "52116\n",
      "Acc: 0.7264161462979483\n",
      "Prec 0.6134121811252853\n",
      "Recall 0.5821967281395901\n",
      "F1 0.5973969616397244\n",
      "Epoch: 864, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51948\n",
      "Acc: 0.7120065789473684\n",
      "Prec 0.6015027009921897\n",
      "Recall 0.5749712976465772\n",
      "F1 0.5879378361571282\n",
      "468\n",
      "468\n",
      "71744\n",
      "52052\n",
      "Acc: 0.7255240856378233\n",
      "Prec 0.6141663153236369\n",
      "Recall 0.5764181466542166\n",
      "F1 0.5946938172335817\n",
      "Epoch: 865, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51645\n",
      "Acc: 0.7078536184210527\n",
      "Prec 0.5975039401157857\n",
      "Recall 0.5664673646216148\n",
      "F1 0.5815718668163912\n",
      "468\n",
      "468\n",
      "71744\n",
      "52166\n",
      "Acc: 0.7271130686886709\n",
      "Prec 0.614365166595093\n",
      "Recall 0.5823863344186283\n",
      "F1 0.5979484915034233\n",
      "Epoch: 866, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51807\n",
      "Acc: 0.7100740131578948\n",
      "Prec 0.5990917623870422\n",
      "Recall 0.5679825964123637\n",
      "F1 0.5831225613420173\n",
      "468\n",
      "468\n",
      "71744\n",
      "52185\n",
      "Acc: 0.7273778991971455\n",
      "Prec 0.6141215315370753\n",
      "Recall 0.5843941447125026\n",
      "F1 0.5988891664649476\n",
      "Epoch: 867, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51996\n",
      "Acc: 0.7126644736842105\n",
      "Prec 0.6033202738671732\n",
      "Recall 0.572696496871387\n",
      "F1 0.587609659883036\n",
      "468\n",
      "468\n",
      "71744\n",
      "52180\n",
      "Acc: 0.7273082069580732\n",
      "Prec 0.613816511623923\n",
      "Recall 0.5850693637191897\n",
      "F1 0.5990982849695549\n",
      "Epoch: 868, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52033\n",
      "Acc: 0.713171600877193\n",
      "Prec 0.603856629817205\n",
      "Recall 0.5742837548517186\n",
      "F1 0.5886990332836793\n",
      "468\n",
      "468\n",
      "71744\n",
      "52154\n",
      "Acc: 0.7269458073148974\n",
      "Prec 0.6136858082260758\n",
      "Recall 0.5810591359050895\n",
      "F1 0.5969269795979351\n",
      "Epoch: 869, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51575\n",
      "Acc: 0.7068941885964912\n",
      "Prec 0.5964328190808031\n",
      "Recall 0.5664763583225927\n",
      "F1 0.5810687505130433\n",
      "468\n",
      "468\n",
      "71744\n",
      "51955\n",
      "Acc: 0.7241720561998216\n",
      "Prec 0.6132270014473576\n",
      "Recall 0.5737040894969277\n",
      "F1 0.5928075205114018\n",
      "Epoch: 870, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51875\n",
      "Acc: 0.7110060307017544\n",
      "Prec 0.6016275756546704\n",
      "Recall 0.5708244026511154\n",
      "F1 0.5858213519120321\n",
      "468\n",
      "468\n",
      "71744\n",
      "52003\n",
      "Acc: 0.7248411016949152\n",
      "Prec 0.6125264822398465\n",
      "Recall 0.576925441967346\n",
      "F1 0.5941931813990171\n",
      "Epoch: 871, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.897s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51794\n",
      "Acc: 0.7098958333333333\n",
      "Prec 0.6008949627860973\n",
      "Recall 0.5671501441295378\n",
      "F1 0.5835351096170693\n",
      "468\n",
      "468\n",
      "71744\n",
      "52071\n",
      "Acc: 0.7257889161462979\n",
      "Prec 0.6136119145800755\n",
      "Recall 0.5832927654326445\n",
      "F1 0.5980683283050213\n",
      "Epoch: 872, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51947\n",
      "Acc: 0.7119928728070175\n",
      "Prec 0.6015859360676735\n",
      "Recall 0.5728431918079419\n",
      "F1 0.5868628418423779\n",
      "468\n",
      "468\n",
      "71744\n",
      "52087\n",
      "Acc: 0.7260119313113291\n",
      "Prec 0.6129925172580516\n",
      "Recall 0.5805621732534366\n",
      "F1 0.5963367591558282\n",
      "Epoch: 873, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.843s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51954\n",
      "Acc: 0.7120888157894737\n",
      "Prec 0.6029421963174005\n",
      "Recall 0.5718333326394343\n",
      "F1 0.586975872429477\n",
      "468\n",
      "468\n",
      "71744\n",
      "52157\n",
      "Acc: 0.7269876226583407\n",
      "Prec 0.6141869971344316\n",
      "Recall 0.5834262622779673\n",
      "F1 0.5984115844770852\n",
      "Epoch: 874, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51979\n",
      "Acc: 0.7124314692982456\n",
      "Prec 0.6023033583455578\n",
      "Recall 0.5727829735913501\n",
      "F1 0.5871723620996863\n",
      "468\n",
      "468\n",
      "71744\n",
      "52156\n",
      "Acc: 0.7269736842105263\n",
      "Prec 0.6138912894378649\n",
      "Recall 0.5841396143627802\n",
      "F1 0.5986460281371435\n",
      "Epoch: 875, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51892\n",
      "Acc: 0.7112390350877194\n",
      "Prec 0.600358905474817\n",
      "Recall 0.570781597924726\n",
      "F1 0.585196762302311\n",
      "468\n",
      "468\n",
      "71744\n",
      "52149\n",
      "Acc: 0.7268761150758252\n",
      "Prec 0.6141090163439866\n",
      "Recall 0.5834939733964356\n",
      "F1 0.5984101795250132\n",
      "Epoch: 876, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51916\n",
      "Acc: 0.7115679824561404\n",
      "Prec 0.6005882444132062\n",
      "Recall 0.5717541627490627\n",
      "F1 0.5858166125246586\n",
      "468\n",
      "468\n",
      "71744\n",
      "52198\n",
      "Acc: 0.7275590990187333\n",
      "Prec 0.6139748909042962\n",
      "Recall 0.5847209313468907\n",
      "F1 0.5989909422708181\n",
      "Epoch: 877, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.776s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51912\n",
      "Acc: 0.7115131578947368\n",
      "Prec 0.6006730186615283\n",
      "Recall 0.5714042774125266\n",
      "F1 0.5856732031908684\n",
      "468\n",
      "468\n",
      "71744\n",
      "52156\n",
      "Acc: 0.7269736842105263\n",
      "Prec 0.6137315707719654\n",
      "Recall 0.5831646218216017\n",
      "F1 0.5980577790855183\n",
      "Epoch: 878, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.848s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51971\n",
      "Acc: 0.7123218201754385\n",
      "Prec 0.6031671046860764\n",
      "Recall 0.5743225842044194\n",
      "F1 0.5883915477796097\n",
      "468\n",
      "468\n",
      "71744\n",
      "52174\n",
      "Acc: 0.7272245762711864\n",
      "Prec 0.6150387199656552\n",
      "Recall 0.5833759695735757\n",
      "F1 0.5987890714577385\n",
      "Epoch: 879, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.841s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51903\n",
      "Acc: 0.7113898026315789\n",
      "Prec 0.6018048109486845\n",
      "Recall 0.5696116358836708\n",
      "F1 0.5852658527615872\n",
      "468\n",
      "468\n",
      "71744\n",
      "52091\n",
      "Acc: 0.726067685102587\n",
      "Prec 0.6141009114602547\n",
      "Recall 0.5825547209629516\n",
      "F1 0.5979120064715542\n",
      "Epoch: 880, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51790\n",
      "Acc: 0.7098410087719298\n",
      "Prec 0.6005940382971295\n",
      "Recall 0.5677629402992594\n",
      "F1 0.5837172086213586\n",
      "468\n",
      "468\n",
      "71744\n",
      "52141\n",
      "Acc: 0.7267646074933095\n",
      "Prec 0.6145178141494034\n",
      "Recall 0.5840907595100572\n",
      "F1 0.5989180866663195\n",
      "Epoch: 881, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52091\n",
      "Acc: 0.7139665570175439\n",
      "Prec 0.6053472199993086\n",
      "Recall 0.5749514805405984\n",
      "F1 0.5897579658785198\n",
      "468\n",
      "468\n",
      "71744\n",
      "52153\n",
      "Acc: 0.7269318688670829\n",
      "Prec 0.6122318336180336\n",
      "Recall 0.5864639091938915\n",
      "F1 0.5990709095776128\n",
      "Epoch: 882, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51778\n",
      "Acc: 0.7096765350877193\n",
      "Prec 0.5988848980229398\n",
      "Recall 0.5704747396762617\n",
      "F1 0.5843346995760847\n",
      "468\n",
      "468\n",
      "71744\n",
      "52234\n",
      "Acc: 0.7280608831400536\n",
      "Prec 0.6156580856316562\n",
      "Recall 0.5857015446389585\n",
      "F1 0.6003063239984172\n",
      "Epoch: 883, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51740\n",
      "Acc: 0.7091557017543859\n",
      "Prec 0.5993215722028505\n",
      "Recall 0.5675395009936277\n",
      "F1 0.5829977087005782\n",
      "468\n",
      "468\n",
      "71744\n",
      "52133\n",
      "Acc: 0.726653099910794\n",
      "Prec 0.6153670245219861\n",
      "Recall 0.5831943061636862\n",
      "F1 0.5988488627391385\n",
      "Epoch: 884, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52060\n",
      "Acc: 0.7135416666666666\n",
      "Prec 0.6032132485037763\n",
      "Recall 0.5746233591812896\n",
      "F1 0.5885713194789384\n",
      "468\n",
      "468\n",
      "71744\n",
      "52237\n",
      "Acc: 0.7281026984834968\n",
      "Prec 0.6154709380282518\n",
      "Recall 0.5856119485578627\n",
      "F1 0.6001702951973887\n",
      "Epoch: 885, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.880s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52011\n",
      "Acc: 0.7128700657894737\n",
      "Prec 0.6035360174966083\n",
      "Recall 0.5736417155389179\n",
      "F1 0.5882092852258061\n",
      "468\n",
      "468\n",
      "71744\n",
      "52182\n",
      "Acc: 0.7273360838537021\n",
      "Prec 0.6150162388568837\n",
      "Recall 0.5835440962148151\n",
      "F1 0.5988669652407711\n",
      "Epoch: 886, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.883s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51740\n",
      "Acc: 0.7091557017543859\n",
      "Prec 0.597642865897093\n",
      "Recall 0.568110550678823\n",
      "F1 0.5825026336209872\n",
      "468\n",
      "468\n",
      "71744\n",
      "52166\n",
      "Acc: 0.7271130686886709\n",
      "Prec 0.6141243181113606\n",
      "Recall 0.5829508562163431\n",
      "F1 0.5981316875397678\n",
      "Epoch: 887, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51903\n",
      "Acc: 0.7113898026315789\n",
      "Prec 0.6009908637744149\n",
      "Recall 0.5709464730729007\n",
      "F1 0.5855835516668807\n",
      "468\n",
      "468\n",
      "71744\n",
      "52080\n",
      "Acc: 0.725914362176628\n",
      "Prec 0.6135649736449572\n",
      "Recall 0.5788848789630718\n",
      "F1 0.5957206246075893\n",
      "Epoch: 888, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52051\n",
      "Acc: 0.7134183114035088\n",
      "Prec 0.6046007945149626\n",
      "Recall 0.573712299879532\n",
      "F1 0.5887516891398338\n",
      "468\n",
      "468\n",
      "71744\n",
      "52121\n",
      "Acc: 0.7264858385370205\n",
      "Prec 0.6123070480059004\n",
      "Recall 0.5876835850729324\n",
      "F1 0.5997426833479158\n",
      "Epoch: 889, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51904\n",
      "Acc: 0.7114035087719298\n",
      "Prec 0.6013171193638922\n",
      "Recall 0.5706064639007371\n",
      "F1 0.5855594000547216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "71744\n",
      "52235\n",
      "Acc: 0.728074821587868\n",
      "Prec 0.6146838235706433\n",
      "Recall 0.5880650961914521\n",
      "F1 0.6010799027063765\n",
      "Epoch: 890, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51813\n",
      "Acc: 0.71015625\n",
      "Prec 0.5995841209429352\n",
      "Recall 0.5708292240565009\n",
      "F1 0.5848534451127945\n",
      "468\n",
      "468\n",
      "71744\n",
      "52149\n",
      "Acc: 0.7268761150758252\n",
      "Prec 0.6132818473043202\n",
      "Recall 0.5818725813138753\n",
      "F1 0.5971644885698812\n",
      "Epoch: 891, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51777\n",
      "Acc: 0.7096628289473684\n",
      "Prec 0.5983399690978777\n",
      "Recall 0.571007696020068\n",
      "F1 0.5843544009759266\n",
      "468\n",
      "468\n",
      "71744\n",
      "52187\n",
      "Acc: 0.7274057760927743\n",
      "Prec 0.6148341591741294\n",
      "Recall 0.5823417711912499\n",
      "F1 0.5981470294563475\n",
      "Epoch: 892, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51817\n",
      "Acc: 0.7102110745614035\n",
      "Prec 0.5990998603860566\n",
      "Recall 0.5722147409503447\n",
      "F1 0.5853487543364774\n",
      "468\n",
      "468\n",
      "71744\n",
      "52324\n",
      "Acc: 0.7293153434433541\n",
      "Prec 0.6175293795659197\n",
      "Recall 0.58493362882379\n",
      "F1 0.600789709745034\n",
      "Epoch: 893, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.807s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51832\n",
      "Acc: 0.7104166666666667\n",
      "Prec 0.6002120331515817\n",
      "Recall 0.568831457680449\n",
      "F1 0.5841005718135693\n",
      "468\n",
      "468\n",
      "71744\n",
      "52165\n",
      "Acc: 0.7270991302408564\n",
      "Prec 0.6145804613538132\n",
      "Recall 0.5822978339563138\n",
      "F1 0.598003778396648\n",
      "Epoch: 894, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.896s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51774\n",
      "Acc: 0.7096217105263158\n",
      "Prec 0.5993210870782624\n",
      "Recall 0.5669069491865334\n",
      "F1 0.5826635589157643\n",
      "468\n",
      "468\n",
      "71744\n",
      "52142\n",
      "Acc: 0.726778545941124\n",
      "Prec 0.613887070734732\n",
      "Recall 0.584398084412676\n",
      "F1 0.5987797255803504\n",
      "Epoch: 895, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51696\n",
      "Acc: 0.7085526315789473\n",
      "Prec 0.598406664318562\n",
      "Recall 0.5687314942990592\n",
      "F1 0.5831918250355336\n",
      "468\n",
      "468\n",
      "71744\n",
      "52166\n",
      "Acc: 0.7271130686886709\n",
      "Prec 0.614617042351478\n",
      "Recall 0.5829466477535102\n",
      "F1 0.5983630723799931\n",
      "Epoch: 896, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51954\n",
      "Acc: 0.7120888157894737\n",
      "Prec 0.6025795761219774\n",
      "Recall 0.5713263399767919\n",
      "F1 0.5865369260845775\n",
      "468\n",
      "468\n",
      "71744\n",
      "52215\n",
      "Acc: 0.727796052631579\n",
      "Prec 0.6161917431439591\n",
      "Recall 0.5869854672441055\n",
      "F1 0.6012341243475811\n",
      "Epoch: 897, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51867\n",
      "Acc: 0.7108963815789474\n",
      "Prec 0.6015146904196617\n",
      "Recall 0.5691824069804404\n",
      "F1 0.584902072598455\n",
      "468\n",
      "468\n",
      "71744\n",
      "52117\n",
      "Acc: 0.7264300847457628\n",
      "Prec 0.6126506323362487\n",
      "Recall 0.5828095619236162\n",
      "F1 0.5973576508169363\n",
      "Epoch: 898, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51788\n",
      "Acc: 0.7098135964912281\n",
      "Prec 0.5992360378066796\n",
      "Recall 0.5676087213634382\n",
      "F1 0.5829937505247063\n",
      "468\n",
      "468\n",
      "71744\n",
      "52142\n",
      "Acc: 0.726778545941124\n",
      "Prec 0.614180530907693\n",
      "Recall 0.5836472562198468\n",
      "F1 0.5985247387648989\n",
      "Epoch: 899, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.869s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51738\n",
      "Acc: 0.7091282894736842\n",
      "Prec 0.5992330379620937\n",
      "Recall 0.5689217279632217\n",
      "F1 0.583684123635791\n",
      "468\n",
      "468\n",
      "71744\n",
      "52233\n",
      "Acc: 0.7280469446922391\n",
      "Prec 0.6157459825584733\n",
      "Recall 0.5849017229889597\n",
      "F1 0.5999276631404062\n",
      "Epoch: 900, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51729\n",
      "Acc: 0.7090049342105263\n",
      "Prec 0.597701373993167\n",
      "Recall 0.5681113104721665\n",
      "F1 0.5825308222752824\n",
      "468\n",
      "468\n",
      "71744\n",
      "52271\n",
      "Acc: 0.7285766057091883\n",
      "Prec 0.6171633546600171\n",
      "Recall 0.5844281184439803\n",
      "F1 0.6003498297217217\n",
      "Epoch: 901, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.867s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51827\n",
      "Acc: 0.7103481359649123\n",
      "Prec 0.5998127923335861\n",
      "Recall 0.5688942286034968\n",
      "F1 0.5839445296179065\n",
      "468\n",
      "468\n",
      "71744\n",
      "52253\n",
      "Acc: 0.728325713648528\n",
      "Prec 0.615446067433714\n",
      "Recall 0.5861737863524458\n",
      "F1 0.6004533805040531\n",
      "Epoch: 902, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.854s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52109\n",
      "Acc: 0.7142132675438596\n",
      "Prec 0.6064939332490205\n",
      "Recall 0.5760101588660107\n",
      "F1 0.5908591254296588\n",
      "468\n",
      "468\n",
      "71744\n",
      "52285\n",
      "Acc: 0.7287717439785906\n",
      "Prec 0.6164788592507472\n",
      "Recall 0.5880410384701592\n",
      "F1 0.601924250939531\n",
      "Epoch: 903, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51990\n",
      "Acc: 0.7125822368421053\n",
      "Prec 0.6032763664438824\n",
      "Recall 0.5755034506968215\n",
      "F1 0.5890627334533889\n",
      "468\n",
      "468\n",
      "71744\n",
      "52260\n",
      "Acc: 0.7284232827832292\n",
      "Prec 0.6164213142238403\n",
      "Recall 0.5838238760164974\n",
      "F1 0.599679938492039\n",
      "Epoch: 904, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.897s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51879\n",
      "Acc: 0.7110608552631579\n",
      "Prec 0.6022284904583649\n",
      "Recall 0.5714226799858287\n",
      "F1 0.586421292199277\n",
      "468\n",
      "468\n",
      "71744\n",
      "52168\n",
      "Acc: 0.7271409455842998\n",
      "Prec 0.6146077901581896\n",
      "Recall 0.5813638091072808\n",
      "F1 0.5975237642981204\n",
      "Epoch: 905, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51686\n",
      "Acc: 0.7084155701754385\n",
      "Prec 0.5975927100285752\n",
      "Recall 0.5750231333161199\n",
      "F1 0.5860907210452749\n",
      "468\n",
      "468\n",
      "71744\n",
      "52077\n",
      "Acc: 0.7258725468331847\n",
      "Prec 0.6136207764583435\n",
      "Recall 0.5749078128327926\n",
      "F1 0.5936338118931224\n",
      "Epoch: 906, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51735\n",
      "Acc: 0.7090871710526315\n",
      "Prec 0.6018153533109681\n",
      "Recall 0.563371482636963\n",
      "F1 0.5819592144510614\n",
      "468\n",
      "468\n",
      "71744\n",
      "52144\n",
      "Acc: 0.7268064228367529\n",
      "Prec 0.6141121458758013\n",
      "Recall 0.5839283008455635\n",
      "F1 0.5986399922494111\n",
      "Epoch: 907, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51629\n",
      "Acc: 0.7076343201754386\n",
      "Prec 0.5949854878412421\n",
      "Recall 0.5675322874640442\n",
      "F1 0.5809347299378276\n",
      "468\n",
      "468\n",
      "71744\n",
      "52143\n",
      "Acc: 0.7267924843889384\n",
      "Prec 0.6169974491180733\n",
      "Recall 0.5796165277067002\n",
      "F1 0.5977231187131244\n",
      "Epoch: 908, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.882s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51809\n",
      "Acc: 0.7101014254385964\n",
      "Prec 0.6015958513394805\n",
      "Recall 0.5677468685219957\n",
      "F1 0.5841814464014035\n",
      "468\n",
      "468\n",
      "71744\n",
      "52147\n",
      "Acc: 0.7268482381801963\n",
      "Prec 0.6149151726693898\n",
      "Recall 0.5837475491562053\n",
      "F1 0.5989261506990438\n",
      "Epoch: 909, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51844\n",
      "Acc: 0.7105811403508772\n",
      "Prec 0.600832263250876\n",
      "Recall 0.5695608898845227\n",
      "F1 0.5847788114818399\n",
      "468\n",
      "468\n",
      "71744\n",
      "52128\n",
      "Acc: 0.7265834076717217\n",
      "Prec 0.6131127679495906\n",
      "Recall 0.5827490051427311\n",
      "F1 0.5975454080098719\n",
      "Epoch: 910, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.856s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52044\n",
      "Acc: 0.7133223684210527\n",
      "Prec 0.6050913933140932\n",
      "Recall 0.5737113837082221\n",
      "F1 0.588983716860709\n",
      "468\n",
      "468\n",
      "71744\n",
      "52249\n",
      "Acc: 0.7282699598572703\n",
      "Prec 0.6152158998017113\n",
      "Recall 0.5864929746230053\n",
      "F1 0.6005111733618619\n",
      "Epoch: 911, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51905\n",
      "Acc: 0.7114172149122807\n",
      "Prec 0.6010324653989734\n",
      "Recall 0.5759176737963373\n",
      "F1 0.5882071089015145\n",
      "468\n",
      "468\n",
      "71744\n",
      "52132\n",
      "Acc: 0.7266391614629795\n",
      "Prec 0.6151380748342238\n",
      "Recall 0.5800720843214341\n",
      "F1 0.5970906831425142\n",
      "Epoch: 912, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.847s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51924\n",
      "Acc: 0.7116776315789474\n",
      "Prec 0.6032078907983877\n",
      "Recall 0.5696556718582152\n",
      "F1 0.5859518655769503\n",
      "468\n",
      "468\n",
      "71744\n",
      "52307\n",
      "Acc: 0.7290783898305084\n",
      "Prec 0.6165974259549435\n",
      "Recall 0.5879362983750612\n",
      "F1 0.6019258753509522\n",
      "Epoch: 913, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52083\n",
      "Acc: 0.7138569078947369\n",
      "Prec 0.6053311331579242\n",
      "Recall 0.5754269746877956\n",
      "F1 0.5900003740358175\n",
      "468\n",
      "468\n",
      "71744\n",
      "52321\n",
      "Acc: 0.7292735280999108\n",
      "Prec 0.6167752370473257\n",
      "Recall 0.5889654669679555\n",
      "F1 0.6025496432062822\n",
      "Epoch: 914, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.813s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52035\n",
      "Acc: 0.7131990131578947\n",
      "Prec 0.6041410180957194\n",
      "Recall 0.5747614246234699\n",
      "F1 0.5890851348704516\n",
      "468\n",
      "468\n",
      "71744\n",
      "52362\n",
      "Acc: 0.7298450044603033\n",
      "Prec 0.6185117065375406\n",
      "Recall 0.587781460909728\n",
      "F1 0.6027551581474023\n",
      "Epoch: 915, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52048\n",
      "Acc: 0.7133771929824562\n",
      "Prec 0.6040753532396492\n",
      "Recall 0.5774462133018629\n",
      "F1 0.590460699415367\n",
      "468\n",
      "468\n",
      "71744\n",
      "52311\n",
      "Acc: 0.7291341436217663\n",
      "Prec 0.6179639171069226\n",
      "Recall 0.5840713764688967\n",
      "F1 0.6005398304055458\n",
      "Epoch: 916, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.845s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52121\n",
      "Acc: 0.7143777412280702\n",
      "Prec 0.6058583838815486\n",
      "Recall 0.5752174948384644\n",
      "F1 0.5901404779867506\n",
      "468\n",
      "468\n",
      "71744\n",
      "52387\n",
      "Acc: 0.7301934656556646\n",
      "Prec 0.6168454226114498\n",
      "Recall 0.592149704042142\n",
      "F1 0.6042453379446545\n",
      "Epoch: 917, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.858s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "52148\n",
      "Acc: 0.7147478070175438\n",
      "Prec 0.6055374492270055\n",
      "Recall 0.5794472796132341\n",
      "F1 0.5922051468155767\n",
      "468\n",
      "468\n",
      "71744\n",
      "52095\n",
      "Acc: 0.7261234388938448\n",
      "Prec 0.6170816785001794\n",
      "Recall 0.577486113778061\n",
      "F1 0.596627671872989\n",
      "Epoch: 918, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51922\n",
      "Acc: 0.7116502192982456\n",
      "Prec 0.6020036141853764\n",
      "Recall 0.5701625885260723\n",
      "F1 0.5856506324308008\n",
      "468\n",
      "468\n",
      "71744\n",
      "52254\n",
      "Acc: 0.7283396520963425\n",
      "Prec 0.6149438864324529\n",
      "Recall 0.588922690527744\n",
      "F1 0.6016520685138373\n",
      "Epoch: 919, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51948\n",
      "Acc: 0.7120065789473684\n",
      "Prec 0.6047373095261045\n",
      "Recall 0.5708884729933656\n",
      "F1 0.5873256002562303\n",
      "468\n",
      "468\n",
      "71744\n",
      "52279\n",
      "Acc: 0.7286881132917038\n",
      "Prec 0.6161739489458006\n",
      "Recall 0.5873990342430521\n",
      "F1 0.6014425175572404\n",
      "Epoch: 920, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.858s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52184\n",
      "Acc: 0.7152412280701754\n",
      "Prec 0.6067852247628892\n",
      "Recall 0.5782083420060201\n",
      "F1 0.592152208421771\n",
      "468\n",
      "468\n",
      "71744\n",
      "52287\n",
      "Acc: 0.7287996208742195\n",
      "Prec 0.6156810448564962\n",
      "Recall 0.5875851183788793\n",
      "F1 0.60130506562723\n",
      "Epoch: 921, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51939\n",
      "Acc: 0.7118832236842105\n",
      "Prec 0.602926286045563\n",
      "Recall 0.5725262041897367\n",
      "F1 0.5873331348113983\n",
      "468\n",
      "468\n",
      "71744\n",
      "52157\n",
      "Acc: 0.7269876226583407\n",
      "Prec 0.6148830133381574\n",
      "Recall 0.5835991889877751\n",
      "F1 0.5988328023730108\n",
      "Epoch: 922, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51955\n",
      "Acc: 0.7121025219298246\n",
      "Prec 0.6031225801021273\n",
      "Recall 0.5731564349930957\n",
      "F1 0.5877578082053756\n",
      "468\n",
      "468\n",
      "71744\n",
      "52223\n",
      "Acc: 0.7279075602140945\n",
      "Prec 0.6150292468829467\n",
      "Recall 0.5842256719005267\n",
      "F1 0.5992318553309003\n",
      "Epoch: 923, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52032\n",
      "Acc: 0.7131578947368421\n",
      "Prec 0.6044649843494194\n",
      "Recall 0.5746266659594971\n",
      "F1 0.5891682780638207\n",
      "468\n",
      "468\n",
      "71744\n",
      "52188\n",
      "Acc: 0.7274197145405887\n",
      "Prec 0.6157619551569765\n",
      "Recall 0.5829868525141837\n",
      "F1 0.5989263502707417\n",
      "Epoch: 924, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.815s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51877\n",
      "Acc: 0.7110334429824562\n",
      "Prec 0.6021782192774054\n",
      "Recall 0.5714925857130261\n",
      "F1 0.5864342644149109\n",
      "468\n",
      "468\n",
      "71744\n",
      "52328\n",
      "Acc: 0.7293710972346119\n",
      "Prec 0.6185677788723837\n",
      "Recall 0.588014022453552\n",
      "F1 0.6029040507907606\n",
      "Epoch: 925, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.901s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52127\n",
      "Acc: 0.7144599780701755\n",
      "Prec 0.6056410149395911\n",
      "Recall 0.576553656124592\n",
      "F1 0.5907394949566173\n",
      "468\n",
      "468\n",
      "71744\n",
      "52320\n",
      "Acc: 0.7292595896520964\n",
      "Prec 0.6163020524502336\n",
      "Recall 0.5880129728093334\n",
      "F1 0.6018252606815206\n",
      "Epoch: 926, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52051\n",
      "Acc: 0.7134183114035088\n",
      "Prec 0.6051926636642857\n",
      "Recall 0.5749270020750411\n",
      "F1 0.5896717322820587\n",
      "468\n",
      "468\n",
      "71744\n",
      "52364\n",
      "Acc: 0.7298728813559322\n",
      "Prec 0.6188198420636252\n",
      "Recall 0.5880666073561559\n",
      "F1 0.6030514059744049\n",
      "Epoch: 927, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52034\n",
      "Acc: 0.7131853070175439\n",
      "Prec 0.6041602514367138\n",
      "Recall 0.574153779370106\n",
      "F1 0.5887749490177336\n",
      "468\n",
      "468\n",
      "71744\n",
      "52270\n",
      "Acc: 0.7285626672613738\n",
      "Prec 0.6160685667378313\n",
      "Recall 0.5886040467152697\n",
      "F1 0.6020232341740387\n",
      "Epoch: 928, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.821s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52010\n",
      "Acc: 0.7128563596491229\n",
      "Prec 0.602598946589901\n",
      "Recall 0.5758144028331286\n",
      "F1 0.5889022773688465\n",
      "468\n",
      "468\n",
      "71744\n",
      "52304\n",
      "Acc: 0.7290365744870652\n",
      "Prec 0.6174898347568039\n",
      "Recall 0.584500677726063\n",
      "F1 0.6005425552965022\n",
      "Epoch: 929, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.804s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51902\n",
      "Acc: 0.711376096491228\n",
      "Prec 0.601909465533634\n",
      "Recall 0.5727918000076283\n",
      "F1 0.5869897587039408\n",
      "468\n",
      "468\n",
      "71744\n",
      "52369\n",
      "Acc: 0.7299425735950045\n",
      "Prec 0.6178977655654979\n",
      "Recall 0.5867804850307315\n",
      "F1 0.6019372399202555\n",
      "Epoch: 930, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.880s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52262\n",
      "Acc: 0.7163103070175438\n",
      "Prec 0.6088505247411883\n",
      "Recall 0.5764309103564894\n",
      "F1 0.5921973496845788\n",
      "468\n",
      "468\n",
      "71744\n",
      "52262\n",
      "Acc: 0.7284511596788582\n",
      "Prec 0.6157298364793248\n",
      "Recall 0.5924615978944665\n",
      "F1 0.6038716587672452\n",
      "Epoch: 931, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52178\n",
      "Acc: 0.7151589912280701\n",
      "Prec 0.6070096737270247\n",
      "Recall 0.5774402348586467\n",
      "F1 0.5918558581796727\n",
      "468\n",
      "468\n",
      "71744\n",
      "52416\n",
      "Acc: 0.7305976806422837\n",
      "Prec 0.6197234039873452\n",
      "Recall 0.5887953192000777\n",
      "F1 0.6038636099970437\n",
      "Epoch: 932, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52103\n",
      "Acc: 0.7141310307017544\n",
      "Prec 0.6053007098071665\n",
      "Recall 0.5754380659163965\n",
      "F1 0.589991752470075\n",
      "468\n",
      "468\n",
      "71744\n",
      "52280\n",
      "Acc: 0.7287020517395183\n",
      "Prec 0.6158711709611581\n",
      "Recall 0.5875658360369758\n",
      "F1 0.6013856269211858\n",
      "Epoch: 933, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.885s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52007\n",
      "Acc: 0.7128152412280702\n",
      "Prec 0.6047402895166093\n",
      "Recall 0.5740668288744196\n",
      "F1 0.5890044857707407\n",
      "468\n",
      "468\n",
      "71744\n",
      "52386\n",
      "Acc: 0.7301795272078502\n",
      "Prec 0.6193442390685836\n",
      "Recall 0.5884995724661205\n",
      "F1 0.6035280661629548\n",
      "Epoch: 934, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.855s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52196\n",
      "Acc: 0.715405701754386\n",
      "Prec 0.6088067876430977\n",
      "Recall 0.5783051235149799\n",
      "F1 0.5931641005627425\n",
      "468\n",
      "468\n",
      "71744\n",
      "52321\n",
      "Acc: 0.7292735280999108\n",
      "Prec 0.6184977112678977\n",
      "Recall 0.5864591715312614\n",
      "F1 0.6020525058150333\n",
      "Epoch: 935, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52053\n",
      "Acc: 0.7134457236842106\n",
      "Prec 0.6056951390591986\n",
      "Recall 0.5743239147849925\n",
      "F1 0.5895925193707104\n",
      "468\n",
      "468\n",
      "71744\n",
      "52367\n",
      "Acc: 0.7299146966993756\n",
      "Prec 0.617585741825452\n",
      "Recall 0.590059849035299\n",
      "F1 0.6035090962873368\n",
      "Epoch: 936, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.896s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52066\n",
      "Acc: 0.7136239035087719\n",
      "Prec 0.6052302710061012\n",
      "Recall 0.5752139649433575\n",
      "F1 0.5898404910404729\n",
      "468\n",
      "468\n",
      "71744\n",
      "52322\n",
      "Acc: 0.7292874665477252\n",
      "Prec 0.6166381489504557\n",
      "Recall 0.5907893937571941\n",
      "F1 0.6034370847116008\n",
      "Epoch: 937, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52131\n",
      "Acc: 0.714514802631579\n",
      "Prec 0.6062791040930148\n",
      "Recall 0.5778495108917824\n",
      "F1 0.5917230262500743\n",
      "468\n",
      "468\n",
      "71744\n",
      "52403\n",
      "Acc: 0.7304164808206958\n",
      "Prec 0.6198489342984158\n",
      "Recall 0.5873886275825377\n",
      "F1 0.6031823831902084\n",
      "Epoch: 938, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.808s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52017\n",
      "Acc: 0.7129523026315789\n",
      "Prec 0.6047029860268553\n",
      "Recall 0.5725400253285104\n",
      "F1 0.5881821503233061\n",
      "468\n",
      "468\n",
      "71744\n",
      "52332\n",
      "Acc: 0.7294268510258698\n",
      "Prec 0.6174422685504637\n",
      "Recall 0.5893406473114423\n",
      "F1 0.6030642652329617\n",
      "Epoch: 939, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52012\n",
      "Acc: 0.7128837719298246\n",
      "Prec 0.6030898372336053\n",
      "Recall 0.5728684398591458\n",
      "F1 0.5875908029748437\n",
      "468\n",
      "468\n",
      "71744\n",
      "52421\n",
      "Acc: 0.730667372881356\n",
      "Prec 0.6181089374889387\n",
      "Recall 0.5924603930937137\n",
      "F1 0.6050129551905601\n",
      "Epoch: 940, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52046\n",
      "Acc: 0.7133497807017544\n",
      "Prec 0.6039216469739123\n",
      "Recall 0.5778703014333856\n",
      "F1 0.5906088371126463\n",
      "468\n",
      "468\n",
      "71744\n",
      "52486\n",
      "Acc: 0.7315733719892953\n",
      "Prec 0.6203823047492488\n",
      "Recall 0.5915421330984632\n",
      "F1 0.6056190640724183\n",
      "Epoch: 941, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52139\n",
      "Acc: 0.7146244517543859\n",
      "Prec 0.604731540965489\n",
      "Recall 0.575459374714791\n",
      "F1 0.5897324404225238\n",
      "468\n",
      "468\n",
      "71744\n",
      "52478\n",
      "Acc: 0.7314618644067796\n",
      "Prec 0.6206997809733983\n",
      "Recall 0.5915649478836583\n",
      "F1 0.6057822600004438\n",
      "Epoch: 942, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.810s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52177\n",
      "Acc: 0.7151452850877194\n",
      "Prec 0.6064713721184615\n",
      "Recall 0.5771833084090356\n",
      "F1 0.5914649918989935\n",
      "468\n",
      "468\n",
      "71744\n",
      "52308\n",
      "Acc: 0.7290923282783229\n",
      "Prec 0.6169297418877269\n",
      "Recall 0.5870884523624121\n",
      "F1 0.6016392926799263\n",
      "Epoch: 943, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52213\n",
      "Acc: 0.7156387061403509\n",
      "Prec 0.6069872547077658\n",
      "Recall 0.576375974445708\n",
      "F1 0.5912856877572291\n",
      "468\n",
      "468\n",
      "71744\n",
      "52479\n",
      "Acc: 0.7314758028545941\n",
      "Prec 0.6205429697741239\n",
      "Recall 0.5920868965657041\n",
      "F1 0.6059810521873817\n",
      "Epoch: 944, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.820s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52237\n",
      "Acc: 0.7159676535087719\n",
      "Prec 0.6084072879035959\n",
      "Recall 0.5785557032509265\n",
      "F1 0.5931061186224126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "71744\n",
      "52467\n",
      "Acc: 0.7313085414808207\n",
      "Prec 0.6201238446358973\n",
      "Recall 0.5926438927473344\n",
      "F1 0.6060725363018596\n",
      "Epoch: 945, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52143\n",
      "Acc: 0.7146792763157894\n",
      "Prec 0.6053789294517606\n",
      "Recall 0.5760995011750767\n",
      "F1 0.59037641354828\n",
      "468\n",
      "468\n",
      "71744\n",
      "52328\n",
      "Acc: 0.7293710972346119\n",
      "Prec 0.6173664955608179\n",
      "Recall 0.5902383847197097\n",
      "F1 0.6034977318661319\n",
      "Epoch: 946, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.870s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52022\n",
      "Acc: 0.7130208333333333\n",
      "Prec 0.6034753525169859\n",
      "Recall 0.5736653439089331\n",
      "F1 0.5881928926480001\n",
      "468\n",
      "468\n",
      "71744\n",
      "52395\n",
      "Acc: 0.7303049732381802\n",
      "Prec 0.6189549491597405\n",
      "Recall 0.5897372629098391\n",
      "F1 0.6039929668396856\n",
      "Epoch: 947, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.853s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52164\n",
      "Acc: 0.7149671052631579\n",
      "Prec 0.6074398441732168\n",
      "Recall 0.5764882648604915\n",
      "F1 0.5915594690295083\n",
      "468\n",
      "468\n",
      "71744\n",
      "52300\n",
      "Acc: 0.7289808206958073\n",
      "Prec 0.6170972903967801\n",
      "Recall 0.5885507407659577\n",
      "F1 0.6024860622671504\n",
      "Epoch: 948, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.838s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51591\n",
      "Acc: 0.7071134868421053\n",
      "Prec 0.5962009295061849\n",
      "Recall 0.5696933634884015\n",
      "F1 0.5826458108357289\n",
      "468\n",
      "468\n",
      "71744\n",
      "52195\n",
      "Acc: 0.7275172836752899\n",
      "Prec 0.6176694066254969\n",
      "Recall 0.5785591165977206\n",
      "F1 0.5974749127094712\n",
      "Epoch: 949, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52067\n",
      "Acc: 0.7136376096491228\n",
      "Prec 0.6038697476987472\n",
      "Recall 0.5731815661878924\n",
      "F1 0.5881256045100349\n",
      "468\n",
      "468\n",
      "71744\n",
      "52423\n",
      "Acc: 0.7306952497769849\n",
      "Prec 0.6199200286676323\n",
      "Recall 0.5898868204904085\n",
      "F1 0.6045306404465599\n",
      "Epoch: 950, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.773s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52196\n",
      "Acc: 0.715405701754386\n",
      "Prec 0.6082224539843741\n",
      "Recall 0.5757867122730921\n",
      "F1 0.5915602971509115\n",
      "468\n",
      "468\n",
      "71744\n",
      "52490\n",
      "Acc: 0.7316291257805531\n",
      "Prec 0.6197700650264543\n",
      "Recall 0.5932044387562714\n",
      "F1 0.6061963420260168\n",
      "Epoch: 951, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.836s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52199\n",
      "Acc: 0.7154468201754386\n",
      "Prec 0.6068082810628288\n",
      "Recall 0.5793795082045706\n",
      "F1 0.5927767704872041\n",
      "468\n",
      "468\n",
      "71744\n",
      "52404\n",
      "Acc: 0.7304304192685103\n",
      "Prec 0.619825421161117\n",
      "Recall 0.5857393633932042\n",
      "F1 0.6023005188228912\n",
      "Epoch: 952, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.825s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52147\n",
      "Acc: 0.714734100877193\n",
      "Prec 0.6055435494554143\n",
      "Recall 0.576804130580896\n",
      "F1 0.5908245543506686\n",
      "468\n",
      "468\n",
      "71744\n",
      "52531\n",
      "Acc: 0.7322006021409456\n",
      "Prec 0.6206859304382878\n",
      "Recall 0.5938151702569434\n",
      "F1 0.606953293411286\n",
      "Epoch: 953, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.840s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52454\n",
      "Acc: 0.7189418859649123\n",
      "Prec 0.6123983993385597\n",
      "Recall 0.5849931625164908\n",
      "F1 0.5983821629644462\n",
      "468\n",
      "468\n",
      "71744\n",
      "52473\n",
      "Acc: 0.7313921721677074\n",
      "Prec 0.62022563420264\n",
      "Recall 0.5893615707878322\n",
      "F1 0.6043998357595501\n",
      "Epoch: 954, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52302\n",
      "Acc: 0.7168585526315789\n",
      "Prec 0.6094458826318406\n",
      "Recall 0.5777955618283748\n",
      "F1 0.5931988439290946\n",
      "468\n",
      "468\n",
      "71744\n",
      "52518\n",
      "Acc: 0.7320194023193577\n",
      "Prec 0.620094492631633\n",
      "Recall 0.5950582909661585\n",
      "F1 0.6073184771554472\n",
      "Epoch: 955, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.827s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52323\n",
      "Acc: 0.7171463815789474\n",
      "Prec 0.6086276104961449\n",
      "Recall 0.5811392796422058\n",
      "F1 0.5945659003722272\n",
      "468\n",
      "468\n",
      "71744\n",
      "52503\n",
      "Acc: 0.731810325602141\n",
      "Prec 0.6205669049246135\n",
      "Recall 0.5910272682786891\n",
      "F1 0.6054369865976763\n",
      "Epoch: 956, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.894s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52270\n",
      "Acc: 0.7164199561403509\n",
      "Prec 0.6085731331550697\n",
      "Recall 0.5801957537932859\n",
      "F1 0.5940457419535189\n",
      "468\n",
      "468\n",
      "71744\n",
      "52454\n",
      "Acc: 0.7311273416592329\n",
      "Prec 0.6216851337081043\n",
      "Recall 0.5882480977748922\n",
      "F1 0.6045045921591603\n",
      "Epoch: 957, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52186\n",
      "Acc: 0.7152686403508772\n",
      "Prec 0.6067526231671735\n",
      "Recall 0.5777441612234737\n",
      "F1 0.5918931819172425\n",
      "468\n",
      "468\n",
      "71744\n",
      "52537\n",
      "Acc: 0.7322842328278323\n",
      "Prec 0.6212802814810493\n",
      "Recall 0.5907108444090116\n",
      "F1 0.6056100442465272\n",
      "Epoch: 958, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.896s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52267\n",
      "Acc: 0.7163788377192982\n",
      "Prec 0.6084218173285275\n",
      "Recall 0.5790316576285174\n",
      "F1 0.5933630257603757\n",
      "468\n",
      "468\n",
      "71744\n",
      "52521\n",
      "Acc: 0.7320612176628011\n",
      "Prec 0.6214112722538633\n",
      "Recall 0.5902903256380595\n",
      "F1 0.6054511488506126\n",
      "Epoch: 959, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52256\n",
      "Acc: 0.7162280701754385\n",
      "Prec 0.6081326170188918\n",
      "Recall 0.5780093297152753\n",
      "F1 0.5926884675293654\n",
      "468\n",
      "468\n",
      "71744\n",
      "52509\n",
      "Acc: 0.7318939562890276\n",
      "Prec 0.6209785046557804\n",
      "Recall 0.5918344221426689\n",
      "F1 0.606056294990411\n",
      "Epoch: 960, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.908s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52345\n",
      "Acc: 0.7174479166666666\n",
      "Prec 0.6099185792323263\n",
      "Recall 0.5803048826754631\n",
      "F1 0.5947433249142606\n",
      "468\n",
      "468\n",
      "71744\n",
      "52602\n",
      "Acc: 0.7331902319357716\n",
      "Prec 0.6228022596844777\n",
      "Recall 0.5950535968172278\n",
      "F1 0.6086118036919365\n",
      "Epoch: 961, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52372\n",
      "Acc: 0.7178179824561404\n",
      "Prec 0.6097553441603151\n",
      "Recall 0.5819110768156791\n",
      "F1 0.5955079083689172\n",
      "468\n",
      "468\n",
      "71744\n",
      "52484\n",
      "Acc: 0.7315454950936664\n",
      "Prec 0.6219486943346305\n",
      "Recall 0.589266214859072\n",
      "F1 0.6051665153149111\n",
      "Epoch: 962, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52100\n",
      "Acc: 0.7140899122807017\n",
      "Prec 0.6051328041403933\n",
      "Recall 0.5750170913942042\n",
      "F1 0.5896906931240358\n",
      "468\n",
      "468\n",
      "71744\n",
      "52397\n",
      "Acc: 0.7303328501338091\n",
      "Prec 0.6198597001181347\n",
      "Recall 0.5888242200477908\n",
      "F1 0.6039435097490391\n",
      "Epoch: 963, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51958\n",
      "Acc: 0.7121436403508772\n",
      "Prec 0.6050322994325805\n",
      "Recall 0.5714227068508558\n",
      "F1 0.58774741477987\n",
      "468\n",
      "468\n",
      "71744\n",
      "52434\n",
      "Acc: 0.7308485727029438\n",
      "Prec 0.6204019029084072\n",
      "Recall 0.5907980075669652\n",
      "F1 0.6052381691230212\n",
      "Epoch: 964, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.865s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52322\n",
      "Acc: 0.7171326754385965\n",
      "Prec 0.6105932760103148\n",
      "Recall 0.5797963539245227\n",
      "F1 0.5947964368288213\n",
      "468\n",
      "468\n",
      "71744\n",
      "52492\n",
      "Acc: 0.731657002676182\n",
      "Prec 0.6215687475584489\n",
      "Recall 0.590659766167971\n",
      "F1 0.605720203629938\n",
      "Epoch: 965, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.832s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52134\n",
      "Acc: 0.7145559210526315\n",
      "Prec 0.6073642935126157\n",
      "Recall 0.5777081415356239\n",
      "F1 0.5921651484974207\n",
      "468\n",
      "468\n",
      "71744\n",
      "52429\n",
      "Acc: 0.7307788804638715\n",
      "Prec 0.6204020084622422\n",
      "Recall 0.5894952102171759\n",
      "F1 0.6045538525938411\n",
      "Epoch: 966, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.835s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51966\n",
      "Acc: 0.7122532894736842\n",
      "Prec 0.6027240733549083\n",
      "Recall 0.5713226226344\n",
      "F1 0.5866034110744613\n",
      "468\n",
      "468\n",
      "71744\n",
      "52480\n",
      "Acc: 0.7314897413024085\n",
      "Prec 0.6213696533196263\n",
      "Recall 0.5894963725618493\n",
      "F1 0.6050135173051556\n",
      "Epoch: 967, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52312\n",
      "Acc: 0.7169956140350877\n",
      "Prec 0.6083362863606511\n",
      "Recall 0.579861302348638\n",
      "F1 0.593757594910129\n",
      "468\n",
      "468\n",
      "71744\n",
      "52623\n",
      "Acc: 0.7334829393398751\n",
      "Prec 0.6235877681385343\n",
      "Recall 0.593450430311156\n",
      "F1 0.6081459559938116\n",
      "Epoch: 968, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.831s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52293\n",
      "Acc: 0.7167351973684211\n",
      "Prec 0.6087688620890911\n",
      "Recall 0.5789170107591503\n",
      "F1 0.5934677812386474\n",
      "468\n",
      "468\n",
      "71744\n",
      "52578\n",
      "Acc: 0.7328557091882248\n",
      "Prec 0.62222785371888\n",
      "Recall 0.5925181239682055\n",
      "F1 0.6070096750075344\n",
      "Epoch: 969, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.833s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52236\n",
      "Acc: 0.7159539473684211\n",
      "Prec 0.607598437430066\n",
      "Recall 0.5770345272613276\n",
      "F1 0.5919222030065913\n",
      "468\n",
      "468\n",
      "71744\n",
      "52523\n",
      "Acc: 0.73208909455843\n",
      "Prec 0.6215917118472409\n",
      "Recall 0.592328658225667\n",
      "F1 0.606607473965625\n",
      "Epoch: 970, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.875s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52317\n",
      "Acc: 0.7170641447368421\n",
      "Prec 0.609126780715202\n",
      "Recall 0.579564015960854\n",
      "F1 0.5939777850518965\n",
      "468\n",
      "468\n",
      "71744\n",
      "52552\n",
      "Acc: 0.7324933095450491\n",
      "Prec 0.6209918347695397\n",
      "Recall 0.5943290086082104\n",
      "F1 0.6073679448903477\n",
      "Epoch: 971, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.842s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52238\n",
      "Acc: 0.7159813596491228\n",
      "Prec 0.6073922850282676\n",
      "Recall 0.5781107955185759\n",
      "F1 0.5923899192696573\n",
      "468\n",
      "468\n",
      "71744\n",
      "52668\n",
      "Acc: 0.7341101694915254\n",
      "Prec 0.6241582993558165\n",
      "Recall 0.5955537478254378\n",
      "F1 0.6095206082070761\n",
      "Epoch: 972, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.814s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n",
      "72960\n",
      "52255\n",
      "Acc: 0.7162143640350878\n",
      "Prec 0.6072823477562711\n",
      "Recall 0.5797155850519989\n",
      "F1 0.5931788620530702\n",
      "468\n",
      "468\n",
      "71744\n",
      "52618\n",
      "Acc: 0.7334132471008028\n",
      "Prec 0.6226867554314729\n",
      "Recall 0.592296409131567\n",
      "F1 0.6071115057606407\n",
      "Epoch: 973, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.857s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52303\n",
      "Acc: 0.7168722587719298\n",
      "Prec 0.6090904518358028\n",
      "Recall 0.578505556018465\n",
      "F1 0.5934041680410367\n",
      "468\n",
      "468\n",
      "71744\n",
      "52617\n",
      "Acc: 0.7333993086529884\n",
      "Prec 0.6231081054704327\n",
      "Recall 0.5950011156400353\n",
      "F1 0.6087303363179017\n",
      "Epoch: 974, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.780s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52249\n",
      "Acc: 0.7161321271929825\n",
      "Prec 0.6075640356902138\n",
      "Recall 0.5814138364408757\n",
      "F1 0.5942013643046195\n",
      "468\n",
      "468\n",
      "71744\n",
      "52545\n",
      "Acc: 0.7323957404103479\n",
      "Prec 0.6217471643165834\n",
      "Recall 0.5905537905983513\n",
      "F1 0.6057491635098126\n",
      "Epoch: 975, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.824s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52335\n",
      "Acc: 0.7173108552631579\n",
      "Prec 0.6099560128600283\n",
      "Recall 0.577545452115125\n",
      "F1 0.5933084406341427\n",
      "468\n",
      "468\n",
      "71744\n",
      "52589\n",
      "Acc: 0.7330090321141838\n",
      "Prec 0.622675524166559\n",
      "Recall 0.5927466531819722\n",
      "F1 0.6073426005328175\n",
      "Epoch: 976, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.861s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52259\n",
      "Acc: 0.7162691885964912\n",
      "Prec 0.6068199283584358\n",
      "Recall 0.5820749946201037\n",
      "F1 0.594189948510671\n",
      "468\n",
      "468\n",
      "71744\n",
      "52495\n",
      "Acc: 0.7316988180196253\n",
      "Prec 0.6222480314335573\n",
      "Recall 0.5862560539264737\n",
      "F1 0.6037160815440279\n",
      "Epoch: 977, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.851s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51992\n",
      "Acc: 0.712609649122807\n",
      "Prec 0.6034351330457934\n",
      "Recall 0.5722326769868161\n",
      "F1 0.5874198453406871\n",
      "468\n",
      "468\n",
      "71744\n",
      "52485\n",
      "Acc: 0.7315594335414808\n",
      "Prec 0.6207152272569815\n",
      "Recall 0.5923226463141361\n",
      "F1 0.6061866558773696\n",
      "Epoch: 978, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.830s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52150\n",
      "Acc: 0.7147752192982456\n",
      "Prec 0.606834188601392\n",
      "Recall 0.5772430562505841\n",
      "F1 0.5916688682069917\n",
      "468\n",
      "468\n",
      "71744\n",
      "52386\n",
      "Acc: 0.7301795272078502\n",
      "Prec 0.6178217296557363\n",
      "Recall 0.5934727291603137\n",
      "F1 0.6054025020335988\n",
      "Epoch: 979, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52012\n",
      "Acc: 0.7128837719298246\n",
      "Prec 0.6049408880091484\n",
      "Recall 0.5758713499479937\n",
      "F1 0.5900482983124545\n",
      "468\n",
      "468\n",
      "71744\n",
      "52383\n",
      "Acc: 0.7301377118644068\n",
      "Prec 0.6214650756345991\n",
      "Recall 0.5857136572642795\n",
      "F1 0.603059965176597\n",
      "Epoch: 980, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.859s\n",
      "468\n",
      "468\n",
      "72960\n",
      "51899\n",
      "Acc: 0.7113349780701754\n",
      "Prec 0.6032553645586158\n",
      "Recall 0.5688047511519515\n",
      "F1 0.5855237507349462\n",
      "468\n",
      "468\n",
      "71744\n",
      "52431\n",
      "Acc: 0.7308067573595004\n",
      "Prec 0.6193982372246437\n",
      "Recall 0.5889563303570999\n",
      "F1 0.6037938244493033\n",
      "Epoch: 981, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.834s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52172\n",
      "Acc: 0.715076754385965\n",
      "Prec 0.6068101783031788\n",
      "Recall 0.5757987117572131\n",
      "F1 0.5908978393191218\n",
      "468\n",
      "468\n",
      "71744\n",
      "52598\n",
      "Acc: 0.7331344781445138\n",
      "Prec 0.6213524285996344\n",
      "Recall 0.5954686901714473\n",
      "F1 0.6081352650531678\n",
      "Epoch: 982, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.863s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52345\n",
      "Acc: 0.7174479166666666\n",
      "Prec 0.6093334711439017\n",
      "Recall 0.5803018871290219\n",
      "F1 0.594463439131509\n",
      "468\n",
      "468\n",
      "71744\n",
      "52620\n",
      "Acc: 0.7334411239964318\n",
      "Prec 0.6227358031748768\n",
      "Recall 0.5938761337606567\n",
      "F1 0.6079636734049729\n",
      "Epoch: 983, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.903s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52163\n",
      "Acc: 0.714953399122807\n",
      "Prec 0.605749128394207\n",
      "Recall 0.5792509827064828\n",
      "F1 0.5922037890275361\n",
      "468\n",
      "468\n",
      "71744\n",
      "52529\n",
      "Acc: 0.7321727252453167\n",
      "Prec 0.6223965392712755\n",
      "Recall 0.58949139287326\n",
      "F1 0.6054972462763379\n",
      "Epoch: 984, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.862s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52188\n",
      "Acc: 0.7152960526315789\n",
      "Prec 0.6071286034577056\n",
      "Recall 0.5777390171431379\n",
      "F1 0.5920693190405021\n",
      "468\n",
      "468\n",
      "71744\n",
      "52433\n",
      "Acc: 0.7308346342551294\n",
      "Prec 0.621755127792623\n",
      "Recall 0.5871759306709298\n",
      "F1 0.6039709928125117\n",
      "Epoch: 985, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.889s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52148\n",
      "Acc: 0.7147478070175438\n",
      "Prec 0.6070091612428988\n",
      "Recall 0.5744060574206232\n",
      "F1 0.5902577410881267\n",
      "468\n",
      "468\n",
      "71744\n",
      "52483\n",
      "Acc: 0.7315315566458519\n",
      "Prec 0.6210761982303039\n",
      "Recall 0.5931848364880025\n",
      "F1 0.6068101875299\n",
      "Epoch: 986, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.852s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52235\n",
      "Acc: 0.7159402412280702\n",
      "Prec 0.6065412168420943\n",
      "Recall 0.578276575169244\n",
      "F1 0.5920717597918643\n",
      "468\n",
      "468\n",
      "71744\n",
      "52582\n",
      "Acc: 0.7329114629794826\n",
      "Prec 0.6217321495527717\n",
      "Recall 0.5930083026133816\n",
      "F1 0.6070306229268936\n",
      "Epoch: 987, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.880s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52419\n",
      "Acc: 0.7184621710526315\n",
      "Prec 0.6105958511415294\n",
      "Recall 0.581388708731945\n",
      "F1 0.595634449308535\n",
      "468\n",
      "468\n",
      "71744\n",
      "52628\n",
      "Acc: 0.7335526315789473\n",
      "Prec 0.6233349094134241\n",
      "Recall 0.5951622626367427\n",
      "F1 0.6089228987585843\n",
      "Epoch: 988, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.866s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52316\n",
      "Acc: 0.7170504385964912\n",
      "Prec 0.6089614460520901\n",
      "Recall 0.5802143704532677\n",
      "F1 0.5942404430822582\n",
      "468\n",
      "468\n",
      "71744\n",
      "52557\n",
      "Acc: 0.7325630017841214\n",
      "Prec 0.622506386574322\n",
      "Recall 0.592248072115697\n",
      "F1 0.6070003772217976\n",
      "Epoch: 989, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.877s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52403\n",
      "Acc: 0.7182428728070176\n",
      "Prec 0.6119774999802444\n",
      "Recall 0.5826742432882956\n",
      "F1 0.5969664862076834\n",
      "468\n",
      "468\n",
      "71744\n",
      "52590\n",
      "Acc: 0.7330229705619982\n",
      "Prec 0.6231784260955127\n",
      "Recall 0.5932818671052473\n",
      "F1 0.6078627674740517\n",
      "Epoch: 990, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.873s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52254\n",
      "Acc: 0.7162006578947369\n",
      "Prec 0.609386014123877\n",
      "Recall 0.5775744894396609\n",
      "F1 0.5930539641758645\n",
      "468\n",
      "468\n",
      "71744\n",
      "52630\n",
      "Acc: 0.7335805084745762\n",
      "Prec 0.6236741503240965\n",
      "Recall 0.5957816046953389\n",
      "F1 0.6094088851647925\n",
      "Epoch: 991, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.917s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52326\n",
      "Acc: 0.7171875\n",
      "Prec 0.6091133382944062\n",
      "Recall 0.5822784259786579\n",
      "F1 0.5953936673065373\n",
      "468\n",
      "468\n",
      "71744\n",
      "52596\n",
      "Acc: 0.7331066012488849\n",
      "Prec 0.622346406421408\n",
      "Recall 0.5949407664254404\n",
      "F1 0.6083350852248812\n",
      "Epoch: 992, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.850s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52289\n",
      "Acc: 0.7166803728070176\n",
      "Prec 0.6078277814918326\n",
      "Recall 0.5780875164697716\n",
      "F1 0.5925847372875712\n",
      "468\n",
      "468\n",
      "71744\n",
      "52608\n",
      "Acc: 0.7332738626226584\n",
      "Prec 0.6225729462262534\n",
      "Recall 0.594051559213828\n",
      "F1 0.6079779385937532\n",
      "Epoch: 993, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.864s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52339\n",
      "Acc: 0.7173656798245615\n",
      "Prec 0.6078073320718547\n",
      "Recall 0.5813797508410282\n",
      "F1 0.5942998883131525\n",
      "468\n",
      "468\n",
      "71744\n",
      "52619\n",
      "Acc: 0.7334271855486173\n",
      "Prec 0.6237423253323762\n",
      "Recall 0.5929468147586346\n",
      "F1 0.6079548388314063\n",
      "Epoch: 994, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.837s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52452\n",
      "Acc: 0.7189144736842106\n",
      "Prec 0.6118230365977393\n",
      "Recall 0.582667110135027\n",
      "F1 0.5968892445425857\n",
      "468\n",
      "468\n",
      "71744\n",
      "52643\n",
      "Acc: 0.7337617082961642\n",
      "Prec 0.6234420957771531\n",
      "Recall 0.5952768506546149\n",
      "F1 0.609034016294444\n",
      "Epoch: 995, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.828s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52521\n",
      "Acc: 0.7198601973684211\n",
      "Prec 0.6118432703750548\n",
      "Recall 0.5844769242875645\n",
      "F1 0.5978470887816246\n",
      "468\n",
      "468\n",
      "71744\n",
      "52703\n",
      "Acc: 0.7345980151650312\n",
      "Prec 0.6249525719263103\n",
      "Recall 0.5955898000940232\n",
      "F1 0.6099179936960615\n",
      "Epoch: 996, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.829s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52463\n",
      "Acc: 0.7190652412280701\n",
      "Prec 0.6118667522369217\n",
      "Recall 0.5833058124959657\n",
      "F1 0.5972450231613059\n",
      "468\n",
      "468\n",
      "71744\n",
      "52691\n",
      "Acc: 0.7344307537912578\n",
      "Prec 0.6240396165247895\n",
      "Recall 0.5958524431989064\n",
      "F1 0.6096203794349226\n",
      "Epoch: 997, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.868s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52290\n",
      "Acc: 0.7166940789473685\n",
      "Prec 0.6088207458570774\n",
      "Recall 0.5817803165522094\n",
      "F1 0.5949934657903425\n",
      "468\n",
      "468\n",
      "71744\n",
      "52687\n",
      "Acc: 0.734375\n",
      "Prec 0.6241240025665186\n",
      "Recall 0.5946420192439879\n",
      "F1 0.6090264259147484\n",
      "Epoch: 998, Train loss: 0.001, Val loss: 0.000, Epoch time = 1.849s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52374\n",
      "Acc: 0.7178453947368421\n",
      "Prec 0.6093598213850066\n",
      "Recall 0.5837875965369115\n",
      "F1 0.5962996696118145\n",
      "468\n",
      "468\n",
      "71744\n",
      "52597\n",
      "Acc: 0.7331205396966993\n",
      "Prec 0.6237931497353051\n",
      "Recall 0.5883019226551582\n",
      "F1 0.6055279287698957\n",
      "Epoch: 999, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.874s\n",
      "468\n",
      "468\n",
      "72960\n",
      "52465\n",
      "Acc: 0.7190926535087719\n",
      "Prec 0.6108930151593146\n",
      "Recall 0.5809152661991884\n",
      "F1 0.5955271230637622\n",
      "468\n",
      "468\n",
      "71744\n",
      "52715\n",
      "Acc: 0.7347652765388046\n",
      "Prec 0.6238246381111124\n",
      "Recall 0.5947149895688524\n",
      "F1 0.6089221141759726\n",
      "Epoch: 1000, Train loss: 0.000, Val loss: 0.000, Epoch time = 1.846s\n",
      "best_model_lstm_seq_02_13_2022_42_1\tAcc:0.7334271855486173\tprec:0.6237423253323762\trecall:0.5929468147586346\tf1sc:0.6079548388314063\n"
     ]
    }
   ],
   "source": [
    "MBR_NO=42\n",
    "BRN_NO=1\n",
    "Val_loss=[]\n",
    "Train_loss=[]\n",
    "Accuracy=[]\n",
    "F1score=[]\n",
    "\n",
    "if featnorm==True:\n",
    "    Data_train = load('Data/Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'norm_train.npy',allow_pickle=True)\n",
    "    Data_test =  load('Data/Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'norm_test.npy',allow_pickle=True)\n",
    "else:\n",
    "    Data_train = load('Data/Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'train.npy',allow_pickle=True)\n",
    "    Data_test =  load('Data/Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'test.npy',allow_pickle=True)\n",
    "\n",
    "Xtrain_data,Ytrain_data,Xtest_data,Ytest_data = Data_load(Data_train,Data_test)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = Xtrain_data.shape[1]\n",
    "\n",
    "\n",
    "lstm = RNNModel(rnn_type='LSTM',ntoken=SRC_VOCAB_SIZE,ninp=EMB_SIZE,nhid=FFN_HID_DIM,nlayers=NUM_LAYERS,proj_size=TGT_VOCAB_SIZE,\n",
    "                attention=False)\n",
    "summary = SummaryWriter()\n",
    "for p in lstm.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "lstm = lstm.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "NUM_EPOCHS = 1000\n",
    "best_val_loss=100000000\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss,_ = train_epoch_lstm(lstm, optimizer,Xtrain_data,Ytrain_data,loss_fn,device,BATCH_SIZE,bptt)\n",
    "    end_time = timer()\n",
    "    val_loss,acc,prec,reca,f1sc,confusion = evaluate_lstm(lstm,Xtrain_data,Ytrain_data,loss_fn,device,BATCH_SIZE,bptt)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_confusion=confusion\n",
    "        best_acc=acc\n",
    "        best_prec=prec\n",
    "        best_reca=reca\n",
    "        best_f1sc=f1sc\n",
    "        best_model = lstm\n",
    "    Val_loss.append(val_loss)\n",
    "    Train_loss.append(train_loss)\n",
    "    Accuracy.append(acc)\n",
    "    F1score.append(f1sc)\n",
    "now = datetime.now()\n",
    "now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "date_time = now.strftime(\"%m_%d_%Y\")\n",
    "\n",
    "PATH='best_model_lstm_seq_'+date_time+'_'+str(MBR_NO)+'_'+str(BRN_NO)\n",
    "#     if featnorm==True:\n",
    "#         torch.save(best_model.state_dict(), PATH+'norm')\n",
    "#     else:\n",
    "#         torch.save(best_model.state_dict(), PATH)\n",
    "if featnorm==True:\n",
    "    file_name='results/result_ALSTM_'+date_time+'_norm.txt'\n",
    "else:\n",
    "    file_name='results/result_ALSTM_'+date_time+'.txt'\n",
    "text_to_append=PATH+'\\t'+\"Acc:\"+str(best_acc)+'\\t'+\"prec:\"+str(best_prec)+'\\t'+\"recall:\"+str(best_reca)+'\\t'+\"f1sc:\"+str(best_f1sc)\n",
    "print(text_to_append)\n",
    "with open(file_name, \"a+\") as file_object:\n",
    "    # Move read cursor to the start of file.\n",
    "    file_object.seek(0)\n",
    "    # If file is not empty then append '\\n'\n",
    "    data = file_object.read(100)\n",
    "    if len(data) > 0:\n",
    "        file_object.write(\"\\n\")\n",
    "    # Append text at the end of file\n",
    "    file_object.write(text_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49d4f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Val_loss);\n",
    "plt.plot(Train_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e39892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb8e0086dd0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(F1score)\n",
    "plt.plot(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686a46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Val_loss_LSTM\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(Val_loss, fp)\n",
    "with open(\"Val_loss_LSTM\", \"rb\") as fp:   # Unpickling\n",
    "    Val_loss_ALSTM = pickle.load(fp)\n",
    "    \n",
    "with open(\"Train_loss_LSTM\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(Train_loss, fp)\n",
    "with open(\"Train_loss_LSTM\", \"rb\") as fp:   # Unpickling\n",
    "    Train_loss_ALSTM = pickle.load(fp)\n",
    "    \n",
    "with open(\"Accuracy_LSTM\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(Accuracy, fp)\n",
    "with open(\"Accuracy_LSTM\", \"rb\") as fp:   # Unpickling\n",
    "    Accuracy_ALSTM = pickle.load(fp)\n",
    "    \n",
    "with open(\"F1_LSTM\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(F1score, fp)\n",
    "with open(\"F1_LSTM\", \"rb\") as fp:   # Unpickling\n",
    "    F1_ALSTM = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a2269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"Val_loss_Trans\", \"rb\") as fp:   # Unpickling\n",
    "    Val_loss_Trans = pickle.load(fp)\n",
    "\n",
    "with open(\"Train_loss_Trans\", \"rb\") as fp:   # Unpickling\n",
    "    Train_loss_Trans = pickle.load(fp)\n",
    "    \n",
    "\n",
    "with open(\"Accuracy_Trans\", \"rb\") as fp:   # Unpickling\n",
    "    Accuracy_Trans = pickle.load(fp)\n",
    "    \n",
    "\n",
    "with open(\"F1_Trans\", \"rb\") as fp:   # Unpickling\n",
    "    F1_Trans = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1969e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Val_loss_ALSTM\", \"rb\") as fp:   # Unpickling\n",
    "    Val_loss_ALSTM = pickle.load(fp)\n",
    "\n",
    "with open(\"Train_loss_ALSTM\", \"rb\") as fp:   # Unpickling\n",
    "    Train_loss_ALSTM = pickle.load(fp)\n",
    "    \n",
    "\n",
    "with open(\"Accuracy_ALSTM\", \"rb\") as fp:   # Unpickling\n",
    "    Accuracy_ALSTM = pickle.load(fp)\n",
    "    \n",
    "\n",
    "with open(\"F1_ALSTM\", \"rb\") as fp:   # Unpickling\n",
    "    F1_ALSTM = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e1941eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "# ax.plot(Val_loss);\n",
    "ax.plot(Train_loss);\n",
    "\n",
    "# ax.plot(Val_loss_Trans);\n",
    "ax.plot(Train_loss_Trans);\n",
    "# ax.plot(Val_loss_ALSTM);\n",
    "ax.plot(Train_loss_ALSTM);\n",
    "ax.legend([\"Train_loss_LSTM\",\"Train_loss_Trans\",\"Train_loss_ALSTM\"])\n",
    "fig.savefig('Loss.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb1c875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Accuracy);\n",
    "# plt.plot(F1score);\n",
    "\n",
    "plt.plot(Accuracy_Trans);\n",
    "plt.plot(Accuracy_ALSTM);\n",
    "# plt.plot(F1_Trans);\n",
    "plt.legend([\"Acc_LSTM\",\"Acc_Trans\",\"Acc_ALSTM\"])\n",
    "plt.savefig('Accuracy.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca5a46",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "for MBR_NO,BRN_NO in mbrnlist:\n",
    "    if featnorm==True:\n",
    "        Data_train = load('Data/Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'norm_train.npy',allow_pickle=True)\n",
    "        Data_test =  load('Data/Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'norm_test.npy',allow_pickle=True)\n",
    "    else:\n",
    "        Data_train = load('Data/Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'train.npy',allow_pickle=True)\n",
    "        Data_test =  load('Data/Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'test.npy',allow_pickle=True)\n",
    "\n",
    "    Xtrain_data,Ytrain_data,Xtest_data,Ytest_data = Data_load(Data_train,Data_test)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    SRC_VOCAB_SIZE = Xtrain_data.shape[1]\n",
    "\n",
    "\n",
    "    lstm = RNNModel(rnn_type='LSTM',ntoken=SRC_VOCAB_SIZE,ninp=EMB_SIZE,nhid=FFN_HID_DIM,nlayers=NUM_LAYERS,proj_size=TGT_VOCAB_SIZE,\n",
    "                    attention_width=38)\n",
    "    summary = SummaryWriter()\n",
    "    for p in lstm.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "\n",
    "    lstm = lstm.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(lstm.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "    NUM_EPOCHS = 1000\n",
    "    best_val_loss=100000000\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        start_time = timer()\n",
    "        train_loss,_ = train_epoch_lstm(lstm, optimizer,Xtrain_data,Ytrain_data,loss_fn,device,BATCH_SIZE,bptt)\n",
    "        end_time = timer()\n",
    "        val_loss,acc,prec,reca,f1sc,confusion = evaluate_lstm(lstm,Xtrain_data,Ytrain_data,loss_fn,device,BATCH_SIZE,bptt)\n",
    "        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_confusion=confusion\n",
    "            best_acc=acc\n",
    "            best_prec=prec\n",
    "            best_reca=reca\n",
    "            best_f1sc=f1sc\n",
    "            best_model = lstm\n",
    "        summary.add_scalar('val loss', val_loss, epoch)\n",
    "        summary.add_scalar('total loss', train_loss, epoch)\n",
    "        summary.add_scalar('f1 score', f1sc, epoch)\n",
    "        summary.add_scalar('Accuracy', acc, epoch)\n",
    "    now = datetime.now()\n",
    "    now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    date_time = now.strftime(\"%m_%d_%Y\")\n",
    "\n",
    "    PATH='best_model_alstm_seq_'+date_time+'_'+str(MBR_NO)+'_'+str(BRN_NO)\n",
    "#     if featnorm==True:\n",
    "#         torch.save(best_model.state_dict(), PATH+'norm')\n",
    "#     else:\n",
    "#         torch.save(best_model.state_dict(), PATH)\n",
    "    if featnorm==True:\n",
    "        file_name='results/result_ALSTM_'+date_time+'_norm.txt'\n",
    "    else:\n",
    "        file_name='results/result_ALSTM_'+date_time+'.txt'\n",
    "    text_to_append=PATH+'\\t'+\"Acc:\"+str(best_acc)+'\\t'+\"prec:\"+str(best_prec)+'\\t'+\"recall:\"+str(best_reca)+'\\t'+\"f1sc:\"+str(best_f1sc)\n",
    "    print(text_to_append)\n",
    "    with open(file_name, \"a+\") as file_object:\n",
    "        # Move read cursor to the start of file.\n",
    "        file_object.seek(0)\n",
    "        # If file is not empty then append '\\n'\n",
    "        data = file_object.read(100)\n",
    "        if len(data) > 0:\n",
    "            file_object.write(\"\\n\")\n",
    "        # Append text at the end of file\n",
    "        file_object.write(text_to_append)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
