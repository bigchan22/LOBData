{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5258cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-555b6d1d105a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtst\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOZELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tst'"
     ]
    }
   ],
   "source": [
    "### 필요 라이브러리\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import math\n",
    "import warnings\n",
    "# warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import json\n",
    "from typing import Optional\n",
    "from numpy import load\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import threading\n",
    "from os import makedirs, path, remove\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from tst import Transformer\n",
    "from tst.loss import OZELoss\n",
    "\n",
    "from src.dataset import OzeDataset\n",
    "from src.utils import compute_loss\n",
    "from src.visualization import map_plot_function, plot_values_distribution, plot_error_distribution, plot_errors_threshold, plot_visual_sample\n",
    "from lxml import html\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0aee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b9f53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load array\n",
    "x = load('xdata.npy')\n",
    "y = load('ydata.npy')\n",
    "# print the array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335104a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LOBDataset(Dataset):\n",
    "    \"\"\"Torch dataset for Oze datachallenge.\n",
    "\n",
    "    Load dataset from a single npz file.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    labels: :py:class:`dict`\n",
    "        Ordered labels list for R, Z and X.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    dataset_path:\n",
    "        Path to the dataset inputs as npz.\n",
    "    labels_path:\n",
    "        Path to the labels, divided in R, Z and X, in json format.\n",
    "        Default is \"labels.json\".\n",
    "    normalize:\n",
    "        Data normalization method, one of ``'mean'``, ``'max'`` or ``None``.\n",
    "        Default is ``'max'``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 X: np.array,Y: np.array,\n",
    "                 **kwargs):\n",
    "        \"\"\"Load dataset from npz.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self._x=torch.Tensor(X)\n",
    "        self._y=torch.Tensor(Y)\n",
    "\n",
    "\n",
    "\n",
    "    def _load_npz(self, dataset_path, labels_path):\n",
    "        # Load dataset as csv\n",
    "        dataset = np.load(dataset_path)\n",
    "\n",
    "        # Load labels, can be found through csv or challenge description\n",
    "        with open(labels_path, \"r\") as stream_json:\n",
    "            self.labels = json.load(stream_json)\n",
    "\n",
    "        R = dataset['R'].astype(np.float32)\n",
    "        X = dataset['X'].astype(np.float32)\n",
    "        Z = dataset['Z'].astype(np.float32)\n",
    "\n",
    "        m = Z.shape[0]  # Number of training example\n",
    "        K = Z.shape[1]  # Time serie length\n",
    "\n",
    "        R = np.tile(R[:, np.newaxis, :], (1, K, 1))\n",
    "\n",
    "        # Store R, Z and X as x and y\n",
    "        #self._x = np.concatenate([Z, R], axis=-1)\n",
    "        self._x = Z\n",
    "        self._y = X\n",
    "\n",
    "        # Normalize\n",
    "        if self._normalize == \"mean\":\n",
    "            mean = np.mean(self._x, axis=(0, 1))\n",
    "            std = np.std(self._x, axis=(0, 1))\n",
    "            self._x = (self._x - mean) / (std + np.finfo(float).eps)\n",
    "\n",
    "            self._mean = np.mean(self._y, axis=(0, 1))\n",
    "            self._std = np.std(self._y, axis=(0, 1))\n",
    "            self._y = (self._y - self._mean) / (self._std + np.finfo(float).eps)\n",
    "        elif self._normalize == \"max\":\n",
    "            M = np.max(self._x, axis=(0, 1))\n",
    "            m = np.min(self._x, axis=(0, 1))\n",
    "            self._x = (self._x - m) / (M - m + np.finfo(float).eps)\n",
    "\n",
    "            self._M = np.max(self._y, axis=(0, 1))\n",
    "            self._m = np.min(self._y, axis=(0, 1))\n",
    "            self._y = (self._y - self._m) / (self._M - self._m + np.finfo(float).eps)\n",
    "        elif self._normalize is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise(\n",
    "                NameError(f'Normalize method \"{self._normalize}\" not understood.'))\n",
    "\n",
    "        # Convert to float32\n",
    "        self._x = torch.Tensor(self._x)\n",
    "        self._y = torch.Tensor(self._y)\n",
    "\n",
    "    def rescale(self,\n",
    "                y: np.ndarray,\n",
    "                idx_label: int) -> torch.Tensor:\n",
    "        \"\"\"Rescale output from initial normalization.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        y:\n",
    "            Array to resize, of shape (K,).\n",
    "        idx_label:\n",
    "            Index of the output label.\n",
    "        \"\"\"\n",
    "        if self._normalize == \"max\":\n",
    "            return y * (self._M[idx_label] - self._m[idx_label] + np.finfo(float).eps) + self._m[idx_label]\n",
    "        elif self._normalize == \"mean\":\n",
    "            return y * (self._std[idx_label] + np.finfo(float).eps) + self._mean[idx_label]\n",
    "        else:\n",
    "            raise(\n",
    "                NameError(f'Normalize method \"{self._normalize}\" not understood.'))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return (self._x[idx], self._y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._x.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81385194",
   "metadata": {},
   "outputs": [],
   "source": [
    "lobdata=LOBDataset(x,y)\n",
    "\n",
    "\n",
    "dataset_train, dataset_test = random_split(lobdata, (180, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60ab3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "dataloader_test = DataLoader(dataset_test,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9011b536",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f8e11eb0a885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load transformer with Adam optimizer and MSE loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOZELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Transformer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load transformer with Adam optimizer and MSE loss function\n",
    "net = Transformer(d_input, d_model, d_output, q, v, h, N, attention_size=attention_size, dropout=dropout, chunk_mode=chunk_mode, pe=pe).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "loss_function = OZELoss(alpha=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
