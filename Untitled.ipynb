{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845bc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import yaml\n",
    "\n",
    "from argparse import Namespace\n",
    "from timeit import default_timer as timer\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from source.transformer import Seq2SeqTransformer\n",
    "from source.train import train_epoch, evaluate\n",
    "from source.Attention_LSTM import RNNModel\n",
    "from source.train import train_epoch_lstm, evaluate_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0f04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return Namespace(**config)\n",
    "\n",
    "config_file = \"Train_info.yaml\"\n",
    "args = load_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18068f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modeltype = args.model\n",
    "if modeltype not in ['Trans', 'ALSTM', 'LSTM']:\n",
    "    raise ValueError\n",
    "\n",
    "datasubfix = args.data\n",
    "\n",
    "if args.trainname:\n",
    "    trainname = args.trainname\n",
    "else:\n",
    "    now = datetime.now()\n",
    "    now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    date_time = now.strftime(\"%m_%d_%Y\")\n",
    "    trainname = date_time\n",
    "device = args.device\n",
    "\n",
    "\n",
    "num_epochs = args.epoch\n",
    "seq_length = 39\n",
    "TGT_VOCAB_SIZE = 3\n",
    "EMB_SIZE = args.emb_dim\n",
    "NHEAD = args.num_head\n",
    "FFN_HID_DIM = args.hid_dim\n",
    "BATCH_SIZE = args.batch_size\n",
    "lr_init = args.lr_initial\n",
    "NUM_ENCODER_LAYERS = args.num_layers // 2\n",
    "NUM_DECODER_LAYERS = args.num_layers // 2\n",
    "NUM_LAYERS = args.num_layers\n",
    "train_data_path = os.path.join('/Data/LOBData/TrainData',args.data)\n",
    "train_data_info_path = os.path.join(train_data_path,\"config.yaml\")\n",
    "train_data_config = load_config(train_data_info_path)\n",
    "mbrnlist = train_data_config.MBRNlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87da8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASK_STEP1_BSTORD_RQTY',\n",
       " 'ASK_STEP2_BSTORD_RQTY',\n",
       " 'ASK_STEP3_BSTORD_RQTY',\n",
       " 'ASK_STEP4_BSTORD_RQTY',\n",
       " 'ASK_STEP5_BSTORD_RQTY',\n",
       " 'BID_STEP1_BSTORD_RQTY',\n",
       " 'BID_STEP2_BSTORD_RQTY',\n",
       " 'BID_STEP3_BSTORD_RQTY',\n",
       " 'BID_STEP4_BSTORD_RQTY',\n",
       " 'BID_STEP5_BSTORD_RQTY',\n",
       " '매도5단계호가합계잔량',\n",
       " '매수5단계호가합계잔량',\n",
       " '매도10단계호가합계잔량',\n",
       " '매수10단계호가합계잔량',\n",
       " '매도총호가잔량',\n",
       " '매수총호가잔량',\n",
       " '고가',\n",
       " '저가',\n",
       " '시가',\n",
       " '직전체결가격',\n",
       " 'NEW_ASK_QTY',\n",
       " 'CCL_ASK_QTY',\n",
       " 'NEW_BID_QTY',\n",
       " 'CCL_BID_QTY']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_config.feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9388bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x,y):\n",
    "    x = x[:,:-4]\n",
    "    x = torch.FloatTensor(x)\n",
    "    y = torch.FloatTensor(y)\n",
    "    y[-1]=0\n",
    "    return x,y\n",
    "\n",
    "class TimeSeriesNpyDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, seq_length, transform=None):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.seq_length = seq_length\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x_data) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample = self.x_data[idx:idx + self.seq_length]\n",
    "        y_sample = self.y_data[idx + 1:idx + self.seq_length + 1]\n",
    "\n",
    "        # Set the last value of y_sample to 0\n",
    "        y_sample[-1] = 0\n",
    "\n",
    "        if self.transform:\n",
    "            x_sample,y_sample = self.transform(x_sample,y_sample)\n",
    "\n",
    "        return x_sample, y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c169abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(XData, YData,seq_length, train_ratio=0.9):\n",
    "    data_len = len(XData) // seq_length\n",
    "    split_idx = int(data_len * train_ratio)\n",
    "    X_train = XData[:split_idx * seq_length]\n",
    "    Y_train = YData[:split_idx * seq_length]\n",
    "    X_test = XData[split_idx * seq_length:]\n",
    "    Y_test = YData[split_idx * seq_length:]\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "def check_inf(data, idx, mbr=None, brn=None, dataname=None):\n",
    "    if np.isinf(data[seq_length * idx:seq_length * (idx + 1)].tolist()).any():\n",
    "        print(np.isinf(data[seq_length * idx:seq_length * (idx + 1)].tolist()).any())\n",
    "        print(mbr, brn)\n",
    "        print(dataname)\n",
    "        print(data[seq_length * idx:seq_length * (idx + 1)].tolist())\n",
    "        raise RuntimeError\n",
    "\n",
    "def generate_square_subsequent_mask(sz, device):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "def generate_square_subsequent_mask3(sz, device):\n",
    "    mask = (torch.triu(torch.ones((sz, sz - 1), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "def create_mask(src, tgt, device):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.double)\n",
    "    src_mask = generate_square_subsequent_mask(src_seq_len, device)\n",
    "    mmr_mask = generate_square_subsequent_mask3(src_seq_len, device)\n",
    "    return src_mask, tgt_mask, mmr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7c1265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "torch.Size([2, 39, 24])\n",
      "torch.Size([2, 39, 4])\n",
      "Tensor data type: torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (39) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5c3c2dd0049b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmr_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Tensor data type: {src_mask.dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Min/LOBData/source/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, src_mask, tgt_mask, memory_mask)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 memory_mask: Tensor):\n\u001b[1;32m     72\u001b[0m         \u001b[0msrc_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_tok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtgt_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_tok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Min/LOBData/source/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_embedding)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embedding\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtoken_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (39) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "mbr,brn=mbrnlist[0]\n",
    "\n",
    "# Paths to your .npy files\n",
    "x_data_file = os.path.join(train_data_path,f\"Input_{mbr}_{brn}.npy\")\n",
    "y_data_file = os.path.join(train_data_path,f\"Label_{mbr}_{brn}.npy\")\n",
    "\n",
    "XData = np.load(x_data_file)\n",
    "YData = np.load(y_data_file)\n",
    "X_train, Y_train, X_test, Y_test = split_data(XData, YData,seq_length)\n",
    "\n",
    "# Create the train and test datasets and data loaders\n",
    "train_dataset = TimeSeriesNpyDataset(X_train, Y_train, seq_length, transform=transform)\n",
    "test_dataset = TimeSeriesNpyDataset(X_test, Y_test, seq_length, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2,shuffle=False, num_workers=2)\n",
    "\n",
    "SRC_VOCAB_SIZE = X_train.shape[1]\n",
    "print(SRC_VOCAB_SIZE)\n",
    "\n",
    "model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                   NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "model = model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "summary = SummaryWriter()\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_init, betas=(0.9, 0.98), eps=1e-9)\n",
    "# Iterate over the data loader to get sequences\n",
    "for batch_idx, (x_sequence, y_sequence) in enumerate(train_dataloader):\n",
    "    x_sequence ,y_sequence = x_sequence.to(device), y_sequence.to(device)\n",
    "    \n",
    "    src_input=x_sequence\n",
    "    tgt_input=y_sequence\n",
    "    print(src_input.shape)\n",
    "    print(tgt_input.shape)\n",
    "    src_mask, tgt_mask, mmr_mask = create_mask(src_input, tgt_input, device)\n",
    "    print(f\"Tensor data type: {src_mask.dtype}\")\n",
    "    logits = model(src_input, tgt_input, src_mask, tgt_mask,src_mask)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    tgt_out = tgt[1:]\n",
    "    loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46157d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mbr, brn in mbrnlist:\n",
    "    print(mbr,brn)\n",
    "\n",
    "    # Paths to your .npy files\n",
    "    x_data_file = os.path.join(train_data_path,f\"Input_{mbr}_{brn}.npy\")\n",
    "    y_data_file = os.path.join(train_data_path,f\"Label_{mbr}_{brn}.npy\")\n",
    "\n",
    "    XData = np.load(x_data_file)\n",
    "    YData = np.load(y_data_file)\n",
    "    X_train, Y_train, X_test, Y_test = split_data(XData, YData)\n",
    "\n",
    "    # Create the train and test datasets and data loaders\n",
    "    train_dataset = TimeSeriesNpyDataset(X_train, Y_train, seq_length)\n",
    "    test_dataset = TimeSeriesNpyDataset(X_test, Y_test, seq_length)\n",
    "    \n",
    "    \n",
    "    # Iterate over the data loader to get sequences\n",
    "    for batch_idx, (x_sequence, y_sequence) in enumerate(train_dataloader):\n",
    "        # Perform your machine learning tasks here\n",
    "        if device == None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        SRC_VOCAB_SIZE = Xtrain_data.shape[1]\n",
    "\n",
    "        if modeltype == 'Trans':\n",
    "            model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                       NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "        if modeltype == \"ALSTM\":\n",
    "            model = RNNModel(rnn_type='LSTM', ntoken=SRC_VOCAB_SIZE, ninp=EMB_SIZE, nhid=FFN_HID_DIM, nlayers=NUM_LAYERS,\n",
    "                             proj_size=TGT_VOCAB_SIZE,\n",
    "                             attention_width=39)\n",
    "        if modeltype == \"LSTM\":\n",
    "            model = RNNModel(rnn_type='LSTM', ntoken=SRC_VOCAB_SIZE, ninp=EMB_SIZE, nhid=FFN_HID_DIM, nlayers=NUM_LAYERS,\n",
    "                             proj_size=TGT_VOCAB_SIZE,\n",
    "                             attention=False)\n",
    "        \n",
    "        summary = SummaryWriter()\n",
    "        for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr_init, betas=(0.9, 0.98), eps=1e-9)\n",
    "        \n",
    "        \n",
    "        print(x_sequence)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9898da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sequence.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
