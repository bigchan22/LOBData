{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b9e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from numpy import load\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from timeit import default_timer as timer\n",
    "import time\n",
    "\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966444f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class Seq2SeqRegression(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 num_layers: int,\n",
    "                 emb_size:int,\n",
    "                 proj_size:int):\n",
    "        \n",
    "        super(Seq2SeqRegression, self).__init__()\n",
    "        self.generator = nn.Linear(emb_size, proj_size)\n",
    "        self.src_tok_emb = nn.Linear(input_size, emb_size)\n",
    "        self.bn1=nn.BatchNorm1d(BATCH_SIZE)\n",
    "    def forward(self,\n",
    "                src: Tensor):\n",
    "\n",
    "        src_emb = self.src_tok_emb(src)\n",
    "        outs=self.bn1(src_emb)\n",
    "        return self.generator(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001b8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "def generate_square_subsequent_mask2(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1)\n",
    "    mask = mask.float().masked_fill(mask == 1, float('-inf')).masked_fill(mask == 0, float(0.0))\n",
    "    return mask\n",
    "def generate_square_subsequent_mask3(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz-1), device=DEVICE)) == 1).transpose(0,1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "    src_mask = generate_square_subsequent_mask(src_seq_len)\n",
    "    mmr_mask = generate_square_subsequent_mask3(src_seq_len)\n",
    "    return src_mask, tgt_mask ,mmr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98024906",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def batchify(data, bsz):\n",
    "#     # 데이터셋을 bsz 파트들로 나눕니다.\n",
    "#     nbatch = data.size(0) // bsz\n",
    "#     # 깔끔하게 나누어 떨어지지 않는 추가적인 부분(나머지들) 은 잘라냅니다.\n",
    "#     data = data.narrow(0, 0, nbatch * bsz)\n",
    "#     # 데이터에 대하여 bsz 배치들로 동등하게 나눕니다.\n",
    "#     data = data.view(bsz, -1,data.size(1)).transpose(0,1).contiguous()\n",
    "#     return data.to(device)\n",
    "\n",
    "def batchify(data, bsz,bptt):\n",
    "    # 데이터셋을 bsz 파트들로 나눕니다.\n",
    "    if(data.size(0)%(bsz*bptt)!=0):\n",
    "        data=data.view(-1,bptt,data.size(1)).transpose(0,1).contiguous()\n",
    "        return data.to(device)\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # 깔끔하게 나누어 떨어지지 않는 추가적인 부분(나머지들) 은 잘라냅니다.\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # 데이터에 대하여 bsz 배치들로 동등하게 나눕니다.\n",
    "    data = data.view(bsz, -1,data.size(1)).transpose(0,1).contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "\n",
    "bptt = 39\n",
    "def get_batch(source, i,bs):\n",
    "    seq_len = min(bptt*bs, len(source)  - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    if(seq_len!=bptt*bs):\n",
    "        print(seq_len)\n",
    "    target = source[i:i+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789f9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    total=0\n",
    "    correct=0\n",
    "    correct1=0\n",
    "    tot1=0\n",
    "    correct2=0\n",
    "    tot2=0\n",
    "    correct0=0\n",
    "    tot0=0\n",
    "    conf00=0\n",
    "    conf01=0\n",
    "    conf02=0\n",
    "    conf10=0\n",
    "    conf11=0\n",
    "    conf12=0\n",
    "    conf20=0\n",
    "    conf21=0\n",
    "    conf22=0\n",
    "    \n",
    "    \n",
    "#     for batch, i in enumerate(range(0, Xtrain_data.size(0) - 1, BATCH_SIZE*bptt)):\n",
    "    i=0\n",
    "    while(i<Xtest_data.size(0)):\n",
    "        data, org_targets = get_batch(Xtrain_data, i,BATCH_SIZE)\n",
    "        if (data.isnan().any() or data.isinf().any()):\n",
    "#            print(data)\n",
    "            continue\n",
    "#         _,targets = get_batch(Ytrain_data,i)\n",
    "        targets,_ = get_batch(Ytrain_data,i,BATCH_SIZE)\n",
    "        targets=torch.unsqueeze(targets,1)\n",
    "        src=batchify(data,BATCH_SIZE,bptt)\n",
    "        tgt=batchify(targets,BATCH_SIZE,bptt)\n",
    "        logits = model(src)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        \n",
    "        _,predicted=torch.max(logits,-1)\n",
    "#         print(logits)\n",
    "#         print(logits.size())\n",
    "#         print(\"predicted\",predicted)\n",
    "#         print(\"tgt\",tgt.squeeze())\n",
    "#         print(predicted.size())\n",
    "        correct += (tgt.squeeze() == predicted).sum().item()\n",
    "        total+=len(predicted)*BATCH_SIZE\n",
    "        tot0+=(0== tgt.squeeze()).sum().item()\n",
    "        tot1+=(1== tgt.squeeze()).sum().item()\n",
    "        tot2+=(2== tgt.squeeze()).sum().item()\n",
    "        correct0+=((0== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "        correct1+=((1== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "        correct2+=((2== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "        \n",
    "        conf00+=((0== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "        conf01+=((0== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "        conf02+=((0== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "        conf10+=((1== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "        conf11+=((1== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "        conf12+=((1== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "        conf20+=((2== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "        conf21+=((2== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "        conf22+=((2== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        i+=targets.size()[0]\n",
    "\n",
    "    tp0=conf00\n",
    "    fp0=conf01+conf02\n",
    "    fn0=conf10+conf20\n",
    "    if(tp0+fp0==0):\n",
    "        prec0=0\n",
    "    else:\n",
    "        prec0=tp0/(tp0+fp0)\n",
    "    if(tp0+fn0==0):\n",
    "        reca0=0\n",
    "    else:\n",
    "        reca0=tp0/(tp0+fn0)\n",
    "    \n",
    "    tp1=conf11\n",
    "    fp1=conf10+conf12\n",
    "    fn1=conf01+conf21\n",
    "    \n",
    "    if(tp1+fp1==0):\n",
    "        prec1=0\n",
    "    else:\n",
    "        prec1=tp1/(tp1+fp1)\n",
    "    if(tp1+fn1==0):\n",
    "        reca1=0\n",
    "    else:\n",
    "        reca1=tp1/(tp1+fn1)\n",
    "    \n",
    "    tp2=conf22\n",
    "    fp2=conf20+conf21\n",
    "    fn2=conf02+conf12\n",
    "    \n",
    "    if(tp2+fp2==0):\n",
    "        prec2=0\n",
    "    else:\n",
    "        prec2=tp2/(tp2+fp2)\n",
    "    if(tp2+fn2==0):\n",
    "        reca2=0\n",
    "    else:\n",
    "        reca2=tp2/(tp2+fn2)\n",
    "        \n",
    "    prec=(prec0+prec1+prec2)/3\n",
    "    reca=(reca0+reca1+reca2)/3\n",
    "    if(prec+reca==0):\n",
    "        f1sc=0\n",
    "    else:\n",
    "        f1sc=2*(prec*reca)/(prec+reca)\n",
    "    print(total)\n",
    "    print(correct)\n",
    "    print(\"Acc:\",correct/total)            \n",
    "    print(\"Prec\",prec)\n",
    "    print(\"Recall\",reca)\n",
    "    print(\"F1\",f1sc) \n",
    "    return losses / Xtrain_data.size(0),[conf00,conf01,conf02,conf10,conf11,conf12,conf20,conf21,conf22]\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    total=0\n",
    "    correct=0\n",
    "    correct1=0\n",
    "    tot1=0\n",
    "    correct2=0\n",
    "    tot2=0\n",
    "    correct0=0\n",
    "    tot0=0\n",
    "    conf00=0\n",
    "    conf01=0\n",
    "    conf02=0\n",
    "    conf10=0\n",
    "    conf11=0\n",
    "    conf12=0\n",
    "    conf20=0\n",
    "    conf21=0\n",
    "    conf22=0\n",
    "    stime=time.time()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        i=0\n",
    "        while(i<Xtest_data.size(0)):\n",
    "            data, org_targets = get_batch(Xtest_data, i,BATCH_SIZE)\n",
    "            if (data.isnan().any() or data.isinf().any()):\n",
    "                print(data)\n",
    "                continue\n",
    "            targets,_ = get_batch(Ytest_data,i,BATCH_SIZE)\n",
    "            targets=torch.unsqueeze(targets,1)\n",
    "            src=batchify(data,BATCH_SIZE,bptt)\n",
    "            tgt=batchify(targets,BATCH_SIZE,bptt)\n",
    "#             print(src.shape)\n",
    "            if(src.shape[1]!=BATCH_SIZE):\n",
    "#                 print(\"Something wrong\")\n",
    "                break\n",
    "#             print(tgt.shape)\n",
    "#             src=src[:-1]\n",
    "#             tgt=tgt[1:]\n",
    "\n",
    "\n",
    "            logits = model(src)\n",
    "#            print(logits.reshape(-1, logits.shape[-1]).shape,'AA')\n",
    "#            print(tgt.reshape(-1).shape,'BB')\n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt.reshape(-1))\n",
    "            if(loss.isnan()):\n",
    "                print(src,tgt_input)\n",
    "                break\n",
    "            losses += loss.item()\n",
    "            _,predicted=torch.max(logits,-1)\n",
    "\n",
    "            \n",
    "            correct += (tgt.squeeze() == predicted).sum().item()\n",
    "            total+=len(predicted)*BATCH_SIZE\n",
    "            tot0+=(0== tgt.squeeze()).sum().item()\n",
    "            tot1+=(1== tgt.squeeze()).sum().item()\n",
    "            tot2+=(2== tgt.squeeze()).sum().item()\n",
    "            correct0+=((0== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "            correct1+=((1== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "            correct2+=((2== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "            \n",
    "            conf00+=((0== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "            conf01+=((0== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "            conf02+=((0== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "            conf10+=((1== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "            conf11+=((1== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "            conf12+=((1== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "            conf20+=((2== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "            conf21+=((2== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "            conf22+=((2== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "            \n",
    "            i+=targets.size()[0]\n",
    "    etime=time.time()\n",
    "    print(\"Time elapsed\",etime-stime)\n",
    "#     print(total,tot0,tot1,tot2)\n",
    "#     print(correct)\n",
    "    tp0=conf00\n",
    "    fp0=conf01+conf02\n",
    "    fn0=conf10+conf20\n",
    "    if(tp0+fp0==0):\n",
    "        prec0=0\n",
    "    else:\n",
    "        prec0=tp0/(tp0+fp0)\n",
    "    if(tp0+fn0==0):\n",
    "        reca0=0\n",
    "    else:\n",
    "        reca0=tp0/(tp0+fn0)\n",
    "    \n",
    "    tp1=conf11\n",
    "    fp1=conf10+conf12\n",
    "    fn1=conf01+conf21\n",
    "    \n",
    "    if(tp1+fp1==0):\n",
    "        prec1=0\n",
    "    else:\n",
    "        prec1=tp1/(tp1+fp1)\n",
    "    if(tp1+fn1==0):\n",
    "        reca1=0\n",
    "    else:\n",
    "        reca1=tp1/(tp1+fn1)\n",
    "    \n",
    "    tp2=conf22\n",
    "    fp2=conf20+conf21\n",
    "    fn2=conf02+conf12\n",
    "    \n",
    "    if(tp2+fp2==0):\n",
    "        prec2=0\n",
    "    else:\n",
    "        prec2=tp2/(tp2+fp2)\n",
    "    if(tp2+fn2==0):\n",
    "        reca2=0\n",
    "    else:\n",
    "        reca2=tp2/(tp2+fn2)\n",
    "    \n",
    "    prec=(prec0+prec1+prec2)/3\n",
    "    reca=(reca0+reca1+reca2)/3\n",
    "    if(prec+reca==0):\n",
    "        f1sc=0\n",
    "    else:\n",
    "        f1sc=2*(prec*reca)/(prec+reca)\n",
    "    print(total)\n",
    "    print(correct)\n",
    "    print(\"Acc:\",correct/total)            \n",
    "    print(\"Prec\",prec)\n",
    "    print(\"Recall\",reca)\n",
    "    print(\"F1\",f1sc)\n",
    "    return losses / Xtest_data.size(0),correct/total,prec,reca,f1sc,[conf00,conf01,conf02,conf10,conf11,conf12,conf20,conf21,conf22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b6d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbrnlist1=[(5,194),(2,155),(12,100),(17,29),(42,1),(44,1),(50,92),(2,83),(4,10118),(8,298)]\n",
    "mbrnlist2=[(5,194),(12,100),(2,155),(17,29),(42,1),(44,1),(2,83),(4,10118),(4,9997),(50,91)]\n",
    "\n",
    "mbrnlist=mbrnlist1+mbrnlist2\n",
    "mbrnlist=set(mbrnlist)\n",
    "mbrnlist=list(mbrnlist)\n",
    "\n",
    "# load array\n",
    "MBR_NO,BRN_NO=mbrnlist[2]\n",
    "featnorm=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75078970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2785717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21883765070020436\n",
      "Recall 0.294195743755925\n",
      "F1 0.25098212360151273\n",
      "312\n",
      "312\n",
      "Time elapsed 0.015231609344482422\n",
      "7488\n",
      "3979\n",
      "Acc: 0.5313835470085471\n",
      "Prec 0.21036214644462067\n",
      "Recall 0.3333333333333333\n",
      "F1 0.25794113833787113\n",
      "Epoch: 1, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.494s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21883765070020436\n",
      "Recall 0.294195743755925\n",
      "F1 0.25098212360151273\n",
      "312\n",
      "312\n",
      "Time elapsed 0.016574859619140625\n",
      "7488\n",
      "3931\n",
      "Acc: 0.5249732905982906\n",
      "Prec 0.21019142337717892\n",
      "Recall 0.329312222501466\n",
      "F1 0.2566010640033944\n",
      "Epoch: 2, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.049s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.2187996891035531\n",
      "Recall 0.294195743755925\n",
      "F1 0.2509571553515855\n",
      "312\n",
      "312\n",
      "Time elapsed 0.017729759216308594\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20981278244028403\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25552825552825553\n",
      "Epoch: 3, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.047s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21876174107678162\n",
      "Recall 0.294195743755925\n",
      "F1 0.2509321923333061\n",
      "312\n",
      "312\n",
      "Time elapsed 0.016675472259521484\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20981278244028403\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25552825552825553\n",
      "Epoch: 4, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.039s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21872380661312962\n",
      "Recall 0.294195743755925\n",
      "F1 0.2509072345453689\n",
      "312\n",
      "312\n",
      "Time elapsed 0.024590015411376953\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20981278244028403\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25552825552825553\n",
      "Epoch: 5, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.037s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21876174107678162\n",
      "Recall 0.294195743755925\n",
      "F1 0.2509321923333061\n",
      "312\n",
      "312\n",
      "Time elapsed 0.024951934814453125\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20981278244028403\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25552825552825553\n",
      "Epoch: 6, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.040s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21868564681740907\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508821247823929\n",
      "312\n",
      "312\n",
      "Time elapsed 0.030681610107421875\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20981278244028403\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25552825552825553\n",
      "Epoch: 7, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.034s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21868564681740907\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508821247823929\n",
      "312\n",
      "312\n",
      "Time elapsed 0.014482498168945312\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20981278244028403\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25552825552825553\n",
      "Epoch: 8, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.033s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21864750036894132\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508570200673358\n",
      "312\n",
      "312\n",
      "Time elapsed 0.01342320442199707\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20981278244028403\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25552825552825553\n",
      "Epoch: 9, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.029s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21864750036894132\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508570200673358\n",
      "312\n",
      "312\n",
      "Time elapsed 0.022365093231201172\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20981278244028403\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25552825552825553\n",
      "Epoch: 10, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.042s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21864750036894132\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508570200673358\n",
      "312\n",
      "312\n",
      "Time elapsed 0.013195991516113281\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.2097789252864289\n",
      "Recall 0.3267152550892184\n",
      "F1 0.255503144654088\n",
      "Epoch: 11, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.032s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21864750036894132\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508570200673358\n",
      "312\n",
      "312\n",
      "Time elapsed 0.025066614151000977\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20974507905776055\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25547803871474895\n",
      "Epoch: 12, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.049s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21864750036894132\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508570200673358\n",
      "312\n",
      "312\n",
      "Time elapsed 0.014090776443481445\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20974507905776055\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25547803871474895\n",
      "Epoch: 13, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.032s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21864750036894132\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508570200673358\n",
      "312\n",
      "312\n",
      "Time elapsed 0.02627110481262207\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20974507905776055\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25547803871474895\n",
      "Epoch: 14, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.053s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21864750036894132\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508570200673358\n",
      "312\n",
      "312\n",
      "Time elapsed 0.015581846237182617\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20974507905776055\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25547803871474895\n",
      "Epoch: 15, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.045s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21860960614915784\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508320776495232\n",
      "312\n",
      "312\n",
      "Time elapsed 0.013862848281860352\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20974507905776055\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25547803871474895\n",
      "Epoch: 16, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.029s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21860960614915784\n",
      "Recall 0.294195743755925\n",
      "F1 0.2508320776495232\n",
      "312\n",
      "312\n",
      "Time elapsed 0.015544891357421875\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20971124374899178\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2554529377087837\n",
      "Epoch: 17, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.043s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.017791032791137695\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20964360587002095\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2554027504911591\n",
      "Epoch: 18, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.032s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.014580965042114258\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20964360587002095\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2554027504911591\n",
      "Epoch: 19, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.029s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.019468069076538086\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20964360587002095\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2554027504911591\n",
      "Epoch: 20, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.042s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.013850688934326172\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20964360587002095\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2554027504911591\n",
      "Epoch: 21, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.029s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.013412714004516602\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20960980328926151\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2553776642765937\n",
      "Epoch: 22, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.029s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.013846397399902344\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20960980328926151\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2553776642765937\n",
      "Epoch: 23, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.031s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.01544809341430664\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20964360587002095\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2554027504911591\n",
      "Epoch: 24, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.045s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.012959957122802734\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20964360587002095\n",
      "Recall 0.3267152550892184\n",
      "F1 0.2554027504911591\n",
      "Epoch: 25, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.031s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.014532804489135742\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.20954223081882659\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25532750662869486\n",
      "Epoch: 26, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.034s\n",
      "8112\n",
      "3745\n",
      "Acc: 0.46166173570019725\n",
      "Prec 0.21857172546499104\n",
      "Recall 0.294195743755925\n",
      "F1 0.25080714045642866\n",
      "312\n",
      "312\n",
      "Time elapsed 0.026441335678100586\n",
      "7488\n",
      "3900\n",
      "Acc: 0.5208333333333334\n",
      "Prec 0.209508460918614\n",
      "Recall 0.3267152550892184\n",
      "F1 0.25530243519245877\n",
      "Epoch: 27, Train loss: 0.000, Val loss: 0.003, Epoch time = 0.033s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f7e15d2774bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreca\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1sc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e36a9b02b34e>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0816e8590ad1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 src: Tensor):\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msrc_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_tok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mouts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for MBR_NO,BRN_NO in mbrnlist:\n",
    "    if featnorm==True:\n",
    "        Data_train = load('Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'norm_train.npy',allow_pickle=True)\n",
    "        Data_test =  load('Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'norm_test.npy',allow_pickle=True)\n",
    "    else:\n",
    "        Data_train = load('Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'train.npy',allow_pickle=True)\n",
    "        Data_test =  load('Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'test.npy',allow_pickle=True)\n",
    "    \n",
    "#     if featnorm==True:\n",
    "#         Data_train = load('Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'norm_train.npy',allow_pickle=True)\n",
    "#         Data_test =  load('Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'norm_test.npy',allow_pickle=True)\n",
    "#     else:\n",
    "#         Data_train = load('Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'train.npy',allow_pickle=True)\n",
    "#         Data_test =  load('Data0930_'+str(MBR_NO)+'_'+str(BRN_NO)+'test.npy',allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "    Xdata=[]\n",
    "    Ydata=[]\n",
    "    Xtrain_data=[]\n",
    "    Ytrain_data=[]\n",
    "    Xtest_data=[]\n",
    "    Ytest_data=[]\n",
    "\n",
    "\n",
    "\n",
    "    for idx in range(len(Data_train)//39):\n",
    "        if(np.isinf(Data_train[39*idx:39*(idx+1)][:,:].tolist()).any()):\n",
    "            print(np.isinf(Data_train[39*idx:39*(idx+1)][:,:].tolist()).any())\n",
    "            continue\n",
    "        Xtrain_data.append(Data_train[39*idx:39*(idx+1)][:,:].tolist())\n",
    "        Ytrain_data.append(Data_train[39*idx:39*(idx+1)][:,-1].tolist())\n",
    "    for idx in range(len(Data_test)//39):\n",
    "        if(np.isinf(Data_test[39*idx:39*(idx+1)][:,:].tolist()).any()):\n",
    "            print(np.isinf(Data_test[39*idx:39*(idx+1)][:,:].tolist()).any())\n",
    "            continue\n",
    "        Xtest_data.append(Data_test[39*idx:39*(idx+1)][:,:].tolist())\n",
    "        Ytest_data.append(Data_test[39*idx:39*(idx+1)][:,-1].tolist())\n",
    "\n",
    "    Xtrain_data=np.vstack(Xtrain_data)\n",
    "    Ytrain_data=np.vstack(Ytrain_data)\n",
    "\n",
    "    Xtrain_data=torch.FloatTensor(Xtrain_data)\n",
    "    Ytrain_data=torch.IntTensor(Ytrain_data)\n",
    "    Ytrain_data=Ytrain_data.view(-1)\n",
    "\n",
    "\n",
    "    Xtest_data=np.vstack(Xtest_data)\n",
    "    Ytest_data=np.vstack(Ytest_data)\n",
    "    Xtest_data=torch.FloatTensor(Xtest_data)\n",
    "    Ytest_data=torch.IntTensor(Ytest_data)\n",
    "    Ytest_data=Ytest_data.view(-1)\n",
    "\n",
    "    Ytrain_data=2*(Ytrain_data>0).long()+(Ytrain_data==0).long()\n",
    "    Ytest_data=2*(Ytest_data>0).long()+(Ytest_data==0).long()\n",
    "    Ytrain_data=Ytrain_data.T\n",
    "    Ytest_data=Ytest_data.T\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "#     SRC_VOCAB_SIZE = Xtrain_data.shape[1]\n",
    "#     TGT_VOCAB_SIZE = 3\n",
    "#     EMB_SIZE = 512\n",
    "#     NHEAD = 8\n",
    "#     FFN_HID_DIM = 512\n",
    "#     BATCH_SIZE = 10\n",
    "#     NUM_ENCODER_LAYERS = 3\n",
    "#     NUM_DECODER_LAYERS = 3\n",
    "\n",
    "    INPUT_SIZE=Xtrain_data.shape[1]\n",
    "    EMB_SIZE=64\n",
    "    HIDDEN_SIZE=64\n",
    "    NUM_LAYERS=12\n",
    "    PROJ_SIZE=3\n",
    "    BATCH_SIZE=16\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    lstm=Seq2SeqRegression(input_size=INPUT_SIZE,hidden_size=HIDDEN_SIZE,num_layers=NUM_LAYERS,emb_size=EMB_SIZE,proj_size=PROJ_SIZE)\n",
    "    for p in lstm.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    lstm = lstm.to(DEVICE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-6, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "    from timeit import default_timer as timer\n",
    "    NUM_EPOCHS = 1000\n",
    "    best_val_loss=100000000\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        start_time = timer()\n",
    "        train_loss,_ = train_epoch(lstm, optimizer)\n",
    "        end_time = timer()\n",
    "        val_loss,acc,prec,reca,f1sc,confusion = evaluate(lstm)\n",
    "        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_confusion=confusion\n",
    "            best_acc=acc\n",
    "            best_prec=prec\n",
    "            best_reca=reca\n",
    "            best_f1sc=f1sc\n",
    "            best_model = lstm\n",
    "\n",
    "\n",
    "    now = datetime.now()\n",
    "    now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    date_time = now.strftime(\"%m_%d_%Y\")\n",
    "    PATH='best_model_seq_logit_'+date_time+'_'+str(MBR_NO)+'_'+str(BRN_NO)\n",
    "\n",
    "\n",
    "    torch.save(best_model.state_dict(), PATH)\n",
    "    file_name='result_logit_norm'+date_time+'.txt'\n",
    "    text_to_append=PATH+'\\t'+\"Acc:\"+str(best_acc)+'\\t'+\"prec:\"+str(best_prec)+'\\t'+\"recall:\"+str(best_reca)+'\\t'+\"f1sc:\"+str(best_f1sc)\n",
    "    print(text_to_append)\n",
    "    with open(file_name, \"a+\") as file_object:\n",
    "        # Move read cursor to the start of file.\n",
    "        file_object.seek(0)\n",
    "        # If file is not empty then append '\\n'\n",
    "        data = file_object.read(100)\n",
    "        if len(data) > 0:\n",
    "            file_object.write(\"\\n\")\n",
    "        # Append text at the end of file\n",
    "        file_object.write(text_to_append)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
