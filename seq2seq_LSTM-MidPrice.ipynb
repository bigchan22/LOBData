{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b9e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from numpy import load\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b6d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load array\n",
    "Data = load('Data_09_lob_dist.npy')\n",
    "# print the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1468292",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=np.nan_to_num(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a238d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata=[]\n",
    "Ydata=[]\n",
    "Xtrain_data=[]\n",
    "Ytrain_data=[]\n",
    "Xtest_data=[]\n",
    "Ytest_data=[]\n",
    "\n",
    "for idx in range(len(Data)//39):\n",
    "#     print(np.isinf(Data[39*idx:39*(idx)+38][:,:].tolist()).any())\n",
    "    if(np.isinf(Data[39*idx:39*(idx)+38][:,:].tolist()).any()):\n",
    "        print(np.isinf(Data[39*idx:39*(idx)+38][:,:].tolist()).any())\n",
    "        continue\n",
    "    if idx< 3735:\n",
    "        Xtrain_data.append(Data[39*idx:39*(idx)+39][:,:].tolist())\n",
    "        Ytrain_data.append(Data[39*idx:39*(idx)+39][:,1].tolist())\n",
    "    else:\n",
    "        Xtest_data.append(Data[39*idx:39*(idx)+39][:,:].tolist())\n",
    "        Ytest_data.append(Data[39*idx:39*(idx)+39][:,1].tolist())\n",
    "\n",
    "\n",
    "Xtrain_data=np.vstack(Xtrain_data)\n",
    "Ytrain_data=np.vstack(Ytrain_data)\n",
    "Xtest_data=np.vstack(Xtest_data)\n",
    "Ytest_data=np.vstack(Ytest_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a9812",
   "metadata": {},
   "source": [
    "Xtrain_data=torch.FloatTensor(Xtrain_data)\n",
    "Ytrain_data=torch.IntTensor(Ytrain_data)\n",
    "Ytrain_data=Ytrain_data.view(-1)\n",
    "\n",
    "\n",
    "Xtest_data=np.vstack(Xtest_data)\n",
    "Ytest_data=np.vstack(Ytest_data)\n",
    "Xtest_data=torch.FloatTensor(Xtest_data)\n",
    "Ytest_data=torch.IntTensor(Ytest_data)\n",
    "Ytest_data=Ytest_data.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd956c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_data=Ytrain_data[:,1:]>Ytrain_data[:,:-1]\n",
    "Ytrain_data=torch.LongTensor(Ytrain_data)\n",
    "Ytrain_data=torch.cat((Ytrain_data,torch.zeros(Ytrain_data.shape[0],1)+2),axis=1)\n",
    "Ytrain_data=Ytrain_data.long()\n",
    "Ytrain_data=Ytrain_data.view(-1)\n",
    "\n",
    "Xtrain_data=torch.FloatTensor(Xtrain_data)\n",
    "\n",
    "\n",
    "Ytest_data=Ytest_data[:,1:]>Ytest_data[:,:-1]\n",
    "Ytest_data=torch.LongTensor(Ytest_data)\n",
    "Ytest_data=torch.cat((Ytest_data,torch.zeros(Ytest_data.shape[0],1)+2),axis=1)\n",
    "\n",
    "Xtest_data=np.vstack(Xtest_data)\n",
    "Ytest_data=np.vstack(Ytest_data)\n",
    "Xtest_data=torch.FloatTensor(Xtest_data)\n",
    "Ytest_data=torch.LongTensor(Ytest_data)\n",
    "Ytest_data=Ytest_data.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d67298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "744*39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a5942db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([145665])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62c8465c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([145665, 17])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3beca2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([145665, 17])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c19ff",
   "metadata": {},
   "source": [
    "Ytrain_data=2*(Ytrain_data>0).long()+(Ytrain_data==0).long()\n",
    "Ytest_data=2*(Ytest_data>0).long()+(Ytest_data==0).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37bc1a",
   "metadata": {},
   "source": [
    "Ydata=(torch.stack([Ydata>0,Ydata==0, Ydata<0],axis=0)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0358866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_data=Ytrain_data.T\n",
    "Ytest_data=Ytest_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6fbe991",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def batchify(data, bsz):\n",
    "#     # 데이터셋을 bsz 파트들로 나눕니다.\n",
    "#     nbatch = data.size(0) // bsz\n",
    "#     # 깔끔하게 나누어 떨어지지 않는 추가적인 부분(나머지들) 은 잘라냅니다.\n",
    "#     data = data.narrow(0, 0, nbatch * bsz)\n",
    "#     # 데이터에 대하여 bsz 배치들로 동등하게 나눕니다.\n",
    "#     data = data.view(bsz, -1,data.size(1)).transpose(0,1).contiguous()\n",
    "#     return data.to(device)\n",
    "\n",
    "\n",
    "def batchify(data, bsz,bptt):\n",
    "    # 데이터셋을 bsz 파트들로 나눕니다.\n",
    "    if(data.size(0)%(bsz*bptt)!=0):\n",
    "        data=data.view(-1,bptt,data.size(1)).transpose(0,1).contiguous()\n",
    "        return data.to(device)\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # 깔끔하게 나누어 떨어지지 않는 추가적인 부분(나머지들) 은 잘라냅니다.\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # 데이터에 대하여 bsz 배치들로 동등하게 나눕니다.\n",
    "    data = data.view(bsz, -1,data.size(1)).transpose(0,1).contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "\n",
    "# batch_size = 25\n",
    "# eval_batch_size = 25\n",
    "\n",
    "# Xtrain_data = batchify(Xtrain_data, batch_size)\n",
    "# Xtest_data = batchify(Xtest_data, eval_batch_size)\n",
    "# Ytrain_data = batchify(Ytrain_data, batch_size)\n",
    "# Ytest_data = batchify(Ytest_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf7796df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 39\n",
    "def get_batch(source, i,bs):\n",
    "    seq_len = min(bptt*bs, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93968dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5f8929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "INPUT_SIZE=Xtrain_data.shape[1]\n",
    "EMB_SIZE=64\n",
    "HIDDEN_SIZE=64\n",
    "NUM_LAYERS=6\n",
    "PROJ_SIZE=3\n",
    "BATCH_SIZE=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93969687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 num_layers: int,\n",
    "                 emb_size:int,\n",
    "                 proj_size:int):\n",
    "        \n",
    "        super(Seq2SeqLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=emb_size,hidden_size=hidden_size,num_layers=num_layers)\n",
    "        self.generator = nn.Linear(emb_size, proj_size)\n",
    "        self.src_tok_emb = nn.Linear(input_size, emb_size)\n",
    "        self.bn1=nn.BatchNorm1d(BATCH_SIZE)\n",
    "    def forward(self,\n",
    "                src: Tensor):\n",
    "\n",
    "        src_emb = self.src_tok_emb(src)\n",
    "        src_emb=self.bn1(src_emb)\n",
    "#         outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "#                                 src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "\n",
    "\n",
    "        outs,_ = self.lstm(src_emb)\n",
    "#         print(outs.size())\n",
    "        return self.generator(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "504d3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "lstm=Seq2SeqLSTM(input_size=INPUT_SIZE,hidden_size=HIDDEN_SIZE,num_layers=NUM_LAYERS,emb_size=EMB_SIZE,proj_size=PROJ_SIZE)\n",
    "for p in lstm.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "lstm = lstm.to(DEVICE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-5, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac331f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2950e+04, 1.7992e-02, 1.9043e-02, 0.0000e+00, 5.0380e+04, 4.6628e+04,\n",
       "        1.7019e+03, 1.9367e+03, 1.5534e+03, 1.3029e+03, 9.6608e+02, 9.7936e+02,\n",
       "        8.9463e+02, 1.4255e+03, 2.6914e+03, 2.8420e+03, 0.0000e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "647d99bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([145665, 17])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f06be10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29055, 17])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba9b6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    total=0\n",
    "    correct=0\n",
    "    correct1=0\n",
    "    tot1=0\n",
    "    correct2=0\n",
    "    tot2=0\n",
    "    correct0=0\n",
    "    tot0=0\n",
    "#     for batch, i in enumerate(range(0, Xtrain_data.size(0) - 1, BATCH_SIZE*bptt)):\n",
    "    i=0\n",
    "    while(i<Xtest_data.size(0)):\n",
    "        data, org_targets = get_batch(Xtrain_data, i,BATCH_SIZE)\n",
    "        if (data.isnan().any() or data.isinf().any()):\n",
    "#            print(data)\n",
    "            continue\n",
    "#         _,targets = get_batch(Ytrain_data,i)\n",
    "        targets,_ = get_batch(Ytrain_data,i,BATCH_SIZE)\n",
    "#         src = src.to(DEVICE)\n",
    "#         tgt = tgt.to(DEVICE)\n",
    "        targets=torch.unsqueeze(targets,1)\n",
    "        src=batchify(data,BATCH_SIZE,bptt)\n",
    "        tgt=batchify(targets,BATCH_SIZE,bptt)\n",
    "        src=src[:]\n",
    "        tgt=tgt[:]\n",
    "        logits = model(src)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        \n",
    "        _,predicted=torch.max(logits,-1)\n",
    "        \n",
    "        correct += (tgt.squeeze() == predicted).sum().item()\n",
    "        total+=len(predicted)*BATCH_SIZE\n",
    "        tot0+=(0== tgt.squeeze()).sum().item()\n",
    "        tot1+=(1== tgt.squeeze()).sum().item()\n",
    "        tot2+=(2== tgt.squeeze()).sum().item()\n",
    "        correct0+=((0== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "        correct1+=((1== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "        correct2+=((2== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "        \n",
    "        i+=targets.size()[0]\n",
    "\n",
    "    print(\"TrainAcc:\",correct/total*100)            \n",
    "    print(\"TrainAcc0:\",correct0/tot0*100,correct0,tot0)     \n",
    "    print(\"TrainAcc1:\",correct1/tot1*100,correct1,tot1)     \n",
    "    print(\"TrainAcc2:\",correct2/tot2*100,correct2,tot2)     \n",
    "    return losses / Xtrain_data.size(0)\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    total=0\n",
    "    correct=0\n",
    "    correct1=0\n",
    "    tot1=0\n",
    "    correct2=0\n",
    "    tot2=0\n",
    "    correct0=0\n",
    "    tot0=0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        i=0\n",
    "        while(i<Xtest_data.size(0)):\n",
    "#         for i in range(0, Xtest_data.size(0) - 1, bptt):\n",
    "\n",
    "            data, org_targets = get_batch(Xtest_data, i,BATCH_SIZE)\n",
    "            if (data.isnan().any() or data.isinf().any()):\n",
    "                print(data)\n",
    "                continue\n",
    "            targets,_ = get_batch(Ytest_data,i,BATCH_SIZE)\n",
    "            targets=torch.unsqueeze(targets,1)\n",
    "            src=batchify(data,BATCH_SIZE,bptt)\n",
    "            tgt=batchify(targets,BATCH_SIZE,bptt)\n",
    "            print(src.shape)\n",
    "            print(tgt.shape)\n",
    "            logits = model(src)\n",
    "#            print(logits.reshape(-1, logits.shape[-1]).shape,'AA')\n",
    "#            print(tgt.reshape(-1).shape,'BB')\n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt.reshape(-1))\n",
    "            if(loss.isnan()):\n",
    "                print(src,tgt_input)\n",
    "                break\n",
    "            losses += loss.item()\n",
    "            _,predicted=torch.max(logits,-1)\n",
    "\n",
    "            \n",
    "            correct += (tgt.squeeze() == predicted).sum().item()\n",
    "            total+=len(predicted)*BATCH_SIZE\n",
    "            tot0+=(0== tgt.squeeze()).sum().item()\n",
    "            tot1+=(1== tgt.squeeze()).sum().item()\n",
    "            tot2+=(2== tgt.squeeze()).sum().item()\n",
    "            correct0+=((0== predicted) &(0==tgt.squeeze())).sum().item()\n",
    "            correct1+=((1== predicted)&(1==tgt.squeeze())).sum().item()\n",
    "            correct2+=((2== predicted)&(2==tgt.squeeze())).sum().item()\n",
    "            i+=targets.size()[0]\n",
    "            \n",
    "    print(total)\n",
    "    print(correct)\n",
    "    print(\"Acc:\",correct/total*100)            \n",
    "    print(\"Acc0:\",correct0/tot0*100,correct0,tot0)     \n",
    "    print(\"Acc1:\",correct1/tot1*100,correct1,tot1)     \n",
    "    print(\"Acc2:\",correct2/tot2*100,correct2,tot2)     \n",
    "    return losses / Xtest_data.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e547b0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29055, 17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bd66d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29055])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "823097d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n",
      "torch.Size([39, 16, 17])\n",
      "torch.Size([39, 16, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 39, 17]' is invalid for input of size 5950",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-49150304ae92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-f771e6ba8e6d>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-453d774a1b1c>\u001b[0m in \u001b[0;36mbatchify\u001b[0;34m(data, bsz, bptt)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 데이터셋을 bsz 파트들로 나눕니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 39, 17]' is invalid for input of size 5950"
     ]
    }
   ],
   "source": [
    "evaluate(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51894615",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 1000\n",
    "best_val_loss=100000000\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(lstm, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(lstm)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = lstm\n",
    "PATH='best_model_seq_mid_1'\n",
    "torch.save(best_model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
