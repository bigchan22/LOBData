{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d2dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c227281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trans\n",
      "1000\n",
      "64\n",
      "0.001\n",
      "128\n",
      "128\n",
      "8\n",
      "4\n",
      "None\n",
      "None\n",
      "[(42, 1)]\n",
      "torch.Size([32838, 10])\n",
      "torch.Size([32838])\n",
      "src in shape torch.Size([39, 64, 10])\n",
      "tgt in shape torch.Size([39, 64, 1])\n",
      "src shape torch.Size([39, 39])\n",
      "tgt shape torch.Size([39, 39])\n",
      "tgt output shape torch.Size([39, 64, 1])\n",
      "logit shape torch.Size([39, 64, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [22,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_153259/3297272865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodeltype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Trans'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             train_loss, _ = train_epoch_lstm(model, optimizer, Xtrain_data, Ytrain_data, loss_fn, device, BATCH_SIZE,\n",
      "\u001b[0;32m~/Min/LOBData/source/train.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, Xtrain_data, Ytrain_data, loss_fn, device, BATCH_SIZE, bptt)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logit shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from source.transformer import Seq2SeqTransformer\n",
    "from source.train import train_epoch, evaluate\n",
    "from source.Attention_LSTM import RNNModel\n",
    "from source.train import train_epoch_lstm, evaluate_lstm\n",
    "from DataInfo import * \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train Config')\n",
    "\n",
    "parser.add_argument('--model', type=str,default='Trans')\n",
    "parser.add_argument('--epoch', type=int, default=1000)\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--lr_initial', type=float, default=1e-3)\n",
    "parser.add_argument('--hid_dim', type=int, default=128)\n",
    "parser.add_argument('--emb_dim', type=int, default=128)\n",
    "parser.add_argument('--num_layers', type=int, default=4)\n",
    "parser.add_argument('--num_head', type=int, default=8)\n",
    "parser.add_argument('--mbr_no', type=int, default=None)\n",
    "parser.add_argument('--brn_no', type=int, default=None)\n",
    "parser.add_argument('--data', type=str, default='1111Train_08')\n",
    "# parser.add_argument('--data', type=str, default='1516Train')\n",
    "# parser.add_argument('--data', type=str, default='_10_0823Train')\n",
    "parser.add_argument('--trainname', type=str, default=None)\n",
    "parser.add_argument('--device', type=str, default='cuda:0')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(args=[])\n",
    "print(args.model)\n",
    "print(args.epoch)\n",
    "print(args.batch_size)\n",
    "print(args.lr_initial)\n",
    "print(args.emb_dim)\n",
    "print(args.hid_dim)\n",
    "print(args.num_head)\n",
    "print(args.num_layers)\n",
    "print(args.mbr_no)\n",
    "print(args.brn_no)\n",
    "\n",
    "modeltype = args.model\n",
    "if modeltype not in ['Trans', 'ALSTM', 'LSTM']:\n",
    "    raise ValueError\n",
    "\n",
    "datasubfix = args.data\n",
    "\n",
    "if args.trainname:\n",
    "    trainname = args.trainname\n",
    "else:\n",
    "    now = datetime.now()\n",
    "    now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    date_time = now.strftime(\"%m_%d_%Y\")\n",
    "    trainname = date_time\n",
    "device = args.device\n",
    "\n",
    "num_epochs = args.epoch\n",
    "bptt = 39\n",
    "TGT_VOCAB_SIZE = 3\n",
    "EMB_SIZE = args.emb_dim\n",
    "NHEAD = args.num_head\n",
    "FFN_HID_DIM = args.hid_dim\n",
    "BATCH_SIZE = args.batch_size\n",
    "lr_init = args.lr_initial\n",
    "NUM_ENCODER_LAYERS = args.num_layers // 2\n",
    "NUM_DECODER_LAYERS = args.num_layers // 2\n",
    "NUM_LAYERS = args.num_layers\n",
    "\n",
    "if args.mbr_no:\n",
    "    mbrnlist = [(args.mbr_no, args.brn_no)]\n",
    "mbrnlist=[(42,1)]\n",
    "print(mbrnlist)\n",
    "\n",
    "# load array\n",
    "for mbr, brn in mbrnlist:\n",
    "    DataSubfix = str(mbr) + '_' + str(brn) + datasubfix\n",
    "    XDataname = 'Train_ORD' + '_' + DataSubfix + '.npy'\n",
    "    YDataname = 'Train_ORD_Label_' + '_' + DataSubfix + '.npy'\n",
    "    XData = load('/Data/LOBData/TrainData/' + XDataname)\n",
    "    YData = load('/Data/LOBData/TrainData/' + YDataname)\n",
    "    Xdata = []\n",
    "    Ydata = []\n",
    "    Xtrain_data = []\n",
    "    Ytrain_data = []\n",
    "    Xtest_data = []\n",
    "    Ytest_data = []\n",
    "    \n",
    "    for idx in range(len(XData) // 39):\n",
    "        if np.isinf(XData[39 * idx:39 * (idx + 1)][:, :].tolist()).any():\n",
    "            print(np.isinf(XData[39 * idx:39 * (idx + 1)][:, :].tolist()).any())\n",
    "            print(mbr, brn)\n",
    "            print(XDataname)\n",
    "            print(XData[39 * idx:39 * (idx + 1)][:, :].tolist())\n",
    "            raise RuntimeError\n",
    "            continue\n",
    "        if np.isinf(YData[39 * idx:39 * (idx + 1)][:].tolist()).any():\n",
    "            print(np.isinf(YData[39 * idx:39 * (idx + 1)].tolist()).any())\n",
    "            raise RuntimeError\n",
    "            continue\n",
    "        if idx < (len(XData) // 39) * 0.9:\n",
    "            Xtrain_data.append(XData[39 * idx:39 * (idx + 1)][:, :-1].tolist())\n",
    "            Ytrain_data.append(YData[39 * idx:39 * (idx + 1)].tolist())\n",
    "        else:\n",
    "            Xtest_data.append(XData[39 * idx:39 * (idx + 1)][:, :-1].tolist())\n",
    "            Ytest_data.append(YData[39 * idx:39 * (idx + 1)].tolist())\n",
    "    Xtrain_data = np.vstack(Xtrain_data)\n",
    "    Ytrain_data = np.vstack(Ytrain_data)\n",
    "    Xtest_data = np.vstack(Xtest_data)\n",
    "    Ytest_data = np.vstack(Ytest_data)\n",
    "\n",
    "    Xtrain_data = torch.FloatTensor(Xtrain_data)\n",
    "    Xtest_data = torch.FloatTensor(Xtest_data)\n",
    "    Ytrain_data = torch.LongTensor(Ytrain_data)\n",
    "    Ytest_data = torch.LongTensor(Ytest_data)\n",
    "\n",
    "    Ytrain_data = Ytrain_data.view(-1)\n",
    "    Ytest_data = Ytest_data.view(-1)\n",
    "    \n",
    "    print(Xtrain_data.shape)\n",
    "    print(Ytrain_data.shape)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    if device == None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    SRC_VOCAB_SIZE = Xtrain_data.shape[1]\n",
    "\n",
    "    if modeltype == 'Trans':\n",
    "        model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                   NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "    if modeltype == \"ALSTM\":\n",
    "        model = RNNModel(rnn_type='LSTM', ntoken=SRC_VOCAB_SIZE, ninp=EMB_SIZE, nhid=FFN_HID_DIM, nlayers=NUM_LAYERS,\n",
    "                         proj_size=TGT_VOCAB_SIZE,\n",
    "                         attention_width=39)\n",
    "    if modeltype == \"LSTM\":\n",
    "        model = RNNModel(rnn_type='LSTM', ntoken=SRC_VOCAB_SIZE, ninp=EMB_SIZE, nhid=FFN_HID_DIM, nlayers=NUM_LAYERS,\n",
    "                         proj_size=TGT_VOCAB_SIZE,\n",
    "                         attention=False)\n",
    "\n",
    "    summary = SummaryWriter()\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_init, betas=(0.9, 0.98), eps=1e-9)\n",
    "    Val_loss = []\n",
    "    Train_loss = []\n",
    "    Accuracy = []\n",
    "    F1score = []\n",
    "    NUM_EPOCHS = num_epochs\n",
    "    best_val_loss = 100000000\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        start_time = timer()\n",
    "        if modeltype == 'Trans':\n",
    "            train_loss, _ = train_epoch(model, optimizer, Xtrain_data, Ytrain_data, loss_fn, device, BATCH_SIZE, bptt)\n",
    "        else:\n",
    "            train_loss, _ = train_epoch_lstm(model, optimizer, Xtrain_data, Ytrain_data, loss_fn, device, BATCH_SIZE,\n",
    "                                             bptt)\n",
    "        end_time = timer()\n",
    "        if modeltype == 'Trans':\n",
    "            val_loss, acc, prec, reca, f1sc, confusion = evaluate(model, Xtest_data, Ytest_data, loss_fn, device,\n",
    "                                                                  BATCH_SIZE, bptt)\n",
    "        else:\n",
    "            val_loss, acc, prec, reca, f1sc, confusion = evaluate_lstm(model, Xtest_data, Ytest_data, loss_fn, device,\n",
    "                                                                       BATCH_SIZE, bptt)\n",
    "        print((\n",
    "            f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_confusion = confusion\n",
    "            best_acc = acc\n",
    "            best_prec = prec\n",
    "            best_reca = reca\n",
    "            best_f1sc = f1sc\n",
    "            best_model = model\n",
    "        Val_loss.append(val_loss)\n",
    "        Train_loss.append(train_loss)\n",
    "        Accuracy.append(acc)\n",
    "        F1score.append(f1sc)\n",
    "\n",
    "#     PATH = 'results/best_model_' + modeltype + '_' + str(mbr) + '_' + str(brn) + trainname\n",
    "# #     torch.save(best_model.state_dict(), PATH)\n",
    "\n",
    "#     file_name = 'results/result_' + modeltype + '_' + str(mbr) + '_' + str(brn) + trainname + '.txt'\n",
    "#     text_to_append = PATH + '\\t' + \"Acc:\" + str(best_acc) + '\\t' + \"prec:\" + str(best_prec) + '\\t' + \"recall:\" + str(\n",
    "#         best_reca) + '\\t' + \"f1sc:\" + str(best_f1sc)\n",
    "#     print(text_to_append)\n",
    "\n",
    "#     with open(file_name, \"a+\") as file_object:\n",
    "#         # Move read cursor to the start of file.\n",
    "#         file_object.seek(0)\n",
    "#         # If file is not empty then append '\\n'\n",
    "#         data = file_object.read(100)\n",
    "#         if len(data) > 0:\n",
    "#             file_object.write(\"\\n\")\n",
    "#         # Append text at the end of file\n",
    "#         file_object.write(text_to_append)\n",
    "\n",
    "#     with open(\"results/Val_loss_\" + modeltype + '_' + str(mbr) + '_' + str(brn) + trainname, \"wb\") as fp:  # Pickling\n",
    "#         pickle.dump(Val_loss, fp)\n",
    "#     with open(\"results/Train_loss_\" + modeltype + '_' + str(mbr) + '_' + str(brn) + trainname, \"wb\") as fp:  # Pickling\n",
    "#         pickle.dump(Train_loss, fp)\n",
    "#     with open(\"results/Accuracy_\" + modeltype + '_' + str(mbr) + '_' + str(brn) + trainname, \"wb\") as fp:  # Pickling\n",
    "#         pickle.dump(Accuracy, fp)\n",
    "#     with open(\"results/F1_\" + modeltype + '_' + str(mbr) + '_' + str(brn) + trainname, \"wb\") as fp:  # Pickling\n",
    "#         pickle.dump(F1score, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5324d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d483f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82568146",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Ytrain_data==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                   NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src shape torch.Size([39, 64, 10])\n",
    "tgt shape torch.Size([40, 64, 1])\n",
    "2 2 128 8 10 3 128"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
